
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Comprehensive educational resource for NSW HSC Software Engineering syllabus">
      
      
      
        <link rel="canonical" href="https://eatham532.github.io/Software-Engineering-HSC-Textbook/Year12/SoftwareAutomation/Chapter-21-Programming-for-automation/21-02-Neural-networks-concepts-and-implementation/">
      
      
        <link rel="prev" href="../21-01-Regression-models-and-core-algorithm-types-in-Python/quiz/">
      
      
        <link rel="next" href="quiz/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>21.2 Neural Networks: Concepts and Implementation - Software Engineering Textbook HSC</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/diagram-modal.css">
    
      <link rel="stylesheet" href="../../../../assets/quiz.css">
    
      <link rel="stylesheet" href="../../../../assets/common.css">
    
      <link rel="stylesheet" href="../../../../assets/diagram-fix.css">
    
      <link rel="stylesheet" href="../../../../assets/cross-reference.css">
    
      <link rel="stylesheet" href="../../../../assets/site-banner.css">
    
      <link rel="stylesheet" href="../../../../assets/code-runner.css">
    
      <link rel="stylesheet" href="../../../../assets/code-editor.css">
    
      <link rel="stylesheet" href="../../../../assets/glossary.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-58275RL1P9"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-58275RL1P9",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-58275RL1P9",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>if("undefined"!=typeof __md_analytics){var consent=__md_get("__consent");consent&&consent.analytics&&__md_analytics()}</script>
  

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#212-neural-networks-concepts-and-implementation" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
  
  
    
    
    
    <div class="site-banner site-banner--warning" data-banner data-banner-version="1" role="status" aria-live="polite">
      <div class="site-banner__inner">
        <span class="site-banner__icon" aria-hidden="true">
          <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            
              <path d="M12 9v4"/><path d="M12 17h.01"/><path d="M10.29 3.86 1.82 18a2 2 0 0 0 1.71 3h16.94a2 2 0 0 0 1.71-3L13.71 3.86a2 2 0 0 0-3.42 0Z"/>
            
          </svg>
        </span>
        <p class="site-banner__text">
          This textbook is in <strong>beta</strong> – content is actively being refined.
          
            <a class="site-banner__link" href="https://github.com/Eatham532/Software-Engineering-HSC-Textbook/issues/new/choose" target="_blank" rel="noopener">Report issues or suggestions</a>
          
        </p>
        <button type="button" class="site-banner__close" aria-label="Dismiss banner" title="Dismiss" data-banner-dismiss>&times;</button>
      </div>
    </div>
    <script>
      (function(){
        var banner=document.querySelector('[data-banner]');
        if(!banner) return;
        var version=banner.getAttribute('data-banner-version')||'1';
        var KEY='site_banner_dismissed_v'+version;
        try{ if(localStorage.getItem(KEY)){ banner.remove(); return;} }catch(e){}
        var btn=banner.querySelector('[data-banner-dismiss]');
        if(btn){ btn.addEventListener('click',function(){
          banner.classList.add('is-hiding');
          setTimeout(function(){ banner && banner.remove(); },200);
          try{ localStorage.setItem(KEY,'1'); }catch(e){}
        }); }
      })();
    </script>
  
  
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Software Engineering Textbook HSC" class="md-header__button md-logo" aria-label="Software Engineering Textbook HSC" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Software Engineering Textbook HSC
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              21.2 Neural Networks: Concepts and Implementation
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/Eatham532/Software-Engineering-HSC-Textbook/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    Eatham532/Software-Engineering-HSC-Textbook
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    

    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../Year11/ProgrammingFundamentals/" class="md-tabs__link">
          
  
  
  Year 11

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
  
  
    
    
      
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../ProgrammingForTheWeb/" class="md-tabs__link">
          
  
  
  Year 12

        </a>
      </li>
    
  

    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../code-editor/" class="md-tabs__link">
        
  
  
    
  
  Code Editor

      </a>
    </li>
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../glossary/" class="md-tabs__link">
        
  
  
    
  
  Glossary

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Software Engineering Textbook HSC" class="md-nav__button md-logo" aria-label="Software Engineering Textbook HSC" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Software Engineering Textbook HSC
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Eatham532/Software-Engineering-HSC-Textbook/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    Eatham532/Software-Engineering-HSC-Textbook
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    
  
  
  
    <a href="../../../../Year11/ProgrammingFundamentals/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Year 11
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

  

      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Year 12
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Year 12
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../ProgrammingForTheWeb/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Programming For The Web
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../SecureSoftwareArchitecture/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Secure Software Architecture
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Software Automation
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            Software Automation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    
  
  
  
    <a href="../../Chapter-20-ML-and-automation-basics/20-01-What-is-AI-vs-ML/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Chapter 20 — ML and automation basics
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

  

      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3_3_3" id="__nav_3_3_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Chapter 21 — Programming for automation
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_3_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_3_3">
            <span class="md-nav__icon md-icon"></span>
            Chapter 21 — Programming for automation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../21-01-Regression-models-and-core-algorithm-types-in-Python/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    21.1 Regression models and core algorithm types in Python
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3_3_2" checked>
        
          
          <label class="md-nav__link" for="__nav_3_3_3_2" id="__nav_3_3_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    21.2 Neural networks: concepts and implementation
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_3_3_3_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_3_3_2">
            <span class="md-nav__icon md-icon"></span>
            21.2 Neural networks: concepts and implementation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Content
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Content
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-1-perceptron-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Part 1: Perceptron Implementation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 1: Perceptron Implementation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from-scratch-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      From-Scratch Implementation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-2-tiny-multi-layer-perceptron-mlp-demo" class="md-nav__link">
    <span class="md-ellipsis">
      Part 2: Tiny Multi-Layer Perceptron (MLP) Demo
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 2: Tiny Multi-Layer Perceptron (MLP) Demo">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation_1" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from-scratch-implementation_1" class="md-nav__link">
    <span class="md-ellipsis">
      From-Scratch Implementation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-3-training-loop-intuition" class="md-nav__link">
    <span class="md-ellipsis">
      Part 3: Training Loop Intuition
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 3: Training Loop Intuition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#understanding-the-training-process" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding the Training Process
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-analysis-tools" class="md-nav__link">
    <span class="md-ellipsis">
      Training Analysis Tools
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-4-practical-applications-and-behavior-reasoning" class="md-nav__link">
    <span class="md-ellipsis">
      Part 4: Practical Applications and Behavior Reasoning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 4: Practical Applications and Behavior Reasoning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#understanding-neural-network-behavior" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding Neural Network Behavior
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior-analysis-tools" class="md-nav__link">
    <span class="md-ellipsis">
      Behavior Analysis Tools
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#recap" class="md-nav__link">
    <span class="md-ellipsis">
      Recap
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="quiz/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Quiz
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    
  
  
  
    <a href="../../Chapter-22-Significance-and-impact/22-01-Assessing-the-impact-of-automation/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Chapter 22 — Significance and impact
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../SoftwareEngineeringProject/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Software Engineering Project
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../code-editor/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Code Editor
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../glossary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Glossary
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-1-perceptron-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Part 1: Perceptron Implementation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 1: Perceptron Implementation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from-scratch-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      From-Scratch Implementation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-2-tiny-multi-layer-perceptron-mlp-demo" class="md-nav__link">
    <span class="md-ellipsis">
      Part 2: Tiny Multi-Layer Perceptron (MLP) Demo
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 2: Tiny Multi-Layer Perceptron (MLP) Demo">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation_1" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from-scratch-implementation_1" class="md-nav__link">
    <span class="md-ellipsis">
      From-Scratch Implementation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-3-training-loop-intuition" class="md-nav__link">
    <span class="md-ellipsis">
      Part 3: Training Loop Intuition
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 3: Training Loop Intuition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#understanding-the-training-process" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding the Training Process
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-analysis-tools" class="md-nav__link">
    <span class="md-ellipsis">
      Training Analysis Tools
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-4-practical-applications-and-behavior-reasoning" class="md-nav__link">
    <span class="md-ellipsis">
      Part 4: Practical Applications and Behavior Reasoning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 4: Practical Applications and Behavior Reasoning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#understanding-neural-network-behavior" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding Neural Network Behavior
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior-analysis-tools" class="md-nav__link">
    <span class="md-ellipsis">
      Behavior Analysis Tools
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#recap" class="md-nav__link">
    <span class="md-ellipsis">
      Recap
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#summary" class="md-nav__link">
    <span class="md-ellipsis">
      Summary
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/Eatham532/Software-Engineering-HSC-Textbook/edit/main/docs/Year12/SoftwareAutomation/Chapter-21-Programming-for-automation/21-02-Neural-networks-concepts-and-implementation/index.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/Eatham532/Software-Engineering-HSC-Textbook/raw/main/docs/Year12/SoftwareAutomation/Chapter-21-Programming-for-automation/21-02-Neural-networks-concepts-and-implementation/index.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="212-neural-networks-concepts-and-implementation">21.2 Neural Networks: Concepts and Implementation<a class="headerlink" href="#212-neural-networks-concepts-and-implementation" title="Permanent link">&para;</a></h1>
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h2>
<p>Neural networks form the foundation of modern <span class="glossary-term" data-glossary-category="Automation" data-glossary-definition="The simulation of human intelligence processes by computer systems, including learning, reasoning, and self-correction." data-glossary-full-form="Artificial Intelligence" data-glossary-term="AI">AI</span> systems by mimicking how biological neurons process information. This section implements neural networks from scratch, starting with the simple perceptron and progressing to multi-layer perceptrons (MLPs) with backpropagation training.</p>
<p><strong>Key Learning Goals:</strong></p>
<ul>
<li>
<p><strong>Understand</strong> perceptron architecture and learning <span class="glossary-term" data-glossary-category="Programming Fundamentals" data-glossary-definition="A finite sequence of well-defined instructions to solve a problem or perform a computation." data-glossary-term="Algorithm">algorithm</span></p>
</li>
<li>
<p><strong>Implement</strong> tiny MLP with backpropagation from mathematical principles</p>
</li>
<li>
<p><strong>Develop</strong> training loop intuition through hands-on coding</p>
</li>
<li>
<p><strong>Reason</strong> about neural network behavior and decision-making</p>
</li>
</ul>
<div class="diagram-container" data-container-id="kroki-diagram-0"><button class="diagram-expand-btn" onclick="openDiagramModal('kroki-diagram-0')">🔍 View Larger</button><div id="kroki-diagram-0" class="diagram-content"><p><svg xmlns="http://www.w3.org/2000/svg" contentStyleType="text/css" data-diagram-type="DESCRIPTION" height="679px" preserveAspectRatio="xMaxYMax meet" style="width:2440px;height:679px;background:#FFFFFF;" version="1.1" viewBox="0 0 2440 679" width="2440px" zoomAndPan="magnify" id="Kroki" data-diagram-id="kroki-svg-0"><defs /><g><g class="cluster" data-entity="Neural Network Architecture" data-source-line="3" data-uid="ent0002" id="cluster_Neural Network Architecture"><path d="M13.5,11 L241.5967,11 A3.75,3.75 0 0 1 244.0967,13.5 L251.0967,33.2969 L1981.5,33.2969 A2.5,2.5 0 0 1 1984,35.7969 L1984,448.93 A2.5,2.5 0 0 1 1981.5,451.43 L13.5,451.43 A2.5,2.5 0 0 1 11,448.93 L11,13.5 A2.5,2.5 0 0 1 13.5,11" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><line style="stroke:#000000;stroke-width:1;" x1="11" x2="251.0967" y1="33.2969" y2="33.2969" /><text fill="#000000" font-family="Verdana" font-size="14" font-weight="bold" lengthAdjust="spacing" textLength="227.0967" x="15" y="25.9951">Neural Network Architecture</text></g><g class="cluster" data-entity="Training Loop Components" data-source-line="57" data-uid="ent0046" id="cluster_Training Loop Components"><path d="M2018.5,53.91 L2231.4551,53.91 A3.75,3.75 0 0 1 2233.9551,56.41 L2240.9551,76.2069 L2430.5,76.2069 A2.5,2.5 0 0 1 2433,78.7069 L2433,669.52 A2.5,2.5 0 0 1 2430.5,672.02 L2018.5,672.02 A2.5,2.5 0 0 1 2016,669.52 L2016,56.41 A2.5,2.5 0 0 1 2018.5,53.91" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><line style="stroke:#000000;stroke-width:1;" x1="2016" x2="2240.9551" y1="76.2069" y2="76.2069" /><text fill="#000000" font-family="Verdana" font-size="14" font-weight="bold" lengthAdjust="spacing" textLength="211.9551" x="2020" y="68.9051">Training Loop Components</text></g><g class="entity" data-entity="Input Layer" data-source-line="5" data-uid="ent0003" id="entity_Input Layer"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="119.7344" x="1699.13" y="58.12" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="1798.8644" y="63.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1796.8644" y="65.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1796.8644" y="69.12" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="79.7344" x="1714.13" y="91.1151">Input Layer</text></g><g class="entity" data-entity="Hidden Layer 1" data-source-line="6" data-uid="ent0004" id="entity_Hidden Layer 1"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="146.5176" x="1649.74" y="176.54" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="1776.2576" y="181.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1774.2576" y="183.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1774.2576" y="187.54" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="106.5176" x="1664.74" y="209.5351">Hidden Layer 1</text></g><g class="entity" data-entity="Hidden Layer 2" data-source-line="7" data-uid="ent0005" id="entity_Hidden Layer 2"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="146.5176" x="1649.74" y="282.83" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="1776.2576" y="287.83" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1774.2576" y="289.83" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1774.2576" y="293.83" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="106.5176" x="1664.74" y="315.8251">Hidden Layer 2</text></g><g class="entity" data-entity="Output Layer" data-source-line="8" data-uid="ent0006" id="entity_Output Layer"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="132.1143" x="1656.94" y="389.13" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="1769.0543" y="394.13" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1767.0543" y="396.13" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1767.0543" y="400.13" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="92.1143" x="1671.94" y="422.1251">Output Layer</text></g><g class="entity" data-entity="GMN10" data-source-line="14" data-uid="ent0011" id="entity_GMN10"><path d="M1854.34,68.7 L1854.34,77.27 L1819.27,81.27 L1854.34,85.27 L1854.34,93.8328 A0,0 0 0 0 1854.34,93.8328 L1967.654,93.8328 A0,0 0 0 0 1967.654,93.8328 L1967.654,78.7 L1957.654,68.7 L1854.34,68.7 A0,0 0 0 0 1854.34,68.7" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M1957.654,68.7 L1957.654,78.7 L1967.654,78.7 L1957.654,68.7" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="92.314" x="1860.34" y="85.7669">Features/Data</text></g><g class="entity" data-entity="GMN13" data-source-line="15" data-uid="ent0014" id="entity_GMN13"><path d="M1831.07,187.12 L1831.07,195.68 L1796.56,199.68 L1831.07,203.68 L1831.07,212.2528 A0,0 0 0 0 1831.07,212.2528 L1966.9372,212.2528 A0,0 0 0 0 1966.9372,212.2528 L1966.9372,197.12 L1956.9372,187.12 L1831.07,187.12 A0,0 0 0 0 1831.07,187.12" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M1956.9372,187.12 L1956.9372,197.12 L1966.9372,197.12 L1956.9372,187.12" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="114.8672" x="1837.07" y="204.1869">Pattern Detection</text></g><g class="entity" data-entity="GMN16" data-source-line="16" data-uid="ent0017" id="entity_GMN16"><path d="M1831.63,293.41 L1831.63,301.98 L1796.63,305.98 L1831.63,309.98 L1831.63,318.5428 A0,0 0 0 0 1831.63,318.5428 L1968.3668,318.5428 A0,0 0 0 0 1968.3668,318.5428 L1968.3668,303.41 L1958.3668,293.41 L1831.63,293.41 A0,0 0 0 0 1831.63,293.41" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M1958.3668,293.41 L1958.3668,303.41 L1968.3668,303.41 L1958.3668,293.41" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="115.7368" x="1837.63" y="310.4769">Complex Patterns</text></g><g class="entity" data-entity="GMN19" data-source-line="17" data-uid="ent0020" id="entity_GMN19"><path d="M1823.57,399.71 L1823.57,408.28 L1789.32,412.28 L1823.57,416.28 L1823.57,424.8428 A0,0 0 0 0 1823.57,424.8428 L1916.4382,424.8428 A0,0 0 0 0 1916.4382,424.8428 L1916.4382,409.71 L1906.4382,399.71 L1823.57,399.71 A0,0 0 0 0 1823.57,399.71" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M1906.4382,399.71 L1906.4382,409.71 L1916.4382,409.71 L1906.4382,399.71" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="71.8682" x="1829.57" y="416.7769">Predictions</text></g><g class="entity" data-entity="Perceptron" data-source-line="19" data-uid="ent0022" id="entity_Perceptron"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="116.6924" x="1327.65" y="58.12" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="1424.3424" y="63.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1422.3424" y="65.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1422.3424" y="69.12" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="76.6924" x="1342.65" y="91.1151">Perceptron</text></g><g class="entity" data-entity="Binary Classification" data-source-line="20" data-uid="ent0023" id="entity_Binary Classification"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="182.0713" x="1294.96" y="176.54" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="1457.0313" y="181.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1455.0313" y="183.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1455.0313" y="187.54" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="142.0713" x="1309.96" y="209.5351"><span class="glossary-term" data-glossary-category="Programming Fundamentals" data-glossary-definition="A base-2 number system using only digits 0 and 1, fundamental to how computers store and process data." data-glossary-term="Binary">Binary</span> Classification</text></g><g class="entity" data-entity="GMN25" data-source-line="23" data-uid="ent0026" id="entity_GMN25"><path d="M1479.4,53.57 L1479.4,77.27 L1444.49,81.27 L1479.4,85.27 L1479.4,108.9684 A0,0 0 0 0 1479.4,108.9684 L1664.5948,108.9684 A0,0 0 0 0 1664.5948,108.9684 L1664.5948,63.57 L1654.5948,53.57 L1479.4,53.57 A0,0 0 0 0 1479.4,53.57" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M1654.5948,53.57 L1654.5948,63.57 L1664.5948,63.57 L1654.5948,53.57" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="76.7114" x="1485.4" y="70.6369">Single layer</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="164.1948" x="1485.4" y="85.7697">Linear decision boundary</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="131.1108" x="1485.4" y="100.9025">Simple learning rule</text></g><g class="entity" data-entity="Multi-Layer Perceptron" data-source-line="28" data-uid="ent0028" id="entity_Multi-Layer Perceptron"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="199.4482" x="872.28" y="58.12" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="1051.7282" y="63.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1049.7282" y="65.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1049.7282" y="69.12" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="159.4482" x="887.28" y="91.1151">Multi-Layer Perceptron</text></g><g class="entity" data-entity="Non-linear Problems" data-source-line="29" data-uid="ent0029" id="entity_Non-linear Problems"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="182.0986" x="880.95" y="176.54" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="1043.0486" y="181.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1041.0486" y="183.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1041.0486" y="187.54" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="142.0986" x="895.95" y="209.5351">Non-linear Problems</text></g><g class="entity" data-entity="GMN31" data-source-line="32" data-uid="ent0032" id="entity_GMN31"><path d="M1107.03,53.57 L1107.03,77.27 L1072.2,81.27 L1107.03,85.27 L1107.03,108.9684 A0,0 0 0 0 1107.03,108.9684 L1292.9738,108.9684 A0,0 0 0 0 1292.9738,108.9684 L1292.9738,63.57 L1282.9738,53.57 L1107.03,53.57 A0,0 0 0 0 1107.03,53.57" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M1282.9738,53.57 L1282.9738,63.57 L1292.9738,63.57 L1282.9738,53.57" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="143.8823" x="1113.03" y="70.6369">Multiple hidden layers</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="164.9438" x="1113.03" y="85.7697">Backpropagation training</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="152.9849" x="1113.03" y="100.9025">Universal approximator</text></g><g class="entity" data-entity="Activation Functions" data-source-line="37" data-uid="ent0034" id="entity_Activation Functions"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="182.3926" x="385.8" y="58.12" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="548.1926" y="63.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="546.1926" y="65.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="546.1926" y="69.12" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="142.3926" x="400.8" y="91.1151">Activation <span class="glossary-term" data-glossary-category="Programming Fundamentals" data-glossary-definition="A reusable block of code that performs a specific task and returns a value to the caller." data-glossary-term="Function">Functions</span></text></g><g class="entity" data-entity="Non-linearity" data-source-line="38" data-uid="ent0035" id="entity_Non-linearity"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="130.2275" x="411.89" y="176.54" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="522.1175" y="181.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="520.1175" y="183.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="520.1175" y="187.54" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="90.2275" x="426.89" y="209.5351">Non-linearity</text></g><g class="entity" data-entity="GMN37" data-source-line="41" data-uid="ent0038" id="entity_GMN37"><path d="M602.8,53.57 L602.8,77.27 L568.6,81.27 L602.8,85.27 L602.8,108.9684 A0,0 0 0 0 602.8,108.9684 L837.1955,108.9684 A0,0 0 0 0 837.1955,108.9684 L837.1955,63.57 L827.1955,53.57 L602.8,53.57 A0,0 0 0 0 602.8,53.57" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M827.1955,53.57 L827.1955,63.57 L837.1955,63.57 L827.1955,53.57" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="179.5752" x="608.8" y="70.6369">Sigmoid: &#963;(x) = 1/(1+e^-x)</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="104.9966" x="608.8" y="85.7697">ReLU: max(0, x)</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="213.3955" x="608.8" y="100.9025">Tanh: (e^x - e^-x)/(e^x + e^-x)</text></g><g class="entity" data-entity="Training Process" data-source-line="46" data-uid="ent0040" id="entity_Training Process"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="155.4111" x="27.29" y="58.12" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="162.7011" y="63.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="160.7011" y="65.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="160.7011" y="69.12" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="115.4111" x="42.29" y="91.1151">Training Process</text></g><g class="entity" data-entity="Weight Updates" data-source-line="47" data-uid="ent0041" id="entity_Weight Updates"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="152.041" x="28.98" y="176.54" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="161.021" y="181.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="159.021" y="183.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="159.021" y="187.54" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="112.041" x="43.98" y="209.5351">Weight Updates</text></g><g class="entity" data-entity="GMN43" data-source-line="50" data-uid="ent0044" id="entity_GMN43"><path d="M217.39,46 L217.39,77.27 L182.96,81.27 L217.39,85.27 L217.39,116.5313 A0,0 0 0 0 217.39,116.5313 L350.6102,116.5313 A0,0 0 0 0 350.6102,116.5313 L350.6102,56 L340.6102,46 L217.39,46 A0,0 0 0 0 217.39,46" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M340.6102,46 L340.6102,56 L350.6102,56 L340.6102,46" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="86.8677" x="223.39" y="63.0669">Forward pass</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="103.4668" x="223.39" y="78.1997">Loss calculation</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="97.6523" x="223.39" y="93.3325">Backward pass</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="112.2202" x="223.39" y="108.4653">Gradient descent</text></g><g class="entity" data-entity="Data Batch" data-source-line="58" data-uid="ent0047" id="entity_Data Batch"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="118.1211" x="2290.94" y="176.54" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="2389.0611" y="181.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2387.0611" y="183.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2387.0611" y="187.54" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="78.1211" x="2305.94" y="209.5351">Data Batch</text></g><g class="entity" data-entity="Forward Pass" data-source-line="59" data-uid="ent0048" id="entity_Forward Pass"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="133.1055" x="2199.45" y="282.83" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="2312.5555" y="287.83" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2310.5555" y="289.83" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2310.5555" y="293.83" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="93.1055" x="2214.45" y="315.8251">Forward Pass</text></g><g class="entity" data-entity="Loss Calculation" data-source-line="60" data-uid="ent0049" id="entity_Loss Calculation"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="153.5039" x="2184.25" y="389.13" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="2317.7539" y="394.13" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2315.7539" y="396.13" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2315.7539" y="400.13" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="113.5039" x="2199.25" y="422.1251">Loss Calculation</text></g><g class="entity" data-entity="Backward Pass" data-source-line="61" data-uid="ent0050" id="entity_Backward Pass"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="144.7197" x="2190.64" y="495.43" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="2315.3597" y="500.43" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2313.3597" y="502.43" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2313.3597" y="506.43" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="104.7197" x="2205.64" y="528.4251">Backward Pass</text></g><g class="entity" data-entity="Weight Update" data-source-line="62" data-uid="ent0051" id="entity_Weight Update"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="144.7471" x="2240.63" y="601.72" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="2365.3771" y="606.72" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2363.3771" y="608.72" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2363.3771" y="612.72" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="104.7471" x="2255.63" y="634.7151">Weight Update</text></g><g class="entity" data-entity="GMN57" data-source-line="70" data-uid="ent0058" id="entity_GMN57"><path d="M2040.49,187.12 L2040.49,212.2528 L2255.5188,212.2528 L2255.5188,197.12 L2245.5188,187.12 L2040.49,187.12" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M2245.5188,187.12 L2245.5188,197.12 L2255.5188,197.12 L2245.5188,187.12" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="194.0288" x="2046.49" y="204.1869">Iterative optimization process</text></g><g class="link" data-entity-1="Input Layer" data-entity-2="Hidden Layer 1" data-source-line="10" data-uid="lnk7" id="link_Input Layer_Hidden Layer 1"><path d="M1752.06,104.72 C1745.68,125.33 1738.0625,149.9778 1731.6925,170.5778" fill="none" id="Input Layer-to-Hidden Layer 1" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="1729.92,176.31,1736.4003,168.8934,1731.3971,171.5332,1728.7573,166.53,1729.92,176.31" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Hidden Layer 1" data-entity-2="Hidden Layer 2" data-source-line="11" data-uid="lnk8" id="link_Hidden Layer 1_Hidden Layer 2"><path d="M1723,223.31 C1723,240.81 1723,258.91 1723,276.39" fill="none" id="Hidden Layer 1-to-Hidden Layer 2" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="1723,282.39,1727,273.39,1723,277.39,1719,273.39,1723,282.39" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Hidden Layer 2" data-entity-2="Output Layer" data-source-line="12" data-uid="lnk9" id="link_Hidden Layer 2_Output Layer"><path d="M1723,329.61 C1723,347.11 1723,365.21 1723,382.69" fill="none" id="Hidden Layer 2-to-Output Layer" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="1723,388.69,1727,379.69,1723,383.69,1719,379.69,1723,388.69" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Perceptron" data-entity-2="Binary Classification" data-source-line="21" data-uid="lnk24" id="link_Perceptron_Binary Classification"><path d="M1386,104.72 C1386,125.33 1386,149.71 1386,170.31" fill="none" id="Perceptron-to-Binary Classification" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="1386,176.31,1390,167.31,1386,171.31,1382,167.31,1386,176.31" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Multi-Layer Perceptron" data-entity-2="Non-linear Problems" data-source-line="30" data-uid="lnk30" id="link_Multi-Layer Perceptron_Non-linear Problems"><path d="M972,104.72 C972,125.33 972,149.71 972,170.31" fill="none" id="Multi-Layer Perceptron-to-Non-linear Problems" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="972,176.31,976,167.31,972,171.31,968,167.31,972,176.31" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Activation Functions" data-entity-2="Non-linearity" data-source-line="39" data-uid="lnk36" id="link_Activation Functions_Non-linearity"><path d="M477,104.72 C477,125.33 477,149.71 477,170.31" fill="none" id="Activation Functions-to-Non-linearity" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="477,176.31,481,167.31,477,171.31,473,167.31,477,176.31" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Training Process" data-entity-2="Weight Updates" data-source-line="48" data-uid="lnk42" id="link_Training Process_Weight Updates"><path d="M105,104.72 C105,125.33 105,149.71 105,170.31" fill="none" id="Training Process-to-Weight Updates" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="105,176.31,109,167.31,105,171.31,101,167.31,105,176.31" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Data Batch" data-entity-2="Forward Pass" data-source-line="64" data-uid="lnk52" id="link_Data Batch_Forward Pass"><path d="M2331.77,223.31 C2317.68,240.81 2302.0338,260.2373 2287.9538,277.7173" fill="none" id="Data Batch-to-Forward Pass" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="2284.19,282.39,2292.9508,277.8902,2287.3265,278.4961,2286.7206,272.8718,2284.19,282.39" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Forward Pass" data-entity-2="Loss Calculation" data-source-line="65" data-uid="lnk53" id="link_Forward Pass_Loss Calculation"><path d="M2264.92,329.61 C2264.08,347.11 2263.208,365.2169 2262.368,382.6969" fill="none" id="Forward Pass-to-Loss Calculation" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="2262.08,388.69,2266.5074,379.8924,2262.32,383.6958,2258.5166,379.5084,2262.08,388.69" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Loss Calculation" data-entity-2="Backward Pass" data-source-line="66" data-uid="lnk54" id="link_Loss Calculation_Backward Pass"><path d="M2261.43,435.91 C2261.77,453.4 2262.1133,471.5111 2262.4533,488.9911" fill="none" id="Loss Calculation-to-Backward Pass" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="2262.57,494.99,2266.3942,485.9139,2262.4728,489.9909,2258.3957,486.0695,2262.57,494.99" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Backward Pass" data-entity-2="Weight Update" data-source-line="67" data-uid="lnk55" id="link_Backward Pass_Weight Update"><path d="M2273.85,542.21 C2282.24,559.7 2291.1962,578.3896 2299.5762,595.8696" fill="none" id="Backward Pass-to-Weight Update" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="2302.17,601.28,2301.8863,591.4352,2300.0085,596.7713,2294.6724,594.8936,2302.17,601.28" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Weight Update" data-entity-2="Data Batch" data-source-line="68" data-uid="lnk56" id="link_Weight Update_Data Batch"><path d="M2327.16,601.5 C2336.44,585.52 2347.79,563.15 2353,541.72 C2381.49,424.65 2363.7429,284.1238 2354.8729,228.9838" fill="none" id="Weight Update-to-Data Batch" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="2353.92,223.06,2351.4002,232.5811,2354.7141,227.9965,2359.2986,231.3105,2353.92,223.06" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Training Loop Components" data-entity-2="GMN57" data-source-line="70" data-uid="lnk59" id="link_Training Loop Components_GMN57"><path d="M2148,82.35 C2148,85.18 2148,158.08 2148,187.01" fill="none" id="Training Loop Components-GMN57" style="stroke:#000000;stroke-width:1;stroke-dasharray:7.0,7.0;" /></g></g></svg></p></div></div>
<hr />
<h2 id="part-1-perceptron-implementation">Part 1: Perceptron Implementation<a class="headerlink" href="#part-1-perceptron-implementation" title="Permanent link">&para;</a></h2>
<h3 id="mathematical-foundation">Mathematical Foundation<a class="headerlink" href="#mathematical-foundation" title="Permanent link">&para;</a></h3>
<p>The perceptron is the simplest neural network, consisting of a single neuron that learns to classify linearly separable data. It demonstrates the fundamental concepts of neural learning without the complexity of multiple layers.</p>
<p><strong>Perceptron Architecture:</strong></p>
<ul>
<li>
<p><strong>Inputs</strong>: <code>x₁, x₂, ..., xₙ</code> (features)</p>
</li>
<li>
<p><strong>Weights</strong>: <code>w₁, w₂, ..., wₙ</code> (learned parameters)</p>
</li>
<li>
<p><strong>Bias</strong>: <code>b</code> (threshold adjustment)</p>
</li>
<li>
<p><strong>Output</strong>: <code>y = f(Σwᵢxᵢ + b)</code> where <code>f</code> is activation <span class="glossary-term" data-glossary-category="Programming Fundamentals" data-glossary-definition="A reusable block of code that performs a specific task and returns a value to the caller." data-glossary-term="Function">function</span></p>
</li>
</ul>
<p><strong>Activation <span class="glossary-term" data-glossary-category="Programming Fundamentals" data-glossary-definition="A reusable block of code that performs a specific task and returns a value to the caller." data-glossary-term="Function">Functions</span>:</strong></p>
<ul>
<li>
<p><strong>Step <span class="glossary-term" data-glossary-category="Programming Fundamentals" data-glossary-definition="A reusable block of code that performs a specific task and returns a value to the caller." data-glossary-term="Function">Function</span></strong>: <code>f(z) = 1 if z ≥ 0, else 0</code></p>
</li>
<li>
<p><strong>Sigmoid</strong>: <code>f(z) = 1/(1 + e^(-z))</code> (smooth, differentiable)</p>
</li>
</ul>
<p><strong>Learning Rule (Perceptron <span class="glossary-term" data-glossary-category="Programming Fundamentals" data-glossary-definition="A finite sequence of well-defined instructions to solve a problem or perform a computation." data-glossary-term="Algorithm">Algorithm</span>):</strong></p>
<ul>
<li>
<p>For each training example: <code>wᵢ = wᵢ + α(target - prediction) * xᵢ</code></p>
</li>
<li>
<p>Where <code>α</code> is the learning rate</p>
</li>
</ul>
<h3 id="from-scratch-implementation">From-Scratch Implementation<a class="headerlink" href="#from-scratch-implementation" title="Permanent link">&para;</a></h3>
<div class="highlight python-template" data-fence-type="template" data-language="python">
<pre><code class="language-python"><span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Any</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">random</span>

<span class="k">class</span><span class="w"> </span><span class="nc">Perceptron</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Single-layer perceptron implementation from scratch.</span>
<span class="sd">    Demonstrates basic neural network concepts and learning.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s1">&#39;step&#39;</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize perceptron.</span>

<span class="sd">        Args:</span>
<span class="sd">            learning_rate: Step size for weight updates</span>
<span class="sd">            max_epochs: Maximum training iterations</span>
<span class="sd">            activation: Activation function (&#39;step&#39; or &#39;sigmoid&#39;)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span> <span class="o">=</span> <span class="n">max_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trained</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_activation_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Apply activation function to input.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">==</span> <span class="s1">&#39;step&#39;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">z</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">==</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span>

            <span class="c1">## Clip to prevent overflow</span>

            <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="o">-</span><span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
            <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown activation function: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_activation_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Compute derivative of activation function.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">==</span> <span class="s1">&#39;step&#39;</span><span class="p">:</span>

            <span class="c1">## Step function derivative is 0 everywhere (except at 0, undefined)</span>

            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>  <span class="c1"># Use 1 as approximation for learning</span>
        <span class="k">elif</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">==</span> <span class="s1">&#39;sigmoid&#39;</span><span class="p">:</span>
            <span class="n">sigmoid_output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_activation_function</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">sigmoid_output</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigmoid_output</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Unknown activation function: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_forward_pass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform forward pass through perceptron.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: Input features</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple of (linear_output, activated_output)</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">## Linear combination: z = X * w + b</span>

        <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>

        <span class="c1">## Apply activation function</span>

        <span class="n">a</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_activation_function</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">z</span><span class="p">,</span> <span class="n">a</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the perceptron using the perceptron learning algorithm.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: Training features (n_samples, n_features)</span>
<span class="sd">            y: Training targets (n_samples,)</span>

<span class="sd">        Returns:</span>
<span class="sd">            Training statistics</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">## Ensure proper shapes</span>

        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">n_samples</span><span class="p">,</span> <span class="n">n_features</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>

        <span class="c1">## Initialize weights and bias randomly</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="n">n_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>

        <span class="c1">## Track training progress</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_epochs</span><span class="p">):</span>
            <span class="n">total_error</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">correct_predictions</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1">## Process each training example</span>

            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_samples</span><span class="p">):</span>

                <span class="c1">## Forward pass for single example</span>

                <span class="n">x_i</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
                <span class="n">target</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

                <span class="c1">## Compute prediction</span>

                <span class="n">z</span><span class="p">,</span> <span class="n">prediction</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pass</span><span class="p">(</span><span class="n">x_i</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>
                <span class="n">prediction</span> <span class="o">=</span> <span class="n">prediction</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># Extract scalar</span>

                <span class="c1">## Compute error</span>

                <span class="n">error</span> <span class="o">=</span> <span class="n">target</span> <span class="o">-</span> <span class="n">prediction</span>
                <span class="n">total_error</span> <span class="o">+=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">error</span><span class="p">)</span>

                <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">error</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">1e-6</span><span class="p">:</span>  <span class="c1"># Consider very small errors as correct</span>
                    <span class="n">correct_predictions</span> <span class="o">+=</span> <span class="mi">1</span>

                <span class="c1">## Update weights and bias using perceptron learning rule</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">==</span> <span class="s1">&#39;step&#39;</span><span class="p">:</span>

                    <span class="c1">## Classic perceptron rule</span>

                    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">error</span> <span class="o">*</span> <span class="n">x_i</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">error</span>
                <span class="k">else</span><span class="p">:</span>

                    <span class="c1">## Gradient descent for sigmoid</span>

                    <span class="n">derivative</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_activation_derivative</span><span class="p">(</span><span class="n">z</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">error</span> <span class="o">*</span> <span class="n">derivative</span> <span class="o">*</span> <span class="n">x_i</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">+=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">error</span> <span class="o">*</span> <span class="n">derivative</span>

            <span class="c1">## Calculate accuracy</span>

            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">correct_predictions</span> <span class="o">/</span> <span class="n">n_samples</span>

            <span class="c1">## Record epoch statistics</span>

            <span class="n">epoch_stats</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span>
                <span class="s1">&#39;total_error&#39;</span><span class="p">:</span> <span class="n">total_error</span><span class="p">,</span>
                <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">accuracy</span><span class="p">,</span>
                <span class="s1">&#39;weights&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
                <span class="s1">&#39;bias&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
            <span class="p">}</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_stats</span><span class="p">)</span>

            <span class="c1">## Check for convergence</span>

            <span class="k">if</span> <span class="n">total_error</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">converged</span> <span class="o">=</span> <span class="kc">True</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Converged after </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2"> epochs&quot;</span><span class="p">)</span>
                <span class="k">break</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trained</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;converged&#39;</span><span class="p">:</span> <span class="n">converged</span><span class="p">,</span>
            <span class="s1">&#39;final_epoch&#39;</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">),</span>
            <span class="s1">&#39;final_accuracy&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;accuracy&#39;</span><span class="p">],</span>
            <span class="s1">&#39;final_error&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;total_error&#39;</span><span class="p">]</span>
        <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Make predictions on new data.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trained</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Perceptron must be trained before making predictions&quot;</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_forward_pass</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">predictions</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">decision_boundary_equation</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get human-readable decision boundary equation.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trained</span> <span class="ow">or</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;Decision boundary not available&quot;</span>

        <span class="n">w1</span><span class="p">,</span> <span class="n">w2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weights</span>
        <span class="n">b</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>

        <span class="c1">## Decision boundary: w1*x1 + w2*x2 + b = 0</span>

        <span class="c1">## Solving for x2: x2 = (-w1*x1 - b) / w2</span>

        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;x2 = </span><span class="si">{</span><span class="o">-</span><span class="n">w1</span><span class="o">/</span><span class="n">w2</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> * x1 + </span><span class="si">{</span><span class="o">-</span><span class="n">b</span><span class="o">/</span><span class="n">w2</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_training_statistics</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get detailed training statistics.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">stats</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">stats</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">],</span>
            <span class="s1">&#39;errors&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">stats</span><span class="p">[</span><span class="s1">&#39;total_error&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">stats</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">],</span>
            <span class="s1">&#39;accuracies&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">stats</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">stats</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">]</span>
        <span class="p">}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">demonstrate_perceptron</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Demonstrate perceptron with classic examples.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Perceptron Demonstration&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">25</span><span class="p">)</span>

    <span class="c1">## Example 1: AND Gate</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">1. AND Gate Learning&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">20</span><span class="p">)</span>

    <span class="c1">## AND gate truth table</span>

    <span class="n">X_and</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">y_and</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

    <span class="c1">## Train perceptron</span>

    <span class="n">perceptron_and</span> <span class="o">=</span> <span class="n">Perceptron</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;step&#39;</span><span class="p">)</span>
    <span class="n">and_stats</span> <span class="o">=</span> <span class="n">perceptron_and</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_and</span><span class="p">,</span> <span class="n">y_and</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;AND Gate Training:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Converged: </span><span class="si">{</span><span class="n">and_stats</span><span class="p">[</span><span class="s1">&#39;converged&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Final accuracy: </span><span class="si">{</span><span class="n">and_stats</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Epochs required: </span><span class="si">{</span><span class="n">and_stats</span><span class="p">[</span><span class="s1">&#39;final_epoch&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Decision boundary: </span><span class="si">{</span><span class="n">perceptron_and</span><span class="o">.</span><span class="n">decision_boundary_equation</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Test predictions</span>

    <span class="n">predictions_and</span> <span class="o">=</span> <span class="n">perceptron_and</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_and</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">AND Gate Results:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X_and</span><span class="p">,</span> <span class="n">y_and</span><span class="p">,</span> <span class="n">predictions_and</span><span class="p">)):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> AND </span><span class="si">{</span><span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2"> (predicted: </span><span class="si">{</span><span class="n">pred</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

    <span class="c1">## Example 2: OR Gate</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">2. OR Gate Learning&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">19</span><span class="p">)</span>

    <span class="c1">## OR gate truth table</span>

    <span class="n">X_or</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">y_or</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

    <span class="c1">## Train perceptron</span>

    <span class="n">perceptron_or</span> <span class="o">=</span> <span class="n">Perceptron</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;step&#39;</span><span class="p">)</span>
    <span class="n">or_stats</span> <span class="o">=</span> <span class="n">perceptron_or</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_or</span><span class="p">,</span> <span class="n">y_or</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;OR Gate Training:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Converged: </span><span class="si">{</span><span class="n">or_stats</span><span class="p">[</span><span class="s1">&#39;converged&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Final accuracy: </span><span class="si">{</span><span class="n">or_stats</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Epochs required: </span><span class="si">{</span><span class="n">or_stats</span><span class="p">[</span><span class="s1">&#39;final_epoch&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Decision boundary: </span><span class="si">{</span><span class="n">perceptron_or</span><span class="o">.</span><span class="n">decision_boundary_equation</span><span class="p">()</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Example 3: XOR Gate (should fail - not linearly separable)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">3. XOR Gate Learning (Expected to Fail)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">40</span><span class="p">)</span>

    <span class="c1">## XOR gate truth table</span>

    <span class="n">X_xor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">y_xor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>

    <span class="c1">## Train perceptron</span>

    <span class="n">perceptron_xor</span> <span class="o">=</span> <span class="n">Perceptron</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;step&#39;</span><span class="p">)</span>
    <span class="n">xor_stats</span> <span class="o">=</span> <span class="n">perceptron_xor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_xor</span><span class="p">,</span> <span class="n">y_xor</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;XOR Gate Training:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Converged: </span><span class="si">{</span><span class="n">xor_stats</span><span class="p">[</span><span class="s1">&#39;converged&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Final accuracy: </span><span class="si">{</span><span class="n">xor_stats</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Epochs completed: </span><span class="si">{</span><span class="n">xor_stats</span><span class="p">[</span><span class="s1">&#39;final_epoch&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Final error: </span><span class="si">{</span><span class="n">xor_stats</span><span class="p">[</span><span class="s1">&#39;final_error&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">predictions_xor</span> <span class="o">=</span> <span class="n">perceptron_xor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_xor</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">XOR Gate Results (showing limitation):&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X_xor</span><span class="p">,</span> <span class="n">y_xor</span><span class="p">,</span> <span class="n">predictions_xor</span><span class="p">)):</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="s2">&quot;✓&quot;</span> <span class="k">if</span> <span class="nb">abs</span><span class="p">(</span><span class="n">target</span> <span class="o">-</span> <span class="n">pred</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="s2">&quot;✗&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> XOR </span><span class="si">{</span><span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">target</span><span class="si">}</span><span class="s2"> (predicted: </span><span class="si">{</span><span class="n">pred</span><span class="si">:</span><span class="s2">.0f</span><span class="si">}</span><span class="s2">) </span><span class="si">{</span><span class="n">correct</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Perceptron Limitation: Cannot learn XOR (not linearly separable)&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;This motivates the need for multi-layer networks!&quot;</span><span class="p">)</span>

    <span class="c1">## Example 4: Linearly Separable 2D Data</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">4. 2D Classification Problem&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>

    <span class="c1">## Generate linearly separable 2D data</span>

    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

    <span class="c1">## Class 0: points around (2, 2)</span>

    <span class="n">class0_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">25</span><span class="p">)</span>
    <span class="n">class0_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">25</span><span class="p">)</span>

    <span class="c1">## Class 1: points around (5, 5)</span>

    <span class="n">class1_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">25</span><span class="p">)</span>
    <span class="n">class1_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="mi">25</span><span class="p">)</span>

    <span class="c1">## Combine data</span>

    <span class="n">X_2d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span>
        <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">class0_x</span><span class="p">,</span> <span class="n">class1_x</span><span class="p">]),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">class0_y</span><span class="p">,</span> <span class="n">class1_y</span><span class="p">])</span>
    <span class="p">])</span>
    <span class="n">y_2d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">25</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">25</span><span class="p">)])</span>

    <span class="c1">## Shuffle data</span>

    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">y_2d</span><span class="p">))</span>
    <span class="n">X_2d</span> <span class="o">=</span> <span class="n">X_2d</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
    <span class="n">y_2d</span> <span class="o">=</span> <span class="n">y_2d</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>

    <span class="c1">## Train perceptron with sigmoid activation</span>

    <span class="n">perceptron_2d</span> <span class="o">=</span> <span class="n">Perceptron</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">max_epochs</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">)</span>
    <span class="n">stats_2d</span> <span class="o">=</span> <span class="n">perceptron_2d</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_2d</span><span class="p">,</span> <span class="n">y_2d</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;2D Classification Training:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Converged: </span><span class="si">{</span><span class="n">stats_2d</span><span class="p">[</span><span class="s1">&#39;converged&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Final accuracy: </span><span class="si">{</span><span class="n">stats_2d</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Epochs required: </span><span class="si">{</span><span class="n">stats_2d</span><span class="p">[</span><span class="s1">&#39;final_epoch&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Test on new points</span>

    <span class="n">test_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
    <span class="n">test_predictions</span> <span class="o">=</span> <span class="n">perceptron_2d</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_points</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Test Predictions:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">point</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">test_points</span><span class="p">,</span> <span class="n">test_predictions</span><span class="p">):</span>
        <span class="n">class_pred</span> <span class="o">=</span> <span class="s2">&quot;Class 1&quot;</span> <span class="k">if</span> <span class="n">pred</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="s2">&quot;Class 0&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Point </span><span class="si">{</span><span class="n">point</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">class_pred</span><span class="si">}</span><span class="s2"> (confidence: </span><span class="si">{</span><span class="n">pred</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">perceptron_and</span><span class="p">,</span> <span class="n">perceptron_or</span><span class="p">,</span> <span class="n">perceptron_xor</span><span class="p">,</span> <span class="n">perceptron_2d</span>
</code></pre>
</div>
<hr />
<h2 id="part-2-tiny-multi-layer-perceptron-mlp-demo">Part 2: Tiny Multi-Layer Perceptron (MLP) Demo<a class="headerlink" href="#part-2-tiny-multi-layer-perceptron-mlp-demo" title="Permanent link">&para;</a></h2>
<h3 id="mathematical-foundation_1">Mathematical Foundation<a class="headerlink" href="#mathematical-foundation_1" title="Permanent link">&para;</a></h3>
<p>Multi-layer perceptrons extend single perceptrons by adding hidden layers, enabling them to learn non-linear patterns. The key innovation is <strong>backpropagation</strong> - an <span class="glossary-term" data-glossary-category="Programming Fundamentals" data-glossary-definition="A finite sequence of well-defined instructions to solve a problem or perform a computation." data-glossary-term="Algorithm">algorithm</span> that efficiently computes gradients for all weights in the network.</p>
<p><strong>MLP Architecture:</strong></p>
<ul>
<li>
<p><strong>Input Layer</strong>: Receives features</p>
</li>
<li>
<p><strong>Hidden Layer(s)</strong>: Process and transform features</p>
</li>
<li>
<p><strong>Output Layer</strong>: Produces final predictions</p>
</li>
<li>
<p><strong>Connections</strong>: Each neuron connects to all neurons in the next layer</p>
</li>
</ul>
<p><strong>Forward Pass:</strong></p>
<ol>
<li>
<p><code>z₁ = W₁X + b₁</code> (linear transformation)</p>
</li>
<li>
<p><code>a₁ = σ(z₁)</code> (activation <span class="glossary-term" data-glossary-category="Programming Fundamentals" data-glossary-definition="A reusable block of code that performs a specific task and returns a value to the caller." data-glossary-term="Function">function</span>)</p>
</li>
<li>
<p><code>z₂ = W₂a₁ + b₂</code> (second layer)</p>
</li>
<li>
<p><code>ŷ = σ(z₂)</code> (final output)</p>
</li>
</ol>
<p><strong>Backpropagation <span class="glossary-term" data-glossary-category="Programming Fundamentals" data-glossary-definition="A finite sequence of well-defined instructions to solve a problem or perform a computation." data-glossary-term="Algorithm">Algorithm</span>:</strong></p>
<ol>
<li>
<p><strong>Forward pass</strong>: Compute predictions</p>
</li>
<li>
<p><strong>Compute loss</strong>: Compare predictions to targets</p>
</li>
<li>
<p><strong>Backward pass</strong>: Compute gradients using chain rule</p>
</li>
<li>
<p><strong>Update weights</strong>: Apply gradient descent</p>
</li>
</ol>
<h3 id="from-scratch-implementation_1">From-Scratch Implementation<a class="headerlink" href="#from-scratch-implementation_1" title="Permanent link">&para;</a></h3>
<div class="highlight python-template" data-fence-type="template" data-language="python">
<pre><code class="language-python"><span class="k">class</span><span class="w"> </span><span class="nc">TinyMLP</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tiny Multi-Layer Perceptron implementation from scratch.</span>
<span class="sd">    Demonstrates backpropagation and multi-layer learning.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">output_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Initialize tiny MLP with one hidden layer.</span>

<span class="sd">        Args:</span>
<span class="sd">            input_size: Number of input features</span>
<span class="sd">            hidden_size: Number of neurons in hidden layer</span>
<span class="sd">            output_size: Number of output neurons</span>
<span class="sd">            learning_rate: Learning rate for gradient descent</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_size</span> <span class="o">=</span> <span class="n">input_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="n">hidden_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">=</span> <span class="n">output_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">=</span> <span class="n">learning_rate</span>

        <span class="c1">## Initialize weights with small random values</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">W1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">(</span><span class="n">input_size</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>   <span class="c1"># Input to hidden</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">))</span>                            <span class="c1"># Hidden layer bias</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="p">))</span>  <span class="c1"># Hidden to output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_size</span><span class="p">))</span>                            <span class="c1"># Output layer bias</span>

        <span class="c1">## Track training progress</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">trained</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Sigmoid activation function with numerical stability.&quot;&quot;&quot;</span>
        <span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="o">-</span><span class="mi">500</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>  <span class="c1"># Prevent overflow</span>
        <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_sigmoid_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Derivative of sigmoid function.&quot;&quot;&quot;</span>
        <span class="n">sigmoid_z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">sigmoid_z</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">sigmoid_z</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_relu</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;ReLU activation function.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_relu_derivative</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Derivative of ReLU function.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">z</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">forward_pass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform forward pass through the network.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: Input data (batch_size, input_size)</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dictionary containing intermediate values for backpropagation</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">## Ensure X is 2D</span>

        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="c1">## Layer 1: Input to Hidden</span>

        <span class="n">z1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W1</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span>
        <span class="n">a1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid</span><span class="p">(</span><span class="n">z1</span><span class="p">)</span>

        <span class="c1">## Layer 2: Hidden to Output</span>

        <span class="n">z2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W2</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span>
        <span class="n">a2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid</span><span class="p">(</span><span class="n">z2</span><span class="p">)</span>

        <span class="c1">## Store intermediate values for backpropagation</span>

        <span class="n">cache</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;X&#39;</span><span class="p">:</span> <span class="n">X</span><span class="p">,</span>
            <span class="s1">&#39;z1&#39;</span><span class="p">:</span> <span class="n">z1</span><span class="p">,</span>
            <span class="s1">&#39;a1&#39;</span><span class="p">:</span> <span class="n">a1</span><span class="p">,</span>
            <span class="s1">&#39;z2&#39;</span><span class="p">:</span> <span class="n">z2</span><span class="p">,</span>
            <span class="s1">&#39;a2&#39;</span><span class="p">:</span> <span class="n">a2</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">cache</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">compute_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">predictions</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">targets</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Compute mean squared error loss.</span>

<span class="sd">        Args:</span>
<span class="sd">            predictions: Network predictions</span>
<span class="sd">            targets: True target values</span>

<span class="sd">        Returns:</span>
<span class="sd">            Mean squared error</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">predictions</span> <span class="o">-</span> <span class="n">targets</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">backward_pass</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">cache</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span> <span class="n">targets</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Perform backward pass (backpropagation) to compute gradients.</span>

<span class="sd">        Args:</span>
<span class="sd">            cache: Forward pass intermediate values</span>
<span class="sd">            targets: True target values</span>

<span class="sd">        Returns:</span>
<span class="sd">            Dictionary containing gradients for all parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">## Extract values from cache</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span>
        <span class="n">z1</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="s1">&#39;z1&#39;</span><span class="p">]</span>
        <span class="n">a1</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="s1">&#39;a1&#39;</span><span class="p">]</span>
        <span class="n">z2</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="s1">&#39;z2&#39;</span><span class="p">]</span>
        <span class="n">a2</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="s1">&#39;a2&#39;</span><span class="p">]</span>

        <span class="n">m</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>  <span class="c1"># batch size</span>

        <span class="c1">## Ensure targets have correct shape</span>

        <span class="k">if</span> <span class="n">targets</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">targets</span> <span class="o">=</span> <span class="n">targets</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1">## Output layer gradients (Layer 2)</span>

        <span class="n">dz2</span> <span class="o">=</span> <span class="n">a2</span> <span class="o">-</span> <span class="n">targets</span>  <span class="c1"># Derivative of MSE w.r.t. z2 (simplified for sigmoid)</span>
        <span class="n">dW2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">a1</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dz2</span><span class="p">)</span> <span class="o">/</span> <span class="n">m</span>
        <span class="n">db2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dz2</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1">## Hidden layer gradients (Layer 1)</span>

        <span class="n">da1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dz2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">W2</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">dz1</span> <span class="o">=</span> <span class="n">da1</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">_sigmoid_derivative</span><span class="p">(</span><span class="n">z1</span><span class="p">)</span>
        <span class="n">dW1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dz1</span><span class="p">)</span> <span class="o">/</span> <span class="n">m</span>
        <span class="n">db1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">dz1</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">gradients</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;dW1&#39;</span><span class="p">:</span> <span class="n">dW1</span><span class="p">,</span>
            <span class="s1">&#39;db1&#39;</span><span class="p">:</span> <span class="n">db1</span><span class="p">,</span>
            <span class="s1">&#39;dW2&#39;</span><span class="p">:</span> <span class="n">dW2</span><span class="p">,</span>
            <span class="s1">&#39;db2&#39;</span><span class="p">:</span> <span class="n">db2</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="n">gradients</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">update_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gradients</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Update weights using gradient descent.</span>

<span class="sd">        Args:</span>
<span class="sd">            gradients: Computed gradients for all parameters</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W1</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients</span><span class="p">[</span><span class="s1">&#39;dW1&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b1</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients</span><span class="p">[</span><span class="s1">&#39;db1&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">W2</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients</span><span class="p">[</span><span class="s1">&#39;dW2&#39;</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b2</span> <span class="o">-=</span> <span class="bp">self</span><span class="o">.</span><span class="n">learning_rate</span> <span class="o">*</span> <span class="n">gradients</span><span class="p">[</span><span class="s1">&#39;db2&#39;</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train_epoch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train for one epoch (one pass through all data).</span>

<span class="sd">        Args:</span>
<span class="sd">            X: Training features</span>
<span class="sd">            y: Training targets</span>

<span class="sd">        Returns:</span>
<span class="sd">            Training statistics for this epoch</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">## Forward pass</span>

        <span class="n">cache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_pass</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="s1">&#39;a2&#39;</span><span class="p">]</span>

        <span class="c1">## Compute loss</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1">## Backward pass</span>

        <span class="n">gradients</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backward_pass</span><span class="p">(</span><span class="n">cache</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1">## Update weights</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">update_weights</span><span class="p">(</span><span class="n">gradients</span><span class="p">)</span>

        <span class="c1">## Compute accuracy (for classification problems)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>  <span class="c1"># Binary classification</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">predictions</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>  <span class="c1"># Multi-class classification</span>
            <span class="n">predicted_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">true_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">y</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predicted_classes</span> <span class="o">==</span> <span class="n">true_classes</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
            <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">accuracy</span><span class="p">,</span>
            <span class="s1">&#39;predictions&#39;</span><span class="p">:</span> <span class="n">predictions</span>
        <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Train the MLP for specified number of epochs.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: Training features</span>
<span class="sd">            y: Training targets</span>
<span class="sd">            epochs: Number of training epochs</span>
<span class="sd">            verbose: Whether to print training progress</span>

<span class="sd">        Returns:</span>
<span class="sd">            Training history and statistics</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1">## Ensure proper shapes</span>

        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>

            <span class="c1">## Train one epoch</span>

            <span class="n">epoch_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_epoch</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

            <span class="c1">## Add epoch number</span>

            <span class="n">epoch_stats</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span>

            <span class="c1">## Store training history</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_stats</span><span class="p">)</span>

            <span class="c1">## Print progress</span>

            <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">//</span> <span class="mi">10</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">:</span><span class="s2">3d</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">: Loss = </span><span class="si">{</span><span class="n">epoch_stats</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Accuracy = </span><span class="si">{</span><span class="n">epoch_stats</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trained</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;training_history&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">,</span>
            <span class="s1">&#39;final_loss&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
            <span class="s1">&#39;final_accuracy&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span>
        <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Make predictions on new data.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">trained</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;MLP must be trained before making predictions&quot;</span><span class="p">)</span>

        <span class="n">cache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_pass</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">cache</span><span class="p">[</span><span class="s1">&#39;a2&#39;</span><span class="p">]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_weights_info</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get information about current weights.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;W1_shape&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">W1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
            <span class="s1">&#39;W1_mean&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W1</span><span class="p">),</span>
            <span class="s1">&#39;W1_std&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W1</span><span class="p">),</span>
            <span class="s1">&#39;W2_shape&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">W2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
            <span class="s1">&#39;W2_mean&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W2</span><span class="p">),</span>
            <span class="s1">&#39;W2_std&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W2</span><span class="p">),</span>
            <span class="s1">&#39;total_parameters&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">W1</span><span class="o">.</span><span class="n">size</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="o">.</span><span class="n">size</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">W2</span><span class="o">.</span><span class="n">size</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span><span class="o">.</span><span class="n">size</span>
        <span class="p">}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">demonstrate_tiny_mlp</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Demonstrate tiny MLP with XOR problem and other examples.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Tiny Multi-Layer Perceptron Demonstration&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">41</span><span class="p">)</span>

    <span class="c1">## Example 1: XOR Problem (the classic MLP success story)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">1. XOR Problem - MLP Success&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>

    <span class="c1">## XOR data</span>

    <span class="n">X_xor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">y_xor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]])</span>

    <span class="c1">## Create and train tiny MLP</span>

    <span class="n">mlp_xor</span> <span class="o">=</span> <span class="n">TinyMLP</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training MLP on XOR problem...&quot;</span><span class="p">)</span>
    <span class="n">training_stats</span> <span class="o">=</span> <span class="n">mlp_xor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_xor</span><span class="p">,</span> <span class="n">y_xor</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training completed:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Final loss: </span><span class="si">{</span><span class="n">training_stats</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Final accuracy: </span><span class="si">{</span><span class="n">training_stats</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Test XOR predictions</span>

    <span class="n">predictions</span> <span class="o">=</span> <span class="n">mlp_xor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_xor</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">XOR Results:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">inputs</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">X_xor</span><span class="p">,</span> <span class="n">y_xor</span><span class="p">,</span> <span class="n">predictions</span><span class="p">)):</span>
        <span class="n">pred_binary</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="mi">0</span>
        <span class="n">correct</span> <span class="o">=</span> <span class="s2">&quot;✓&quot;</span> <span class="k">if</span> <span class="n">pred_binary</span> <span class="o">==</span> <span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">else</span> <span class="s2">&quot;✗&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> XOR </span><span class="si">{</span><span class="n">inputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2"> = </span><span class="si">{</span><span class="n">target</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2"> (predicted: </span><span class="si">{</span><span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> → </span><span class="si">{</span><span class="n">pred_binary</span><span class="si">}</span><span class="s2">) </span><span class="si">{</span><span class="n">correct</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Show weight information</span>

    <span class="n">weights_info</span> <span class="o">=</span> <span class="n">mlp_xor</span><span class="o">.</span><span class="n">get_weights_info</span><span class="p">()</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Network Architecture:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Hidden layer weights: </span><span class="si">{</span><span class="n">weights_info</span><span class="p">[</span><span class="s1">&#39;W1_shape&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Output layer weights: </span><span class="si">{</span><span class="n">weights_info</span><span class="p">[</span><span class="s1">&#39;W2_shape&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Total parameters: </span><span class="si">{</span><span class="n">weights_info</span><span class="p">[</span><span class="s1">&#39;total_parameters&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Example 2: Simple 2D Classification</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">2. 2D Non-linear Classification&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">32</span><span class="p">)</span>

    <span class="c1">## Generate non-linearly separable data (circular pattern)</span>

    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
    <span class="n">n_samples</span> <span class="o">=</span> <span class="mi">100</span>

    <span class="c1">## Inner circle (class 0)</span>

    <span class="n">r_inner</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">,</span> <span class="n">n_samples</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">theta_inner</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">n_samples</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">x_inner</span> <span class="o">=</span> <span class="n">r_inner</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta_inner</span><span class="p">)</span>
    <span class="n">y_inner</span> <span class="o">=</span> <span class="n">r_inner</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta_inner</span><span class="p">)</span>

    <span class="c1">## Outer circle (class 1)</span>

    <span class="n">r_outer</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mf">2.5</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">n_samples</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">theta_outer</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">n_samples</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">x_outer</span> <span class="o">=</span> <span class="n">r_outer</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">theta_outer</span><span class="p">)</span>
    <span class="n">y_outer</span> <span class="o">=</span> <span class="n">r_outer</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">theta_outer</span><span class="p">)</span>

    <span class="c1">## Combine data</span>

    <span class="n">X_circle</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span>
        <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">x_inner</span><span class="p">,</span> <span class="n">x_outer</span><span class="p">]),</span>
        <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">y_inner</span><span class="p">,</span> <span class="n">y_outer</span><span class="p">])</span>
    <span class="p">])</span>
    <span class="n">y_circle</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">//</span> <span class="mi">2</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n_samples</span> <span class="o">//</span> <span class="mi">2</span><span class="p">)])</span>

    <span class="c1">## Shuffle</span>

    <span class="n">indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">permutation</span><span class="p">(</span><span class="n">n_samples</span><span class="p">)</span>
    <span class="n">X_circle</span> <span class="o">=</span> <span class="n">X_circle</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
    <span class="n">y_circle</span> <span class="o">=</span> <span class="n">y_circle</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1">## Create and train MLP</span>

    <span class="n">mlp_circle</span> <span class="o">=</span> <span class="n">TinyMLP</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training MLP on circular classification...&quot;</span><span class="p">)</span>
    <span class="n">circle_stats</span> <span class="o">=</span> <span class="n">mlp_circle</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_circle</span><span class="p">,</span> <span class="n">y_circle</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training completed:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Final loss: </span><span class="si">{</span><span class="n">circle_stats</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Final accuracy: </span><span class="si">{</span><span class="n">circle_stats</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Test on specific points</span>

    <span class="n">test_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">]])</span>
    <span class="n">test_predictions</span> <span class="o">=</span> <span class="n">mlp_circle</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_points</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Test Predictions:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">point</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">test_points</span><span class="p">,</span> <span class="n">test_predictions</span><span class="p">):</span>
        <span class="n">class_pred</span> <span class="o">=</span> <span class="s2">&quot;Outer&quot;</span> <span class="k">if</span> <span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="k">else</span> <span class="s2">&quot;Inner&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Point </span><span class="si">{</span><span class="n">point</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">class_pred</span><span class="si">}</span><span class="s2"> circle (confidence: </span><span class="si">{</span><span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

    <span class="c1">## Example 3: Function Approximation</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">3. Function Approximation&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">26</span><span class="p">)</span>

    <span class="c1">## Generate data for a non-linear function: y = sin(x) + 0.5*cos(2x)</span>

    <span class="n">X_func</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">2</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">pi</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">y_func</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X_func</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">X_func</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.1</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X_func</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

    <span class="c1">## Normalize inputs for better training</span>

    <span class="n">X_func_norm</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_func</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X_func</span><span class="p">))</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X_func</span><span class="p">)</span>

    <span class="c1">## Create and train MLP for regression</span>

    <span class="n">mlp_func</span> <span class="o">=</span> <span class="n">TinyMLP</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training MLP for function approximation...&quot;</span><span class="p">)</span>
    <span class="n">func_stats</span> <span class="o">=</span> <span class="n">mlp_func</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_func_norm</span><span class="p">,</span> <span class="n">y_func</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training completed:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Final loss: </span><span class="si">{</span><span class="n">func_stats</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Test function approximation</span>

    <span class="n">test_x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">]])</span> <span class="c1"># Normalized test points</span>
    <span class="n">test_predictions</span> <span class="o">=</span> <span class="n">mlp_func</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span>
    <span class="n">actual_x</span> <span class="o">=</span> <span class="n">test_x</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">X_func</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">X_func</span><span class="p">)</span>  <span class="c1"># Denormalize for display</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Function Approximation Results:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x_norm</span><span class="p">,</span> <span class="n">x_actual</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">test_x</span><span class="p">,</span> <span class="n">actual_x</span><span class="p">,</span> <span class="n">test_predictions</span><span class="p">):</span>
        <span class="n">actual_y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">x_actual</span><span class="p">)</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">x_actual</span><span class="p">)</span>
        <span class="n">error</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">actual_y</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  x = </span><span class="si">{</span><span class="n">x_actual</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">: predicted = </span><span class="si">{</span><span class="n">pred</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, actual ≈ </span><span class="si">{</span><span class="n">actual_y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> (error: </span><span class="si">{</span><span class="n">error</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mlp_xor</span><span class="p">,</span> <span class="n">mlp_circle</span><span class="p">,</span> <span class="n">mlp_func</span>
</code></pre>
</div>
<hr />
<h2 id="part-3-training-loop-intuition">Part 3: Training Loop Intuition<a class="headerlink" href="#part-3-training-loop-intuition" title="Permanent link">&para;</a></h2>
<h3 id="understanding-the-training-process">Understanding the Training Process<a class="headerlink" href="#understanding-the-training-process" title="Permanent link">&para;</a></h3>
<p>The training loop is the heart of neural network learning. Understanding how weights evolve, loss decreases, and the network learns patterns is crucial for developing intuition about neural network behavior.</p>
<p><strong>Training Loop Components:</strong></p>
<ol>
<li>
<p><strong>Initialization</strong>: Random weights start the process</p>
</li>
<li>
<p><strong>Forward Pass</strong>: Compute predictions with current weights</p>
</li>
<li>
<p><strong>Loss Calculation</strong>: Measure prediction error</p>
</li>
<li>
<p><strong>Backward Pass</strong>: Compute how to adjust weights</p>
</li>
<li>
<p><strong>Weight Update</strong>: Apply gradient descent</p>
</li>
<li>
<p><strong>Repeat</strong>: Until convergence or max epochs</p>
</li>
</ol>
<h3 id="training-analysis-tools">Training Analysis Tools<a class="headerlink" href="#training-analysis-tools" title="Permanent link">&para;</a></h3>
<div class="highlight python-template" data-fence-type="template" data-language="python">
<pre><code class="language-python"><span class="k">class</span><span class="w"> </span><span class="nc">TrainingAnalyzer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tools for analyzing and visualizing neural network training.</span>
<span class="sd">    Helps build intuition about the learning process.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_logs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">log_training_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">weights</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">gradients</span><span class="p">:</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">loss</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Log detailed training step information.&quot;&quot;&quot;</span>
        <span class="n">log_entry</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;epoch&#39;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
            <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
            <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">accuracy</span><span class="p">,</span>
            <span class="s1">&#39;weights&#39;</span><span class="p">:</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">weights</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
            <span class="s1">&#39;gradients&#39;</span><span class="p">:</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">gradients</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
            <span class="s1">&#39;weight_norms&#39;</span><span class="p">:</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">weights</span><span class="o">.</span><span class="n">items</span><span class="p">()},</span>
            <span class="s1">&#39;gradient_norms&#39;</span><span class="p">:</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">gradients</span><span class="o">.</span><span class="n">items</span><span class="p">()}</span>
        <span class="p">}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_logs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">log_entry</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">analyze_convergence</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Analyze convergence patterns in training.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_logs</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">{}</span>

        <span class="n">losses</span> <span class="o">=</span> <span class="p">[</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">log</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_logs</span><span class="p">]</span>
        <span class="n">accuracies</span> <span class="o">=</span> <span class="p">[</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">log</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_logs</span><span class="p">]</span>

        <span class="c1">## Find convergence point (where loss stops decreasing significantly)</span>

        <span class="n">convergence_epoch</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="n">loss_threshold</span> <span class="o">=</span> <span class="mf">0.001</span>  <span class="c1"># Minimum loss decrease to consider significant</span>

        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">)):</span>
            <span class="n">recent_improvement</span> <span class="o">=</span> <span class="n">losses</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">10</span><span class="p">]</span> <span class="o">-</span> <span class="n">losses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">recent_improvement</span> <span class="o">&lt;</span> <span class="n">loss_threshold</span><span class="p">:</span>
                <span class="n">convergence_epoch</span> <span class="o">=</span> <span class="n">i</span>
                <span class="k">break</span>

        <span class="c1">## Analyze weight evolution</span>

        <span class="n">weight_evolution</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">weight_name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_logs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;weights&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">weight_norms</span> <span class="o">=</span> <span class="p">[</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;weight_norms&#39;</span><span class="p">][</span><span class="n">weight_name</span><span class="p">]</span> <span class="k">for</span> <span class="n">log</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_logs</span><span class="p">]</span>
            <span class="n">weight_evolution</span><span class="p">[</span><span class="n">weight_name</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;initial_norm&#39;</span><span class="p">:</span> <span class="n">weight_norms</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="s1">&#39;final_norm&#39;</span><span class="p">:</span> <span class="n">weight_norms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                <span class="s1">&#39;change_ratio&#39;</span><span class="p">:</span> <span class="n">weight_norms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">weight_norms</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">if</span> <span class="n">weight_norms</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span>
            <span class="p">}</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;convergence_epoch&#39;</span><span class="p">:</span> <span class="n">convergence_epoch</span><span class="p">,</span>
            <span class="s1">&#39;final_loss&#39;</span><span class="p">:</span> <span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
            <span class="s1">&#39;final_accuracy&#39;</span><span class="p">:</span> <span class="n">accuracies</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
            <span class="s1">&#39;loss_reduction&#39;</span><span class="p">:</span> <span class="n">losses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">-</span> <span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
            <span class="s1">&#39;weight_evolution&#39;</span><span class="p">:</span> <span class="n">weight_evolution</span><span class="p">,</span>
            <span class="s1">&#39;training_stable&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">losses</span><span class="p">[</span><span class="o">-</span><span class="mi">10</span><span class="p">:])</span> <span class="o">&lt;</span> <span class="mf">0.01</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">losses</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">10</span> <span class="k">else</span> <span class="kc">False</span>
        <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_training_dynamics</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Get training dynamics for visualization.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;epochs&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">log</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_logs</span><span class="p">],</span>
            <span class="s1">&#39;losses&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">log</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_logs</span><span class="p">],</span>
            <span class="s1">&#39;accuracies&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">log</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_logs</span><span class="p">],</span>
            <span class="s1">&#39;weight_norms&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="n">name</span><span class="p">:</span> <span class="p">[</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;weight_norms&#39;</span><span class="p">][</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">log</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_logs</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_logs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;weight_norms&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
            <span class="p">},</span>
            <span class="s1">&#39;gradient_norms&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="n">name</span><span class="p">:</span> <span class="p">[</span><span class="n">log</span><span class="p">[</span><span class="s1">&#39;gradient_norms&#39;</span><span class="p">][</span><span class="n">name</span><span class="p">]</span> <span class="k">for</span> <span class="n">log</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_logs</span><span class="p">]</span>
                <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_logs</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s1">&#39;gradient_norms&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">keys</span><span class="p">()</span>
            <span class="p">}</span>
        <span class="p">}</span>

<span class="k">class</span><span class="w"> </span><span class="nc">InstrumentedTinyMLP</span><span class="p">(</span><span class="n">TinyMLP</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Extended TinyMLP with detailed training analysis capabilities.</span>
<span class="sd">    Logs training dynamics for educational insight.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">analyzer</span> <span class="o">=</span> <span class="n">TrainingAnalyzer</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">train_epoch_instrumented</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">epoch</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Enhanced training epoch with detailed logging.&quot;&quot;&quot;</span>

        <span class="c1">## Forward pass</span>

        <span class="n">cache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">forward_pass</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="s1">&#39;a2&#39;</span><span class="p">]</span>

        <span class="c1">## Compute loss</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_loss</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1">## Backward pass</span>

        <span class="n">gradients</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">backward_pass</span><span class="p">(</span><span class="n">cache</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>

        <span class="c1">## Log before weight update</span>

        <span class="n">weights</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;W1&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">W1</span><span class="p">,</span> <span class="s1">&#39;b1&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="p">,</span> <span class="s1">&#39;W2&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">W2</span><span class="p">,</span> <span class="s1">&#39;b2&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span><span class="p">}</span>

        <span class="c1">## Compute accuracy</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_size</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">((</span><span class="n">predictions</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">==</span> <span class="p">(</span><span class="n">y</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">predicted_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">predictions</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="n">true_classes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mi">1</span> <span class="k">else</span> <span class="n">y</span>
            <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predicted_classes</span> <span class="o">==</span> <span class="n">true_classes</span><span class="p">)</span>

        <span class="c1">## Log training step</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">analyzer</span><span class="o">.</span><span class="n">log_training_step</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">gradients</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">accuracy</span><span class="p">)</span>

        <span class="c1">## Update weights</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">update_weights</span><span class="p">(</span><span class="n">gradients</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="n">loss</span><span class="p">,</span>
            <span class="s1">&#39;accuracy&#39;</span><span class="p">:</span> <span class="n">accuracy</span><span class="p">,</span>
            <span class="s1">&#39;predictions&#39;</span><span class="p">:</span> <span class="n">predictions</span>
        <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">fit_with_analysis</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Train with detailed analysis logging.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
            <span class="n">epoch_stats</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_epoch_instrumented</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
            <span class="n">epoch_stats</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">epoch_stats</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">verbose</span> <span class="ow">and</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">//</span> <span class="mi">10</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Epoch </span><span class="si">{</span><span class="n">epoch</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">:</span><span class="s2">3d</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">epochs</span><span class="si">}</span><span class="s2">: Loss = </span><span class="si">{</span><span class="n">epoch_stats</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">, Accuracy = </span><span class="si">{</span><span class="n">epoch_stats</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">trained</span> <span class="o">=</span> <span class="kc">True</span>

        <span class="c1">## Analyze training</span>

        <span class="n">convergence_analysis</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">analyzer</span><span class="o">.</span><span class="n">analyze_convergence</span><span class="p">()</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;training_history&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">,</span>
            <span class="s1">&#39;final_loss&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;loss&#39;</span><span class="p">],</span>
            <span class="s1">&#39;final_accuracy&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">training_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;accuracy&#39;</span><span class="p">],</span>
            <span class="s1">&#39;convergence_analysis&#39;</span><span class="p">:</span> <span class="n">convergence_analysis</span>
        <span class="p">}</span>

<span class="k">def</span><span class="w"> </span><span class="nf">demonstrate_training_loop_intuition</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Demonstrate training loop dynamics and intuition.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Training Loop Intuition Demonstration&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">37</span><span class="p">)</span>

    <span class="c1">## Example 1: Weight Evolution During Training</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">1. Weight Evolution Analysis&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">28</span><span class="p">)</span>

    <span class="c1">## Use XOR problem with detailed analysis</span>

    <span class="n">X_xor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">y_xor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]])</span>

    <span class="c1">## Create instrumented MLP</span>

    <span class="n">mlp_analyzed</span> <span class="o">=</span> <span class="n">InstrumentedTinyMLP</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">2.0</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training XOR with weight analysis...&quot;</span><span class="p">)</span>
    <span class="n">analysis_results</span> <span class="o">=</span> <span class="n">mlp_analyzed</span><span class="o">.</span><span class="n">fit_with_analysis</span><span class="p">(</span><span class="n">X_xor</span><span class="p">,</span> <span class="n">y_xor</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">300</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1">## Display convergence analysis</span>

    <span class="n">convergence</span> <span class="o">=</span> <span class="n">analysis_results</span><span class="p">[</span><span class="s1">&#39;convergence_analysis&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Convergence Analysis:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Converged at epoch: </span><span class="si">{</span><span class="n">convergence</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;convergence_epoch&#39;</span><span class="p">,</span><span class="w"> </span><span class="s1">&#39;Not converged&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Final loss: </span><span class="si">{</span><span class="n">convergence</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Loss reduction: </span><span class="si">{</span><span class="n">convergence</span><span class="p">[</span><span class="s1">&#39;loss_reduction&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Training stable: </span><span class="si">{</span><span class="n">convergence</span><span class="p">[</span><span class="s1">&#39;training_stable&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Weight evolution</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Weight Evolution:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">weight_name</span><span class="p">,</span> <span class="n">evolution</span> <span class="ow">in</span> <span class="n">convergence</span><span class="p">[</span><span class="s1">&#39;weight_evolution&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">weight_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">evolution</span><span class="p">[</span><span class="s1">&#39;initial_norm&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> → </span><span class="si">{</span><span class="n">evolution</span><span class="p">[</span><span class="s1">&#39;final_norm&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;(ratio: </span><span class="si">{</span><span class="n">evolution</span><span class="p">[</span><span class="s1">&#39;change_ratio&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

    <span class="c1">## Example 2: Learning Rate Impact</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">2. Learning Rate Impact&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">24</span><span class="p">)</span>

    <span class="n">learning_rates</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mf">5.0</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">]</span>
    <span class="n">lr_results</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">lr</span> <span class="ow">in</span> <span class="n">learning_rates</span><span class="p">:</span>
        <span class="n">mlp_lr</span> <span class="o">=</span> <span class="n">TinyMLP</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>

        <span class="c1">## Train with current learning rate</span>

        <span class="n">lr_stats</span> <span class="o">=</span> <span class="n">mlp_lr</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_xor</span><span class="p">,</span> <span class="n">y_xor</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="n">lr_results</span><span class="p">[</span><span class="n">lr</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;final_loss&#39;</span><span class="p">:</span> <span class="n">lr_stats</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">],</span>
            <span class="s1">&#39;final_accuracy&#39;</span><span class="p">:</span> <span class="n">lr_stats</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">],</span>
            <span class="s1">&#39;converged&#39;</span><span class="p">:</span> <span class="n">lr_stats</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.1</span>
        <span class="p">}</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Learning Rate Impact on XOR Learning:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  LR     | Final Loss | Accuracy | Converged&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  -------|------------|----------|----------&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">lr</span><span class="p">,</span> <span class="n">results</span> <span class="ow">in</span> <span class="n">lr_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">converged_str</span> <span class="o">=</span> <span class="s2">&quot;Yes&quot;</span> <span class="k">if</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;converged&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="s2">&quot;No&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">lr</span><span class="si">:</span><span class="s2">5.1f</span><span class="si">}</span><span class="s2">  |   </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">6.3f</span><span class="si">}</span><span class="s2">   |  </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">6.3f</span><span class="si">}</span><span class="s2">  |    </span><span class="si">{</span><span class="n">converged_str</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Example 3: Hidden Layer Size Impact</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">3. Hidden Layer Size Impact&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">29</span><span class="p">)</span>

    <span class="n">hidden_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">16</span><span class="p">]</span>
    <span class="n">size_results</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">hidden_size</span> <span class="ow">in</span> <span class="n">hidden_sizes</span><span class="p">:</span>
        <span class="n">mlp_size</span> <span class="o">=</span> <span class="n">TinyMLP</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

        <span class="n">size_stats</span> <span class="o">=</span> <span class="n">mlp_size</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_xor</span><span class="p">,</span> <span class="n">y_xor</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="c1">## Count parameters</span>

        <span class="n">total_params</span> <span class="o">=</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">hidden_size</span> <span class="o">+</span> <span class="n">hidden_size</span><span class="p">)</span> <span class="o">+</span> <span class="p">(</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

        <span class="n">size_results</span><span class="p">[</span><span class="n">hidden_size</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;final_loss&#39;</span><span class="p">:</span> <span class="n">size_stats</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">],</span>
            <span class="s1">&#39;final_accuracy&#39;</span><span class="p">:</span> <span class="n">size_stats</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">],</span>
            <span class="s1">&#39;total_params&#39;</span><span class="p">:</span> <span class="n">total_params</span><span class="p">,</span>
            <span class="s1">&#39;converged&#39;</span><span class="p">:</span> <span class="n">size_stats</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.1</span>
        <span class="p">}</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Hidden Layer Size Impact:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Size | Params | Final Loss | Accuracy | Converged&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  -----|--------|------------|----------|----------&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">size</span><span class="p">,</span> <span class="n">results</span> <span class="ow">in</span> <span class="n">size_results</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">converged_str</span> <span class="o">=</span> <span class="s2">&quot;Yes&quot;</span> <span class="k">if</span> <span class="n">results</span><span class="p">[</span><span class="s1">&#39;converged&#39;</span><span class="p">]</span> <span class="k">else</span> <span class="s2">&quot;No&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">size</span><span class="si">:</span><span class="s2">3d</span><span class="si">}</span><span class="s2">  |   </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;total_params&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">3d</span><span class="si">}</span><span class="s2">  |   </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">6.3f</span><span class="si">}</span><span class="s2">   |  </span><span class="si">{</span><span class="n">results</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">6.3f</span><span class="si">}</span><span class="s2">  |    </span><span class="si">{</span><span class="n">converged_str</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Example 4: Training Dynamics Visualization (text-based)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">4. Training Dynamics Analysis&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">31</span><span class="p">)</span>

    <span class="c1">## Get training dynamics from analyzed MLP</span>

    <span class="n">dynamics</span> <span class="o">=</span> <span class="n">mlp_analyzed</span><span class="o">.</span><span class="n">analyzer</span><span class="o">.</span><span class="n">get_training_dynamics</span><span class="p">()</span>

    <span class="c1">## Show loss progression (every 30 epochs)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Loss Progression (every 30 epochs):&quot;</span><span class="p">)</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="n">dynamics</span><span class="p">[</span><span class="s1">&#39;epochs&#39;</span><span class="p">]</span>
    <span class="n">losses</span> <span class="o">=</span> <span class="n">dynamics</span><span class="p">[</span><span class="s1">&#39;losses&#39;</span><span class="p">]</span>

    <span class="n">step</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">epochs</span><span class="p">)</span> <span class="o">//</span> <span class="mi">10</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Epoch | Loss&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  ------|-------&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">epochs</span><span class="p">),</span> <span class="n">step</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">epochs</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">5d</span><span class="si">}</span><span class="s2"> | </span><span class="si">{</span><span class="n">losses</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Weight norm evolution</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Weight Norm Evolution:&quot;</span><span class="p">)</span>
    <span class="n">weight_norms</span> <span class="o">=</span> <span class="n">dynamics</span><span class="p">[</span><span class="s1">&#39;weight_norms&#39;</span><span class="p">]</span>

    <span class="k">for</span> <span class="n">weight_name</span><span class="p">,</span> <span class="n">norms</span> <span class="ow">in</span> <span class="n">weight_norms</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="n">initial_norm</span> <span class="o">=</span> <span class="n">norms</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">final_norm</span> <span class="o">=</span> <span class="n">norms</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">max_norm</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">norms</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">weight_name</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">initial_norm</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> → </span><span class="si">{</span><span class="n">final_norm</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> (max: </span><span class="si">{</span><span class="n">max_norm</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

    <span class="c1">## Example 5: Common Training Issues</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">5. Common Training Issues&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">26</span><span class="p">)</span>

    <span class="c1">## Issue 1: Learning rate too high (oscillation)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;a) Learning Rate Too High (Oscillation):&quot;</span><span class="p">)</span>
    <span class="n">mlp_oscillate</span> <span class="o">=</span> <span class="n">TinyMLP</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">20.0</span><span class="p">)</span>
    <span class="n">osc_stats</span> <span class="o">=</span> <span class="n">mlp_oscillate</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_xor</span><span class="p">,</span> <span class="n">y_xor</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="n">losses_osc</span> <span class="o">=</span> <span class="p">[</span><span class="n">stats</span><span class="p">[</span><span class="s1">&#39;loss&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">stats</span> <span class="ow">in</span> <span class="n">mlp_oscillate</span><span class="o">.</span><span class="n">training_history</span><span class="p">]</span>
    <span class="n">loss_variance</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">losses_osc</span><span class="p">[</span><span class="o">-</span><span class="mi">20</span><span class="p">:])</span> <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">losses_osc</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">20</span> <span class="k">else</span> <span class="mi">0</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Final loss: </span><span class="si">{</span><span class="n">osc_stats</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Loss variance (last 20 epochs): </span><span class="si">{</span><span class="n">loss_variance</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Diagnosis: </span><span class="si">{</span><span class="s1">&#39;Oscillating&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">loss_variance</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">0.1</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;Stable&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Issue 2: Learning rate too low (slow convergence)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">b) Learning Rate Too Low (Slow Convergence):&quot;</span><span class="p">)</span>
    <span class="n">mlp_slow</span> <span class="o">=</span> <span class="n">TinyMLP</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
    <span class="n">slow_stats</span> <span class="o">=</span> <span class="n">mlp_slow</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_xor</span><span class="p">,</span> <span class="n">y_xor</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Final loss: </span><span class="si">{</span><span class="n">slow_stats</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Final accuracy: </span><span class="si">{</span><span class="n">slow_stats</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Diagnosis: </span><span class="si">{</span><span class="s1">&#39;Needs more epochs&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">slow_stats</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">]</span><span class="w"> </span><span class="o">&gt;</span><span class="w"> </span><span class="mf">0.5</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;Adequate&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Issue 3: Insufficient capacity</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">c) Insufficient Network Capacity:&quot;</span><span class="p">)</span>
    <span class="n">mlp_small</span> <span class="o">=</span> <span class="n">TinyMLP</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>
    <span class="n">small_stats</span> <span class="o">=</span> <span class="n">mlp_small</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_xor</span><span class="p">,</span> <span class="n">y_xor</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Final loss: </span><span class="si">{</span><span class="n">small_stats</span><span class="p">[</span><span class="s1">&#39;final_loss&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.4f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Final accuracy: </span><span class="si">{</span><span class="n">small_stats</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Diagnosis: </span><span class="si">{</span><span class="s1">&#39;Insufficient capacity&#39;</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="n">small_stats</span><span class="p">[</span><span class="s1">&#39;final_accuracy&#39;</span><span class="p">]</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="mf">0.8</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="s1">&#39;Adequate&#39;</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">mlp_analyzed</span><span class="p">,</span> <span class="n">lr_results</span><span class="p">,</span> <span class="n">size_results</span>
</code></pre>
</div>
<hr />
<h2 id="part-4-practical-applications-and-behavior-reasoning">Part 4: Practical Applications and Behavior Reasoning<a class="headerlink" href="#part-4-practical-applications-and-behavior-reasoning" title="Permanent link">&para;</a></h2>
<h3 id="understanding-neural-network-behavior">Understanding Neural Network Behavior<a class="headerlink" href="#understanding-neural-network-behavior" title="Permanent link">&para;</a></h3>
<p>To effectively use neural networks in automation systems, we must understand how they make decisions, what patterns they learn, and how to interpret their behavior.</p>
<p><strong>Key Behavioral Concepts:</strong></p>
<ul>
<li>
<p><strong>Feature Learning</strong>: Hidden layers learn useful representations</p>
</li>
<li>
<p><strong>Decision Boundaries</strong>: Networks create complex decision regions</p>
</li>
<li>
<p><strong><span class="glossary-term" data-glossary-category="OOP" data-glossary-definition="The process of extracting common characteristics from specific instances to create more abstract classes in object-oriented design." data-glossary-term="Generalisation">Generalization</span></strong>: Ability to perform well on unseen data</p>
</li>
<li>
<p><strong>Interpretability</strong>: Understanding what the network has learned</p>
</li>
</ul>
<h3 id="behavior-analysis-tools">Behavior Analysis Tools<a class="headerlink" href="#behavior-analysis-tools" title="Permanent link">&para;</a></h3>
<div class="highlight python-template" data-fence-type="template" data-language="python">
<pre><code class="language-python"><span class="k">class</span><span class="w"> </span><span class="nc">NetworkBehaviorAnalyzer</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Tools for understanding and interpreting neural network behavior.</span>
<span class="sd">    Helps reason about what networks learn and how they make decisions.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">mlp</span><span class="p">:</span> <span class="n">TinyMLP</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span> <span class="o">=</span> <span class="n">mlp</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">analyze_hidden_layer_activations</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Analyze what the hidden layer learns by examining activations.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: Input data to analyze</span>

<span class="sd">        Returns:</span>
<span class="sd">            Analysis of hidden layer behavior</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">trained</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;MLP must be trained before analysis&quot;</span><span class="p">)</span>

        <span class="c1">## Get hidden layer activations</span>

        <span class="n">cache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">forward_pass</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="n">hidden_activations</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="s1">&#39;a1&#39;</span><span class="p">]</span>

        <span class="c1">## Analyze each hidden neuron</span>

        <span class="n">neuron_analysis</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hidden_activations</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">neuron_i_activations</span> <span class="o">=</span> <span class="n">hidden_activations</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>

            <span class="n">neuron_analysis</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;neuron_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;mean_activation&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">neuron_i_activations</span><span class="p">),</span>
                <span class="s1">&#39;activation_range&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">neuron_i_activations</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">neuron_i_activations</span><span class="p">)],</span>
                <span class="s1">&#39;activation_variance&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">neuron_i_activations</span><span class="p">),</span>
                <span class="s1">&#39;never_activates&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">neuron_i_activations</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mf">0.1</span><span class="p">,</span>
                <span class="s1">&#39;always_saturated&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">neuron_i_activations</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mf">0.9</span>
            <span class="p">}</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;hidden_activations&#39;</span><span class="p">:</span> <span class="n">hidden_activations</span><span class="p">,</span>
            <span class="s1">&#39;neuron_analysis&#39;</span><span class="p">:</span> <span class="n">neuron_analysis</span><span class="p">,</span>
            <span class="s1">&#39;num_dead_neurons&#39;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">analysis</span> <span class="ow">in</span> <span class="n">neuron_analysis</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> 
                                   <span class="k">if</span> <span class="n">analysis</span><span class="p">[</span><span class="s1">&#39;never_activates&#39;</span><span class="p">]),</span>
            <span class="s1">&#39;num_saturated_neurons&#39;</span><span class="p">:</span> <span class="nb">sum</span><span class="p">(</span><span class="mi">1</span> <span class="k">for</span> <span class="n">analysis</span> <span class="ow">in</span> <span class="n">neuron_analysis</span><span class="o">.</span><span class="n">values</span><span class="p">()</span> 
                                        <span class="k">if</span> <span class="n">analysis</span><span class="p">[</span><span class="s1">&#39;always_saturated&#39;</span><span class="p">])</span>
        <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">analyze_weight_patterns</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Analyze learned weight patterns for insights.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">trained</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;MLP must be trained before analysis&quot;</span><span class="p">)</span>

        <span class="c1">## Input to hidden weights analysis</span>

        <span class="n">W1_analysis</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;weight_matrix_shape&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">W1</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
            <span class="s1">&#39;weight_statistics&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">W1</span><span class="p">),</span>
                <span class="s1">&#39;std&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">W1</span><span class="p">),</span>
                <span class="s1">&#39;min&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">W1</span><span class="p">),</span>
                <span class="s1">&#39;max&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">W1</span><span class="p">)</span>
            <span class="p">},</span>
            <span class="s1">&#39;neuron_weight_norms&#39;</span><span class="p">:</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">W1</span><span class="p">[:,</span> <span class="n">i</span><span class="p">])</span> 
                                   <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">W1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
        <span class="p">}</span>

        <span class="c1">## Hidden to output weights analysis</span>

        <span class="n">W2_analysis</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s1">&#39;weight_vector_shape&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">W2</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span>
            <span class="s1">&#39;weight_statistics&#39;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s1">&#39;mean&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">W2</span><span class="p">),</span>
                <span class="s1">&#39;std&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">W2</span><span class="p">),</span>
                <span class="s1">&#39;min&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">W2</span><span class="p">),</span>
                <span class="s1">&#39;max&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">W2</span><span class="p">)</span>
            <span class="p">}</span>
        <span class="p">}</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;input_to_hidden&#39;</span><span class="p">:</span> <span class="n">W1_analysis</span><span class="p">,</span>
            <span class="s1">&#39;hidden_to_output&#39;</span><span class="p">:</span> <span class="n">W2_analysis</span>
        <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">create_decision_boundary_analysis</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">resolution</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">50</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create a grid analysis to understand decision boundaries.</span>

<span class="sd">        Args:</span>
<span class="sd">            X: Training data to determine grid bounds</span>
<span class="sd">            resolution: Grid resolution for analysis</span>

<span class="sd">        Returns:</span>
<span class="sd">            Decision boundary analysis</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">!=</span> <span class="mi">2</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Decision boundary analysis only supported for 2D input&quot;</span><span class="p">)</span>

        <span class="c1">## Create grid</span>

        <span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="n">xx</span><span class="p">,</span> <span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span>
            <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">x_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">resolution</span><span class="p">),</span>
            <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">y_min</span><span class="p">,</span> <span class="n">y_max</span><span class="p">,</span> <span class="n">resolution</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="c1">## Get predictions for grid points</span>

        <span class="n">grid_points</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">column_stack</span><span class="p">([</span><span class="n">xx</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">yy</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">grid_points</span><span class="p">)</span>

        <span class="c1">## Reshape predictions to grid</span>

        <span class="n">prediction_grid</span> <span class="o">=</span> <span class="n">predictions</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">xx</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;x_grid&#39;</span><span class="p">:</span> <span class="n">xx</span><span class="p">,</span>
            <span class="s1">&#39;y_grid&#39;</span><span class="p">:</span> <span class="n">yy</span><span class="p">,</span>
            <span class="s1">&#39;prediction_grid&#39;</span><span class="p">:</span> <span class="n">prediction_grid</span><span class="p">,</span>
            <span class="s1">&#39;decision_boundary_complexity&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">prediction_grid</span><span class="p">)</span>
        <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">interpret_xor_solution</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_xor</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y_xor</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Specific analysis for XOR problem to understand how MLP solves it.</span>

<span class="sd">        Args:</span>
<span class="sd">            X_xor: XOR input data</span>
<span class="sd">            y_xor: XOR target data</span>

<span class="sd">        Returns:</span>
<span class="sd">            Interpretation of XOR solution</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">trained</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;MLP must be trained before analysis&quot;</span><span class="p">)</span>

        <span class="c1">## Get hidden layer activations for XOR inputs</span>

        <span class="n">cache</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mlp</span><span class="o">.</span><span class="n">forward_pass</span><span class="p">(</span><span class="n">X_xor</span><span class="p">)</span>
        <span class="n">hidden_activations</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="s1">&#39;a1&#39;</span><span class="p">]</span>
        <span class="n">final_outputs</span> <span class="o">=</span> <span class="n">cache</span><span class="p">[</span><span class="s1">&#39;a2&#39;</span><span class="p">]</span>

        <span class="c1">## Analyze how each hidden neuron responds to XOR inputs</span>

        <span class="n">neuron_responses</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">hidden_activations</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">responses</span> <span class="o">=</span> <span class="n">hidden_activations</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>
            <span class="n">neuron_responses</span><span class="p">[</span><span class="sa">f</span><span class="s1">&#39;hidden_neuron_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s1">&#39;input_00&#39;</span><span class="p">:</span> <span class="n">responses</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
                <span class="s1">&#39;input_01&#39;</span><span class="p">:</span> <span class="n">responses</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
                <span class="s1">&#39;input_10&#39;</span><span class="p">:</span> <span class="n">responses</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
                <span class="s1">&#39;input_11&#39;</span><span class="p">:</span> <span class="n">responses</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span>
                <span class="s1">&#39;pattern_type&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_classify_xor_pattern</span><span class="p">(</span><span class="n">responses</span><span class="p">)</span>
            <span class="p">}</span>

        <span class="k">return</span> <span class="p">{</span>
            <span class="s1">&#39;hidden_responses&#39;</span><span class="p">:</span> <span class="n">neuron_responses</span><span class="p">,</span>
            <span class="s1">&#39;final_outputs&#39;</span><span class="p">:</span> <span class="n">final_outputs</span><span class="o">.</span><span class="n">flatten</span><span class="p">(),</span>
            <span class="s1">&#39;solution_interpretation&#39;</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_interpret_xor_strategy</span><span class="p">(</span><span class="n">neuron_responses</span><span class="p">)</span>
        <span class="p">}</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_classify_xor_pattern</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">responses</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Classify the pattern learned by a hidden neuron.&quot;&quot;&quot;</span>

        <span class="c1">## Check for common XOR decomposition patterns</span>

        <span class="k">if</span> <span class="n">responses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">responses</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">responses</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">responses</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;XOR-like&quot;</span>
        <span class="k">elif</span> <span class="n">responses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">responses</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">responses</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">responses</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;XNOR-like&quot;</span>
        <span class="k">elif</span> <span class="n">responses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">responses</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">responses</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">responses</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;OR-like&quot;</span>
        <span class="k">elif</span> <span class="n">responses</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">responses</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">responses</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.5</span> <span class="ow">and</span> <span class="n">responses</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;AND-like&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;Complex&quot;</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_interpret_xor_strategy</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">neuron_responses</span><span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Interpret the overall strategy used to solve XOR.&quot;&quot;&quot;</span>
        <span class="n">patterns</span> <span class="o">=</span> <span class="p">[</span><span class="n">info</span><span class="p">[</span><span class="s1">&#39;pattern_type&#39;</span><span class="p">]</span> <span class="k">for</span> <span class="n">info</span> <span class="ow">in</span> <span class="n">neuron_responses</span><span class="o">.</span><span class="n">values</span><span class="p">()]</span>

        <span class="k">if</span> <span class="s1">&#39;XOR-like&#39;</span> <span class="ow">in</span> <span class="n">patterns</span> <span class="ow">or</span> <span class="s1">&#39;XNOR-like&#39;</span> <span class="ow">in</span> <span class="n">patterns</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;Direct XOR decomposition&quot;</span>
        <span class="k">elif</span> <span class="s1">&#39;OR-like&#39;</span> <span class="ow">in</span> <span class="n">patterns</span> <span class="ow">and</span> <span class="s1">&#39;AND-like&#39;</span> <span class="ow">in</span> <span class="n">patterns</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;OR/AND combination strategy&quot;</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="s2">&quot;Complex non-linear combination&quot;</span>

<span class="k">def</span><span class="w"> </span><span class="nf">demonstrate_behavior_reasoning</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Demonstrate neural network behavior analysis and reasoning.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Neural Network Behavior Reasoning&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">35</span><span class="p">)</span>

    <span class="c1">## Example 1: XOR Solution Analysis</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">1. XOR Solution Analysis&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">25</span><span class="p">)</span>

    <span class="c1">## Train MLP on XOR</span>

    <span class="n">X_xor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>
    <span class="n">y_xor</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">]])</span>

    <span class="n">mlp_xor_analysis</span> <span class="o">=</span> <span class="n">TinyMLP</span><span class="p">(</span><span class="n">input_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1.5</span><span class="p">)</span>
    <span class="n">mlp_xor_analysis</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_xor</span><span class="p">,</span> <span class="n">y_xor</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="c1">## Analyze behavior</span>

    <span class="n">analyzer</span> <span class="o">=</span> <span class="n">NetworkBehaviorAnalyzer</span><span class="p">(</span><span class="n">mlp_xor_analysis</span><span class="p">)</span>

    <span class="c1">## Hidden layer activation analysis</span>

    <span class="n">activation_analysis</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">analyze_hidden_layer_activations</span><span class="p">(</span><span class="n">X_xor</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Hidden Layer Activation Analysis:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">neuron_name</span><span class="p">,</span> <span class="n">analysis</span> <span class="ow">in</span> <span class="n">activation_analysis</span><span class="p">[</span><span class="s1">&#39;neuron_analysis&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">neuron_name</span><span class="si">}</span><span class="s2">:&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    Mean activation: </span><span class="si">{</span><span class="n">analysis</span><span class="p">[</span><span class="s1">&#39;mean_activation&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    Activation range: [</span><span class="si">{</span><span class="n">analysis</span><span class="p">[</span><span class="s1">&#39;activation_range&#39;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">analysis</span><span class="p">[</span><span class="s1">&#39;activation_range&#39;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    Dead neuron: </span><span class="si">{</span><span class="n">analysis</span><span class="p">[</span><span class="s1">&#39;never_activates&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    Saturated: </span><span class="si">{</span><span class="n">analysis</span><span class="p">[</span><span class="s1">&#39;always_saturated&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Network Health:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Dead neurons: </span><span class="si">{</span><span class="n">activation_analysis</span><span class="p">[</span><span class="s1">&#39;num_dead_neurons&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Saturated neurons: </span><span class="si">{</span><span class="n">activation_analysis</span><span class="p">[</span><span class="s1">&#39;num_saturated_neurons&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## XOR-specific interpretation</span>

    <span class="n">xor_interpretation</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">interpret_xor_solution</span><span class="p">(</span><span class="n">X_xor</span><span class="p">,</span> <span class="n">y_xor</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">XOR Solution Strategy:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">xor_interpretation</span><span class="p">[</span><span class="s1">&#39;solution_interpretation&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Hidden Neuron Patterns:&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">neuron</span><span class="p">,</span> <span class="n">response</span> <span class="ow">in</span> <span class="n">xor_interpretation</span><span class="p">[</span><span class="s1">&#39;hidden_responses&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">neuron</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;pattern_type&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;    Responses: [0,0]→</span><span class="si">{</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;input_00&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, [0,1]→</span><span class="si">{</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;input_01&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, &quot;</span>
              <span class="sa">f</span><span class="s2">&quot;[1,0]→</span><span class="si">{</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;input_10&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, [1,1]→</span><span class="si">{</span><span class="n">response</span><span class="p">[</span><span class="s1">&#39;input_11&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Example 2: Weight Pattern Analysis</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">2. Weight Pattern Analysis&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">26</span><span class="p">)</span>

    <span class="n">weight_analysis</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">analyze_weight_patterns</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Input-to-Hidden Weights:&quot;</span><span class="p">)</span>
    <span class="n">W1_stats</span> <span class="o">=</span> <span class="n">weight_analysis</span><span class="p">[</span><span class="s1">&#39;input_to_hidden&#39;</span><span class="p">][</span><span class="s1">&#39;weight_statistics&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Shape: </span><span class="si">{</span><span class="n">weight_analysis</span><span class="p">[</span><span class="s1">&#39;input_to_hidden&#39;</span><span class="p">][</span><span class="s1">&#39;weight_matrix_shape&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Mean: </span><span class="si">{</span><span class="n">W1_stats</span><span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, Std: </span><span class="si">{</span><span class="n">W1_stats</span><span class="p">[</span><span class="s1">&#39;std&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Range: [</span><span class="si">{</span><span class="n">W1_stats</span><span class="p">[</span><span class="s1">&#39;min&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">W1_stats</span><span class="p">[</span><span class="s1">&#39;max&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Hidden-to-Output Weights:&quot;</span><span class="p">)</span>
    <span class="n">W2_stats</span> <span class="o">=</span> <span class="n">weight_analysis</span><span class="p">[</span><span class="s1">&#39;hidden_to_output&#39;</span><span class="p">][</span><span class="s1">&#39;weight_statistics&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Shape: </span><span class="si">{</span><span class="n">weight_analysis</span><span class="p">[</span><span class="s1">&#39;hidden_to_output&#39;</span><span class="p">][</span><span class="s1">&#39;weight_vector_shape&#39;</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Mean: </span><span class="si">{</span><span class="n">W2_stats</span><span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, Std: </span><span class="si">{</span><span class="n">W2_stats</span><span class="p">[</span><span class="s1">&#39;std&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Range: [</span><span class="si">{</span><span class="n">W2_stats</span><span class="p">[</span><span class="s1">&#39;min&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">W2_stats</span><span class="p">[</span><span class="s1">&#39;max&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">]&quot;</span><span class="p">)</span>

    <span class="c1">## Neuron importance based on weight norms</span>

    <span class="n">neuron_norms</span> <span class="o">=</span> <span class="n">weight_analysis</span><span class="p">[</span><span class="s1">&#39;input_to_hidden&#39;</span><span class="p">][</span><span class="s1">&#39;neuron_weight_norms&#39;</span><span class="p">]</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Neuron Importance (by weight norm):&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">norm</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">neuron_norms</span><span class="p">):</span>
        <span class="n">importance</span> <span class="o">=</span> <span class="s2">&quot;High&quot;</span> <span class="k">if</span> <span class="n">norm</span> <span class="o">&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">neuron_norms</span><span class="p">)</span> <span class="k">else</span> <span class="s2">&quot;Low&quot;</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Hidden neuron </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">norm</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">importance</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>

    <span class="c1">## Example 3: Generalization Analysis</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">3. Generalization Analysis&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">27</span><span class="p">)</span>

    <span class="c1">## Test on noisy versions of XOR inputs</span>

    <span class="n">noise_levels</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">]</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Robustness to Input Noise:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  Noise | Accuracy&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;  ------|----------&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">noise_level</span> <span class="ow">in</span> <span class="n">noise_levels</span><span class="p">:</span>

        <span class="c1">## Add noise to XOR inputs</span>

        <span class="n">X_noisy</span> <span class="o">=</span> <span class="n">X_xor</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">noise_level</span><span class="p">,</span> <span class="n">X_xor</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">mlp_xor_analysis</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_noisy</span><span class="p">)</span>

        <span class="c1">## Calculate accuracy</span>

        <span class="n">predicted_classes</span> <span class="o">=</span> <span class="p">(</span><span class="n">predictions</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
        <span class="n">actual_classes</span> <span class="o">=</span> <span class="n">y_xor</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
        <span class="n">accuracy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">predicted_classes</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span> <span class="o">==</span> <span class="n">actual_classes</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  </span><span class="si">{</span><span class="n">noise_level</span><span class="si">:</span><span class="s2">5.1f</span><span class="si">}</span><span class="s2"> |  </span><span class="si">{</span><span class="n">accuracy</span><span class="si">:</span><span class="s2">6.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Example 4: Decision Boundary Complexity</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">4. Decision Boundary Analysis&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">30</span><span class="p">)</span>

    <span class="n">boundary_analysis</span> <span class="o">=</span> <span class="n">analyzer</span><span class="o">.</span><span class="n">create_decision_boundary_analysis</span><span class="p">(</span><span class="n">X_xor</span><span class="p">,</span> <span class="n">resolution</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Decision Boundary Complexity: </span><span class="si">{</span><span class="n">boundary_analysis</span><span class="p">[</span><span class="s1">&#39;decision_boundary_complexity&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Sample some points from decision boundary region</span>

    <span class="n">prediction_grid</span> <span class="o">=</span> <span class="n">boundary_analysis</span><span class="p">[</span><span class="s1">&#39;prediction_grid&#39;</span><span class="p">]</span>
    <span class="n">boundary_points</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">prediction_grid</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">prediction_grid</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]):</span>
            <span class="n">prediction</span> <span class="o">=</span> <span class="n">prediction_grid</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
            <span class="k">if</span> <span class="mf">0.4</span> <span class="o">&lt;</span> <span class="n">prediction</span> <span class="o">&lt;</span> <span class="mf">0.6</span><span class="p">:</span>  <span class="c1"># Near decision boundary</span>
                <span class="n">x</span> <span class="o">=</span> <span class="n">boundary_analysis</span><span class="p">[</span><span class="s1">&#39;x_grid&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">boundary_analysis</span><span class="p">[</span><span class="s1">&#39;y_grid&#39;</span><span class="p">][</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">]</span>
                <span class="n">boundary_points</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">prediction</span><span class="p">))</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Decision boundary points (prediction ≈ 0.5):&quot;</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">pred</span> <span class="ow">in</span> <span class="n">boundary_points</span><span class="p">[:</span><span class="mi">5</span><span class="p">]:</span>  <span class="c1"># Show first 5</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  (</span><span class="si">{</span><span class="n">x</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">y</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">) → </span><span class="si">{</span><span class="n">pred</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="c1">## Example 5: Feature Sensitivity Analysis</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">5. Feature Sensitivity Analysis&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">32</span><span class="p">)</span>

    <span class="c1">## Test sensitivity to each input feature</span>

    <span class="n">base_input</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]])</span>  <span class="c1"># Neutral point</span>
    <span class="n">base_prediction</span> <span class="o">=</span> <span class="n">mlp_xor_analysis</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">base_input</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

    <span class="n">feature_sensitivities</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">perturbation</span> <span class="o">=</span> <span class="mf">0.1</span>

    <span class="k">for</span> <span class="n">feature_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>

        <span class="c1">## Perturb feature positively</span>

        <span class="n">perturbed_input</span> <span class="o">=</span> <span class="n">base_input</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">perturbed_input</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">feature_idx</span><span class="p">]</span> <span class="o">+=</span> <span class="n">perturbation</span>
        <span class="n">pos_prediction</span> <span class="o">=</span> <span class="n">mlp_xor_analysis</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">perturbed_input</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="c1">## Perturb feature negatively</span>

        <span class="n">perturbed_input</span> <span class="o">=</span> <span class="n">base_input</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="n">perturbed_input</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="n">feature_idx</span><span class="p">]</span> <span class="o">-=</span> <span class="n">perturbation</span>
        <span class="n">neg_prediction</span> <span class="o">=</span> <span class="n">mlp_xor_analysis</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">perturbed_input</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>

        <span class="c1">## Calculate sensitivity</span>

        <span class="n">sensitivity</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">pos_prediction</span> <span class="o">-</span> <span class="n">neg_prediction</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">perturbation</span><span class="p">)</span>
        <span class="n">feature_sensitivities</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">sensitivity</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Feature </span><span class="si">{</span><span class="n">feature_idx</span><span class="si">}</span><span class="s2"> sensitivity: </span><span class="si">{</span><span class="n">sensitivity</span><span class="si">:</span><span class="s2">.3f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="n">most_important_feature</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">feature_sensitivities</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;  Most important feature: </span><span class="si">{</span><span class="n">most_important_feature</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">analyzer</span><span class="p">,</span> <span class="n">xor_interpretation</span><span class="p">,</span> <span class="n">weight_analysis</span>

<span class="c1">## Main demonstration function</span>

<span class="k">def</span><span class="w"> </span><span class="nf">run_all_neural_network_demonstrations</span><span class="p">():</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Run all neural network demonstrations.&quot;&quot;&quot;</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;🧠 NEURAL NETWORKS: CONCEPTS AND IMPLEMENTATION&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>

    <span class="c1">## Perceptron demonstrations</span>

    <span class="n">perceptron_models</span> <span class="o">=</span> <span class="n">demonstrate_perceptron</span><span class="p">()</span>

    <span class="c1">## MLP demonstrations</span>

    <span class="n">mlp_models</span> <span class="o">=</span> <span class="n">demonstrate_tiny_mlp</span><span class="p">()</span>

    <span class="c1">## Training loop intuition</span>

    <span class="n">training_analysis</span> <span class="o">=</span> <span class="n">demonstrate_training_loop_intuition</span><span class="p">()</span>

    <span class="c1">## Behavior reasoning</span>

    <span class="n">behavior_analysis</span> <span class="o">=</span> <span class="n">demonstrate_behavior_reasoning</span><span class="p">()</span>

    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="o">*</span><span class="mi">50</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;NEURAL NETWORK DEMONSTRATIONS COMPLETED&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Key concepts demonstrated:&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;• Perceptron: single-layer learning with limitations&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;• Multi-layer Perceptron: overcoming linear separability&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;• Training dynamics: weight evolution and convergence&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;• Behavior analysis: understanding what networks learn&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;• Practical insights: hyperparameter effects and debugging&quot;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;=&quot;</span> <span class="o">*</span> <span class="mi">50</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;perceptrons&quot;</span><span class="p">:</span> <span class="n">perceptron_models</span><span class="p">,</span>
        <span class="s2">&quot;mlps&quot;</span><span class="p">:</span> <span class="n">mlp_models</span><span class="p">,</span>
        <span class="s2">&quot;training_analysis&quot;</span><span class="p">:</span> <span class="n">training_analysis</span><span class="p">,</span>
        <span class="s2">&quot;behavior_analysis&quot;</span><span class="p">:</span> <span class="n">behavior_analysis</span>
    <span class="p">}</span>

<span class="k">if</span> <span class="vm">__name__</span> <span class="o">==</span> <span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">all_results</span> <span class="o">=</span> <span class="n">run_all_neural_network_demonstrations</span><span class="p">()</span>
</code></pre>
</div>
<h2 id="recap">Recap<a class="headerlink" href="#recap" title="Permanent link">&para;</a></h2>
<ul>
<li>
<p>Perceptron experiments show how linear decision boundaries work and why XOR highlights the need for hidden layers.</p>
</li>
<li>
<p>Multi-layer perceptrons add hidden units, non-linear activations, and backpropagation to solve complex patterns.</p>
</li>
<li>
<p>Training loop instrumentation demonstrates how learning rate, capacity, and gradient updates influence convergence.</p>
</li>
<li>
<p>Behaviour analysis techniques (activations, weight norms, decision boundaries) reveal what a trained network pays attention to and how robust it is.</p>
</li>
</ul>
<h2 id="summary">Summary<a class="headerlink" href="#summary" title="Permanent link">&para;</a></h2>
<p>Neural networks power modern automation by stacking simple units into layered systems that learn from data. Building perceptrons and tiny MLPs from scratch demystifies forward passes, loss <span class="glossary-term" data-glossary-category="Programming Fundamentals" data-glossary-definition="A reusable block of code that performs a specific task and returns a value to the caller." data-glossary-term="Function">functions</span>, and gradient-based updates. With careful training analysis and behaviour interpretation, developers can tune architectures confidently and explain how their automation models reach decisions.</p>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="October 27, 2025 08:50:09 UTC">October 27, 2025</span>
  </span>

    
    
    
    
  </aside>


  



  <form class="md-feedback" name="feedback" hidden>
    <fieldset>
      <legend class="md-feedback__title">
        Was this page helpful?
      </legend>
      <div class="md-feedback__inner">
        <div class="md-feedback__list">
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page was helpful" data-md-value="1">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m7 0c0 .8-.7 1.5-1.5 1.5S14 10.3 14 9.5 14.7 8 15.5 8s1.5.7 1.5 1.5m-5 7.73c-1.75 0-3.29-.73-4.19-1.81L9.23 14c.45.72 1.52 1.23 2.77 1.23s2.32-.51 2.77-1.23l1.42 1.42c-.9 1.08-2.44 1.81-4.19 1.81"/></svg>
            </button>
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page could be improved" data-md-value="0">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10m-6.5-4c.8 0 1.5.7 1.5 1.5s-.7 1.5-1.5 1.5-1.5-.7-1.5-1.5.7-1.5 1.5-1.5M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m2 4.5c1.75 0 3.29.72 4.19 1.81l-1.42 1.42C14.32 16.5 13.25 16 12 16s-2.32.5-2.77 1.23l-1.42-1.42C8.71 14.72 10.25 14 12 14"/></svg>
            </button>
          
        </div>
        <div class="md-feedback__note">
          
            <div data-md-value="1" hidden>
              
              
                
              
              
              
                
                
              
              Thanks for your feedback!
            </div>
          
            <div data-md-value="0" hidden>
              
              
                
              
              
              
                
                
              
              Thanks for your feedback! Help us improve this page by creating an <a href="https://github.com/Eatham532/Software-Engineering-HSC-Textbook/issues/new/choose" target="_blank" rel="noopener">issue</a> on github.
            </div>
          
        </div>
      </div>
    </fieldset>
  </form>


                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        

<!-- Footer -->
<footer class="md-footer">
  
    <!-- Custom footer with left/right layout -->
    <div class="md-footer__inner md-grid">
      <!-- Left side: Copyright and cookie settings -->
      <div class="md-footer__left">
        <div class="md-footer__copyright">
          
            Copyright &copy; 2025 Eatham532 – <a href="#__consent">Change cookie settings</a>

          
        </div>
      </div>

      <!-- Right side: Page name and BETA -->
      <div class="md-footer__right">
        <div class="md-footer__page-info">
          <span class="md-footer__page-title">Content</span>
          
            <span class="md-footer__beta-badge">BETA</span>
          
        </div>
      </div>
    </div>
  
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
      <div class="md-consent" data-md-component="consent" id="__consent" hidden>
        <div class="md-consent__overlay"></div>
        <aside class="md-consent__inner">
          <form class="md-consent__form md-grid md-typeset" name="consent">
            



<h4>Cookie consent</h4>
<p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of the textbook. With your consent, you're helping us to make software engineering education better for everyone.</p>
<input class="md-toggle" type="checkbox" id="__settings" >
<div class="md-consent__settings">
  <ul class="task-list">
    
    
    
      
        
  
  
    
    
  
  <li class="task-list-item">
    <label class="task-list-control">
      <input type="checkbox" name="github" checked>
      <span class="task-list-indicator"></span>
      GitHub
    </label>
  </li>

      
    
    
      
        
  
  
    
    
  
  <li class="task-list-item">
    <label class="task-list-control">
      <input type="checkbox" name="analytics" checked>
      <span class="task-list-indicator"></span>
      Google Analytics
    </label>
  </li>

      
    
  </ul>
</div>
<div class="md-consent__controls">
  
    
      <button class="md-button md-button--primary">Accept</button>
    
    
    
  
    
    
    
      <label class="md-button" for="__settings">Manage settings</label>
    
  
</div>
          </form>
        </aside>
      </div>
      <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout((function(){document.querySelector("[data-md-component=consent]").hidden=!1}),250);var form=document.forms.consent;for(var action of["submit","reset"])form.addEventListener(action,(function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map((function(e){return[e,!0]})))),location.hash="",location.reload()}))</script>
    
    
      
      <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tabs", "navigation.top", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.prune", "search.highlight", "search.suggest", "content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.action.edit", "content.action.view", "toc.follow"], "search": "../../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="../../../../assets/diagram-modal.js"></script>
      
        <script src="../../../../assets/quiz.js"></script>
      
        <script src="../../../../assets/ide-utils.js"></script>
      
        <script src="../../../../assets/code-blocks.js"></script>
      
        <script src="../../../../assets/glossary.js"></script>
      
    
  </body>
</html>