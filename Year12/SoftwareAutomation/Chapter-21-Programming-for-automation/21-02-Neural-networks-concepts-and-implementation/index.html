
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Comprehensive educational resource for NSW HSC Software Engineering syllabus">
      
      
      
        <link rel="canonical" href="https://eatham532.github.io/Software-Engineering-HSC-Textbook/Year12/SoftwareAutomation/Chapter-21-Programming-for-automation/21-02-Neural-networks-concepts-and-implementation/">
      
      
        <link rel="prev" href="../21-01-Regression-models-and-core-algorithm-types-in-Python/quiz/">
      
      
        <link rel="next" href="quiz/">
      
      
      <link rel="icon" href="../../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.22">
    
    
      
        <title>21.2 Neural Networks: Concepts and Implementation - Software Engineering Textbook HSC</title>
      
    
    
      <link rel="stylesheet" href="../../../../assets/stylesheets/main.84d31ad4.min.css">
      
        
        <link rel="stylesheet" href="../../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../assets/diagram-modal.css">
    
      <link rel="stylesheet" href="../../../../assets/quiz.css">
    
      <link rel="stylesheet" href="../../../../assets/common.css">
    
      <link rel="stylesheet" href="../../../../assets/diagram-fix.css">
    
      <link rel="stylesheet" href="../../../../assets/cross-reference.css">
    
      <link rel="stylesheet" href="../../../../assets/site-banner.css">
    
      <link rel="stylesheet" href="../../../../assets/code-runner.css">
    
      <link rel="stylesheet" href="../../../../assets/code-editor.css">
    
    <script>__md_scope=new URL("../../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-58275RL1P9"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-58275RL1P9",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-58275RL1P9",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script>
  
    <script>if("undefined"!=typeof __md_analytics){var consent=__md_get("__consent");consent&&consent.analytics&&__md_analytics()}</script>
  

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#212-neural-networks-concepts-and-implementation" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
  
  
    
    
    
    <div class="site-banner site-banner--warning" data-banner data-banner-version="1" role="status" aria-live="polite">
      <div class="site-banner__inner">
        <span class="site-banner__icon" aria-hidden="true">
          <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
            
              <path d="M12 9v4"/><path d="M12 17h.01"/><path d="M10.29 3.86 1.82 18a2 2 0 0 0 1.71 3h16.94a2 2 0 0 0 1.71-3L13.71 3.86a2 2 0 0 0-3.42 0Z"/>
            
          </svg>
        </span>
        <p class="site-banner__text">
          This textbook is in <strong>beta</strong> ‚Äì content is actively being refined.
          
            <a class="site-banner__link" href="https://github.com/Eatham532/Software-Engineering-HSC-Textbook/issues/new/choose" target="_blank" rel="noopener">Report issues or suggestions</a>
          
        </p>
        <button type="button" class="site-banner__close" aria-label="Dismiss banner" title="Dismiss" data-banner-dismiss>&times;</button>
      </div>
    </div>
    <script>
      (function(){
        var banner=document.querySelector('[data-banner]');
        if(!banner) return;
        var version=banner.getAttribute('data-banner-version')||'1';
        var KEY='site_banner_dismissed_v'+version;
        try{ if(localStorage.getItem(KEY)){ banner.remove(); return;} }catch(e){}
        var btn=banner.querySelector('[data-banner-dismiss]');
        if(btn){ btn.addEventListener('click',function(){
          banner.classList.add('is-hiding');
          setTimeout(function(){ banner && banner.remove(); },200);
          try{ localStorage.setItem(KEY,'1'); }catch(e){}
        }); }
      })();
    </script>
  
  
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../.." title="Software Engineering Textbook HSC" class="md-header__button md-logo" aria-label="Software Engineering Textbook HSC" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Software Engineering Textbook HSC
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              21.2 Neural Networks: Concepts and Implementation
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="black" data-md-color-accent="indigo"  aria-label="Switch to system preference"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to system preference" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/Eatham532/Software-Engineering-HSC-Textbook/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    Eatham532/Software-Engineering-HSC-Textbook
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    

    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../.." class="md-tabs__link">
        
  
  
    
  
  Home

      </a>
    </li>
  

      
        
  
  
  
  
    
    
      
  
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../../Year11/ProgrammingFundamentals/" class="md-tabs__link">
          
  
  
  Year 11

        </a>
      </li>
    
  

    
  

      
        
  
  
  
    
  
  
    
    
      
  
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../../ProgrammingForTheWeb/" class="md-tabs__link">
          
  
  
  Year 12

        </a>
      </li>
    
  

    
  

      
        
  
  
  
  
    <li class="md-tabs__item">
      <a href="../../../../code-editor/" class="md-tabs__link">
        
  
  
    
  
  Code Editor

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../.." title="Software Engineering Textbook HSC" class="md-nav__button md-logo" aria-label="Software Engineering Textbook HSC" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    Software Engineering Textbook HSC
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/Eatham532/Software-Engineering-HSC-Textbook/" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg>
  </div>
  <div class="md-source__repository">
    Eatham532/Software-Engineering-HSC-Textbook
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    
  
  
  
    <a href="../../../../Year11/ProgrammingFundamentals/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Year 11
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

  

      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Year 12
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Year 12
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../ProgrammingForTheWeb/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Programming For The Web
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../SecureSoftwareArchitecture/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Secure Software Architecture
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Software Automation
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_3">
            <span class="md-nav__icon md-icon"></span>
            Software Automation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Overview
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    
  
  
  
    <a href="../../Chapter-20-ML-and-automation-basics/20-01-What-is-AI-vs-ML/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Chapter 20 ‚Äî ML and automation basics
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

  

      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3_3" checked>
        
          
          <label class="md-nav__link" for="__nav_3_3_3" id="__nav_3_3_3_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    Chapter 21 ‚Äî Programming for automation
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_3_3_3_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_3_3">
            <span class="md-nav__icon md-icon"></span>
            Chapter 21 ‚Äî Programming for automation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../21-01-Regression-models-and-core-algorithm-types-in-Python/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    21.1 Regression models and core algorithm types in Python
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
      
      
    
    
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3_3_2" checked>
        
          
          <label class="md-nav__link" for="__nav_3_3_3_2" id="__nav_3_3_3_2_label" tabindex="0">
            
  
  
  <span class="md-ellipsis">
    21.2 Neural networks: concepts and implementation
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_3_3_3_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_3_3_3_2">
            <span class="md-nav__icon md-icon"></span>
            21.2 Neural networks: concepts and implementation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Content
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Content
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-1-perceptron-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Part 1: Perceptron Implementation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 1: Perceptron Implementation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from-scratch-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      From-Scratch Implementation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-2-tiny-multi-layer-perceptron-mlp-demo" class="md-nav__link">
    <span class="md-ellipsis">
      Part 2: Tiny Multi-Layer Perceptron (MLP) Demo
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 2: Tiny Multi-Layer Perceptron (MLP) Demo">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation_1" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from-scratch-implementation_1" class="md-nav__link">
    <span class="md-ellipsis">
      From-Scratch Implementation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-3-training-loop-intuition" class="md-nav__link">
    <span class="md-ellipsis">
      Part 3: Training Loop Intuition
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 3: Training Loop Intuition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#understanding-the-training-process" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding the Training Process
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-analysis-tools" class="md-nav__link">
    <span class="md-ellipsis">
      Training Analysis Tools
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-4-practical-applications-and-behavior-reasoning" class="md-nav__link">
    <span class="md-ellipsis">
      Part 4: Practical Applications and Behavior Reasoning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 4: Practical Applications and Behavior Reasoning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#understanding-neural-network-behavior" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding Neural Network Behavior
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior-analysis-tools" class="md-nav__link">
    <span class="md-ellipsis">
      Behavior Analysis Tools
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#main-demonstration-function" class="md-nav__link">
    <span class="md-ellipsis">
      Main demonstration function
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="quiz/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Quiz
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    
  
  
  
    <a href="../../Chapter-22-Significance-and-impact/22-01-Assessing-the-impact-of-automation/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Chapter 22 ‚Äî Significance and impact
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
      
      
    
    
      
        
        
      
    
    <li class="md-nav__item md-nav__item--pruned md-nav__item--nested">
      
        
  
  
  
    <a href="../../../SoftwareEngineeringProject/" class="md-nav__link">
      
  
  
  <span class="md-ellipsis">
    Software Engineering Project
    
  </span>
  

      
        <span class="md-nav__icon md-icon"></span>
      
    </a>
  

      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../../code-editor/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Code Editor
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#introduction" class="md-nav__link">
    <span class="md-ellipsis">
      Introduction
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-1-perceptron-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Part 1: Perceptron Implementation
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 1: Perceptron Implementation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from-scratch-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      From-Scratch Implementation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-2-tiny-multi-layer-perceptron-mlp-demo" class="md-nav__link">
    <span class="md-ellipsis">
      Part 2: Tiny Multi-Layer Perceptron (MLP) Demo
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 2: Tiny Multi-Layer Perceptron (MLP) Demo">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mathematical-foundation_1" class="md-nav__link">
    <span class="md-ellipsis">
      Mathematical Foundation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#from-scratch-implementation_1" class="md-nav__link">
    <span class="md-ellipsis">
      From-Scratch Implementation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-3-training-loop-intuition" class="md-nav__link">
    <span class="md-ellipsis">
      Part 3: Training Loop Intuition
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 3: Training Loop Intuition">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#understanding-the-training-process" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding the Training Process
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#training-analysis-tools" class="md-nav__link">
    <span class="md-ellipsis">
      Training Analysis Tools
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#part-4-practical-applications-and-behavior-reasoning" class="md-nav__link">
    <span class="md-ellipsis">
      Part 4: Practical Applications and Behavior Reasoning
    </span>
  </a>
  
    <nav class="md-nav" aria-label="Part 4: Practical Applications and Behavior Reasoning">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#understanding-neural-network-behavior" class="md-nav__link">
    <span class="md-ellipsis">
      Understanding Neural Network Behavior
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#behavior-analysis-tools" class="md-nav__link">
    <span class="md-ellipsis">
      Behavior Analysis Tools
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#main-demonstration-function" class="md-nav__link">
    <span class="md-ellipsis">
      Main demonstration function
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
    <a href="https://github.com/Eatham532/Software-Engineering-HSC-Textbook/edit/main/docs/Year12/SoftwareAutomation/Chapter-21-Programming-for-automation/21-02-Neural-networks-concepts-and-implementation/index.md" title="Edit this page" class="md-content__button md-icon" rel="edit">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/Eatham532/Software-Engineering-HSC-Textbook/raw/main/docs/Year12/SoftwareAutomation/Chapter-21-Programming-for-automation/21-02-Neural-networks-concepts-and-implementation/index.md" title="View source of this page" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"/></svg>
    </a>
  


<h1 id="212-neural-networks-concepts-and-implementation">21.2 Neural Networks: Concepts and Implementation<a class="headerlink" href="#212-neural-networks-concepts-and-implementation" title="Permanent link">&para;</a></h1>
<ul>
<li>Outcomes: SE-12-02</li>
</ul>
<h2 id="introduction">Introduction<a class="headerlink" href="#introduction" title="Permanent link">&para;</a></h2>
<p>Neural networks form the foundation of modern AI systems by mimicking how biological neurons process information. This section implements neural networks from scratch, starting with the simple perceptron and progressing to multi-layer perceptrons (MLPs) with backpropagation training.</p>
<p><strong>Key Learning Goals:</strong></p>
<ul>
<li>
<p><strong>Understand</strong> perceptron architecture and learning algorithm</p>
</li>
<li>
<p><strong>Implement</strong> tiny MLP with backpropagation from mathematical principles</p>
</li>
<li>
<p><strong>Develop</strong> training loop intuition through hands-on coding</p>
</li>
<li>
<p><strong>Reason</strong> about neural network behavior and decision-making</p>
</li>
</ul>
<div class="diagram-container" data-container-id="kroki-diagram-0"><button class="diagram-expand-btn" onclick="openDiagramModal('kroki-diagram-0')">üîç View Larger</button><div id="kroki-diagram-0" class="diagram-content"><p><svg xmlns="http://www.w3.org/2000/svg" contentStyleType="text/css" data-diagram-type="DESCRIPTION" height="679px" preserveAspectRatio="xMaxYMax meet" style="width:2440px;height:679px;background:#FFFFFF;" version="1.1" viewBox="0 0 2440 679" width="2440px" zoomAndPan="magnify" id="Kroki" data-diagram-id="kroki-svg-0"><defs /><g><g class="cluster" data-entity="Neural Network Architecture" data-source-line="3" data-uid="ent0002" id="cluster_Neural Network Architecture"><path d="M13.5,11 L241.5967,11 A3.75,3.75 0 0 1 244.0967,13.5 L251.0967,33.2969 L1981.5,33.2969 A2.5,2.5 0 0 1 1984,35.7969 L1984,448.93 A2.5,2.5 0 0 1 1981.5,451.43 L13.5,451.43 A2.5,2.5 0 0 1 11,448.93 L11,13.5 A2.5,2.5 0 0 1 13.5,11" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><line style="stroke:#000000;stroke-width:1;" x1="11" x2="251.0967" y1="33.2969" y2="33.2969" /><text fill="#000000" font-family="Verdana" font-size="14" font-weight="bold" lengthAdjust="spacing" textLength="227.0967" x="15" y="25.9951">Neural Network Architecture</text></g><g class="cluster" data-entity="Training Loop Components" data-source-line="57" data-uid="ent0046" id="cluster_Training Loop Components"><path d="M2018.5,53.91 L2231.4551,53.91 A3.75,3.75 0 0 1 2233.9551,56.41 L2240.9551,76.2069 L2430.5,76.2069 A2.5,2.5 0 0 1 2433,78.7069 L2433,669.52 A2.5,2.5 0 0 1 2430.5,672.02 L2018.5,672.02 A2.5,2.5 0 0 1 2016,669.52 L2016,56.41 A2.5,2.5 0 0 1 2018.5,53.91" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><line style="stroke:#000000;stroke-width:1;" x1="2016" x2="2240.9551" y1="76.2069" y2="76.2069" /><text fill="#000000" font-family="Verdana" font-size="14" font-weight="bold" lengthAdjust="spacing" textLength="211.9551" x="2020" y="68.9051">Training Loop Components</text></g><g class="entity" data-entity="Input Layer" data-source-line="5" data-uid="ent0003" id="entity_Input Layer"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="119.7344" x="1699.13" y="58.12" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="1798.8644" y="63.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1796.8644" y="65.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1796.8644" y="69.12" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="79.7344" x="1714.13" y="91.1151">Input Layer</text></g><g class="entity" data-entity="Hidden Layer 1" data-source-line="6" data-uid="ent0004" id="entity_Hidden Layer 1"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="146.5176" x="1649.74" y="176.54" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="1776.2576" y="181.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1774.2576" y="183.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1774.2576" y="187.54" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="106.5176" x="1664.74" y="209.5351">Hidden Layer 1</text></g><g class="entity" data-entity="Hidden Layer 2" data-source-line="7" data-uid="ent0005" id="entity_Hidden Layer 2"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="146.5176" x="1649.74" y="282.83" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="1776.2576" y="287.83" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1774.2576" y="289.83" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1774.2576" y="293.83" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="106.5176" x="1664.74" y="315.8251">Hidden Layer 2</text></g><g class="entity" data-entity="Output Layer" data-source-line="8" data-uid="ent0006" id="entity_Output Layer"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="132.1143" x="1656.94" y="389.13" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="1769.0543" y="394.13" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1767.0543" y="396.13" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1767.0543" y="400.13" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="92.1143" x="1671.94" y="422.1251">Output Layer</text></g><g class="entity" data-entity="GMN10" data-source-line="14" data-uid="ent0011" id="entity_GMN10"><path d="M1854.34,68.7 L1854.34,77.27 L1819.27,81.27 L1854.34,85.27 L1854.34,93.8328 A0,0 0 0 0 1854.34,93.8328 L1967.654,93.8328 A0,0 0 0 0 1967.654,93.8328 L1967.654,78.7 L1957.654,68.7 L1854.34,68.7 A0,0 0 0 0 1854.34,68.7" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M1957.654,68.7 L1957.654,78.7 L1967.654,78.7 L1957.654,68.7" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="92.314" x="1860.34" y="85.7669">Features/Data</text></g><g class="entity" data-entity="GMN13" data-source-line="15" data-uid="ent0014" id="entity_GMN13"><path d="M1831.07,187.12 L1831.07,195.68 L1796.56,199.68 L1831.07,203.68 L1831.07,212.2528 A0,0 0 0 0 1831.07,212.2528 L1966.9372,212.2528 A0,0 0 0 0 1966.9372,212.2528 L1966.9372,197.12 L1956.9372,187.12 L1831.07,187.12 A0,0 0 0 0 1831.07,187.12" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M1956.9372,187.12 L1956.9372,197.12 L1966.9372,197.12 L1956.9372,187.12" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="114.8672" x="1837.07" y="204.1869">Pattern Detection</text></g><g class="entity" data-entity="GMN16" data-source-line="16" data-uid="ent0017" id="entity_GMN16"><path d="M1831.63,293.41 L1831.63,301.98 L1796.63,305.98 L1831.63,309.98 L1831.63,318.5428 A0,0 0 0 0 1831.63,318.5428 L1968.3668,318.5428 A0,0 0 0 0 1968.3668,318.5428 L1968.3668,303.41 L1958.3668,293.41 L1831.63,293.41 A0,0 0 0 0 1831.63,293.41" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M1958.3668,293.41 L1958.3668,303.41 L1968.3668,303.41 L1958.3668,293.41" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="115.7368" x="1837.63" y="310.4769">Complex Patterns</text></g><g class="entity" data-entity="GMN19" data-source-line="17" data-uid="ent0020" id="entity_GMN19"><path d="M1823.57,399.71 L1823.57,408.28 L1789.32,412.28 L1823.57,416.28 L1823.57,424.8428 A0,0 0 0 0 1823.57,424.8428 L1916.4382,424.8428 A0,0 0 0 0 1916.4382,424.8428 L1916.4382,409.71 L1906.4382,399.71 L1823.57,399.71 A0,0 0 0 0 1823.57,399.71" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M1906.4382,399.71 L1906.4382,409.71 L1916.4382,409.71 L1906.4382,399.71" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="71.8682" x="1829.57" y="416.7769">Predictions</text></g><g class="entity" data-entity="Perceptron" data-source-line="19" data-uid="ent0022" id="entity_Perceptron"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="116.6924" x="1327.65" y="58.12" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="1424.3424" y="63.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1422.3424" y="65.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1422.3424" y="69.12" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="76.6924" x="1342.65" y="91.1151">Perceptron</text></g><g class="entity" data-entity="Binary Classification" data-source-line="20" data-uid="ent0023" id="entity_Binary Classification"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="182.0713" x="1294.96" y="176.54" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="1457.0313" y="181.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1455.0313" y="183.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1455.0313" y="187.54" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="142.0713" x="1309.96" y="209.5351">Binary Classification</text></g><g class="entity" data-entity="GMN25" data-source-line="23" data-uid="ent0026" id="entity_GMN25"><path d="M1479.4,53.57 L1479.4,77.27 L1444.49,81.27 L1479.4,85.27 L1479.4,108.9684 A0,0 0 0 0 1479.4,108.9684 L1664.5948,108.9684 A0,0 0 0 0 1664.5948,108.9684 L1664.5948,63.57 L1654.5948,53.57 L1479.4,53.57 A0,0 0 0 0 1479.4,53.57" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M1654.5948,53.57 L1654.5948,63.57 L1664.5948,63.57 L1654.5948,53.57" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="76.7114" x="1485.4" y="70.6369">Single layer</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="164.1948" x="1485.4" y="85.7697">Linear decision boundary</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="131.1108" x="1485.4" y="100.9025">Simple learning rule</text></g><g class="entity" data-entity="Multi-Layer Perceptron" data-source-line="28" data-uid="ent0028" id="entity_Multi-Layer Perceptron"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="199.4482" x="872.28" y="58.12" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="1051.7282" y="63.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1049.7282" y="65.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1049.7282" y="69.12" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="159.4482" x="887.28" y="91.1151">Multi-Layer Perceptron</text></g><g class="entity" data-entity="Non-linear Problems" data-source-line="29" data-uid="ent0029" id="entity_Non-linear Problems"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="182.0986" x="880.95" y="176.54" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="1043.0486" y="181.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1041.0486" y="183.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="1041.0486" y="187.54" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="142.0986" x="895.95" y="209.5351">Non-linear Problems</text></g><g class="entity" data-entity="GMN31" data-source-line="32" data-uid="ent0032" id="entity_GMN31"><path d="M1107.03,53.57 L1107.03,77.27 L1072.2,81.27 L1107.03,85.27 L1107.03,108.9684 A0,0 0 0 0 1107.03,108.9684 L1292.9738,108.9684 A0,0 0 0 0 1292.9738,108.9684 L1292.9738,63.57 L1282.9738,53.57 L1107.03,53.57 A0,0 0 0 0 1107.03,53.57" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M1282.9738,53.57 L1282.9738,63.57 L1292.9738,63.57 L1282.9738,53.57" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="143.8823" x="1113.03" y="70.6369">Multiple hidden layers</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="164.9438" x="1113.03" y="85.7697">Backpropagation training</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="152.9849" x="1113.03" y="100.9025">Universal approximator</text></g><g class="entity" data-entity="Activation Functions" data-source-line="37" data-uid="ent0034" id="entity_Activation Functions"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="182.3926" x="385.8" y="58.12" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="548.1926" y="63.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="546.1926" y="65.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="546.1926" y="69.12" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="142.3926" x="400.8" y="91.1151">Activation Functions</text></g><g class="entity" data-entity="Non-linearity" data-source-line="38" data-uid="ent0035" id="entity_Non-linearity"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="130.2275" x="411.89" y="176.54" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="522.1175" y="181.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="520.1175" y="183.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="520.1175" y="187.54" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="90.2275" x="426.89" y="209.5351">Non-linearity</text></g><g class="entity" data-entity="GMN37" data-source-line="41" data-uid="ent0038" id="entity_GMN37"><path d="M602.8,53.57 L602.8,77.27 L568.6,81.27 L602.8,85.27 L602.8,108.9684 A0,0 0 0 0 602.8,108.9684 L837.1955,108.9684 A0,0 0 0 0 837.1955,108.9684 L837.1955,63.57 L827.1955,53.57 L602.8,53.57 A0,0 0 0 0 602.8,53.57" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M827.1955,53.57 L827.1955,63.57 L837.1955,63.57 L827.1955,53.57" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="179.5752" x="608.8" y="70.6369">Sigmoid: &#963;(x) = 1/(1+e^-x)</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="104.9966" x="608.8" y="85.7697">ReLU: max(0, x)</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="213.3955" x="608.8" y="100.9025">Tanh: (e^x - e^-x)/(e^x + e^-x)</text></g><g class="entity" data-entity="Training Process" data-source-line="46" data-uid="ent0040" id="entity_Training Process"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="155.4111" x="27.29" y="58.12" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="162.7011" y="63.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="160.7011" y="65.12" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="160.7011" y="69.12" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="115.4111" x="42.29" y="91.1151">Training Process</text></g><g class="entity" data-entity="Weight Updates" data-source-line="47" data-uid="ent0041" id="entity_Weight Updates"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="152.041" x="28.98" y="176.54" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="161.021" y="181.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="159.021" y="183.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="159.021" y="187.54" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="112.041" x="43.98" y="209.5351">Weight Updates</text></g><g class="entity" data-entity="GMN43" data-source-line="50" data-uid="ent0044" id="entity_GMN43"><path d="M217.39,46 L217.39,77.27 L182.96,81.27 L217.39,85.27 L217.39,116.5313 A0,0 0 0 0 217.39,116.5313 L350.6102,116.5313 A0,0 0 0 0 350.6102,116.5313 L350.6102,56 L340.6102,46 L217.39,46 A0,0 0 0 0 217.39,46" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M340.6102,46 L340.6102,56 L350.6102,56 L340.6102,46" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="86.8677" x="223.39" y="63.0669">Forward pass</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="103.4668" x="223.39" y="78.1997">Loss calculation</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="97.6523" x="223.39" y="93.3325">Backward pass</text><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="112.2202" x="223.39" y="108.4653">Gradient descent</text></g><g class="entity" data-entity="Data Batch" data-source-line="58" data-uid="ent0047" id="entity_Data Batch"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="118.1211" x="2290.94" y="176.54" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="2389.0611" y="181.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2387.0611" y="183.54" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2387.0611" y="187.54" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="78.1211" x="2305.94" y="209.5351">Data Batch</text></g><g class="entity" data-entity="Forward Pass" data-source-line="59" data-uid="ent0048" id="entity_Forward Pass"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="133.1055" x="2199.45" y="282.83" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="2312.5555" y="287.83" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2310.5555" y="289.83" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2310.5555" y="293.83" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="93.1055" x="2214.45" y="315.8251">Forward Pass</text></g><g class="entity" data-entity="Loss Calculation" data-source-line="60" data-uid="ent0049" id="entity_Loss Calculation"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="153.5039" x="2184.25" y="389.13" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="2317.7539" y="394.13" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2315.7539" y="396.13" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2315.7539" y="400.13" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="113.5039" x="2199.25" y="422.1251">Loss Calculation</text></g><g class="entity" data-entity="Backward Pass" data-source-line="61" data-uid="ent0050" id="entity_Backward Pass"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="144.7197" x="2190.64" y="495.43" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="2315.3597" y="500.43" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2313.3597" y="502.43" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2313.3597" y="506.43" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="104.7197" x="2205.64" y="528.4251">Backward Pass</text></g><g class="entity" data-entity="Weight Update" data-source-line="62" data-uid="ent0051" id="entity_Weight Update"><rect fill="#FFFFFF" height="46.2969" rx="2.5" ry="2.5" style="stroke:#000000;stroke-width:1;" width="144.7471" x="2240.63" y="601.72" /><rect fill="#FFFFFF" height="10" style="stroke:#000000;stroke-width:1;" width="15" x="2365.3771" y="606.72" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2363.3771" y="608.72" /><rect fill="#FFFFFF" height="2" style="stroke:#000000;stroke-width:1;" width="4" x="2363.3771" y="612.72" /><text fill="#000000" font-family="Verdana" font-size="14" lengthAdjust="spacing" textLength="104.7471" x="2255.63" y="634.7151">Weight Update</text></g><g class="entity" data-entity="GMN57" data-source-line="70" data-uid="ent0058" id="entity_GMN57"><path d="M2040.49,187.12 L2040.49,212.2528 L2255.5188,212.2528 L2255.5188,197.12 L2245.5188,187.12 L2040.49,187.12" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><path d="M2245.5188,187.12 L2245.5188,197.12 L2255.5188,197.12 L2245.5188,187.12" fill="#FFFFFF" style="stroke:#000000;stroke-width:1;" /><text fill="#000000" font-family="Verdana" font-size="13" lengthAdjust="spacing" textLength="194.0288" x="2046.49" y="204.1869">Iterative optimization process</text></g><g class="link" data-entity-1="Input Layer" data-entity-2="Hidden Layer 1" data-source-line="10" data-uid="lnk7" id="link_Input Layer_Hidden Layer 1"><path d="M1752.06,104.72 C1745.68,125.33 1738.0625,149.9778 1731.6925,170.5778" fill="none" id="Input Layer-to-Hidden Layer 1" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="1729.92,176.31,1736.4003,168.8934,1731.3971,171.5332,1728.7573,166.53,1729.92,176.31" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Hidden Layer 1" data-entity-2="Hidden Layer 2" data-source-line="11" data-uid="lnk8" id="link_Hidden Layer 1_Hidden Layer 2"><path d="M1723,223.31 C1723,240.81 1723,258.91 1723,276.39" fill="none" id="Hidden Layer 1-to-Hidden Layer 2" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="1723,282.39,1727,273.39,1723,277.39,1719,273.39,1723,282.39" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Hidden Layer 2" data-entity-2="Output Layer" data-source-line="12" data-uid="lnk9" id="link_Hidden Layer 2_Output Layer"><path d="M1723,329.61 C1723,347.11 1723,365.21 1723,382.69" fill="none" id="Hidden Layer 2-to-Output Layer" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="1723,388.69,1727,379.69,1723,383.69,1719,379.69,1723,388.69" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Perceptron" data-entity-2="Binary Classification" data-source-line="21" data-uid="lnk24" id="link_Perceptron_Binary Classification"><path d="M1386,104.72 C1386,125.33 1386,149.71 1386,170.31" fill="none" id="Perceptron-to-Binary Classification" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="1386,176.31,1390,167.31,1386,171.31,1382,167.31,1386,176.31" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Multi-Layer Perceptron" data-entity-2="Non-linear Problems" data-source-line="30" data-uid="lnk30" id="link_Multi-Layer Perceptron_Non-linear Problems"><path d="M972,104.72 C972,125.33 972,149.71 972,170.31" fill="none" id="Multi-Layer Perceptron-to-Non-linear Problems" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="972,176.31,976,167.31,972,171.31,968,167.31,972,176.31" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Activation Functions" data-entity-2="Non-linearity" data-source-line="39" data-uid="lnk36" id="link_Activation Functions_Non-linearity"><path d="M477,104.72 C477,125.33 477,149.71 477,170.31" fill="none" id="Activation Functions-to-Non-linearity" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="477,176.31,481,167.31,477,171.31,473,167.31,477,176.31" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Training Process" data-entity-2="Weight Updates" data-source-line="48" data-uid="lnk42" id="link_Training Process_Weight Updates"><path d="M105,104.72 C105,125.33 105,149.71 105,170.31" fill="none" id="Training Process-to-Weight Updates" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="105,176.31,109,167.31,105,171.31,101,167.31,105,176.31" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Data Batch" data-entity-2="Forward Pass" data-source-line="64" data-uid="lnk52" id="link_Data Batch_Forward Pass"><path d="M2331.77,223.31 C2317.68,240.81 2302.0338,260.2373 2287.9538,277.7173" fill="none" id="Data Batch-to-Forward Pass" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="2284.19,282.39,2292.9508,277.8902,2287.3265,278.4961,2286.7206,272.8718,2284.19,282.39" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Forward Pass" data-entity-2="Loss Calculation" data-source-line="65" data-uid="lnk53" id="link_Forward Pass_Loss Calculation"><path d="M2264.92,329.61 C2264.08,347.11 2263.208,365.2169 2262.368,382.6969" fill="none" id="Forward Pass-to-Loss Calculation" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="2262.08,388.69,2266.5074,379.8924,2262.32,383.6958,2258.5166,379.5084,2262.08,388.69" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Loss Calculation" data-entity-2="Backward Pass" data-source-line="66" data-uid="lnk54" id="link_Loss Calculation_Backward Pass"><path d="M2261.43,435.91 C2261.77,453.4 2262.1133,471.5111 2262.4533,488.9911" fill="none" id="Loss Calculation-to-Backward Pass" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="2262.57,494.99,2266.3942,485.9139,2262.4728,489.9909,2258.3957,486.0695,2262.57,494.99" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Backward Pass" data-entity-2="Weight Update" data-source-line="67" data-uid="lnk55" id="link_Backward Pass_Weight Update"><path d="M2273.85,542.21 C2282.24,559.7 2291.1962,578.3896 2299.5762,595.8696" fill="none" id="Backward Pass-to-Weight Update" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="2302.17,601.28,2301.8863,591.4352,2300.0085,596.7713,2294.6724,594.8936,2302.17,601.28" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Weight Update" data-entity-2="Data Batch" data-source-line="68" data-uid="lnk56" id="link_Weight Update_Data Batch"><path d="M2327.16,601.5 C2336.44,585.52 2347.79,563.15 2353,541.72 C2381.49,424.65 2363.7429,284.1238 2354.8729,228.9838" fill="none" id="Weight Update-to-Data Batch" style="stroke:#000000;stroke-width:1;" /><polygon fill="#000000" points="2353.92,223.06,2351.4002,232.5811,2354.7141,227.9965,2359.2986,231.3105,2353.92,223.06" style="stroke:#000000;stroke-width:1;" /></g><g class="link" data-entity-1="Training Loop Components" data-entity-2="GMN57" data-source-line="70" data-uid="lnk59" id="link_Training Loop Components_GMN57"><path d="M2148,82.35 C2148,85.18 2148,158.08 2148,187.01" fill="none" id="Training Loop Components-GMN57" style="stroke:#000000;stroke-width:1;stroke-dasharray:7.0,7.0;" /></g></g></svg></p></div></div>
<hr />
<h2 id="part-1-perceptron-implementation">Part 1: Perceptron Implementation<a class="headerlink" href="#part-1-perceptron-implementation" title="Permanent link">&para;</a></h2>
<h3 id="mathematical-foundation">Mathematical Foundation<a class="headerlink" href="#mathematical-foundation" title="Permanent link">&para;</a></h3>
<p>The perceptron is the simplest neural network, consisting of a single neuron that learns to classify linearly separable data. It demonstrates the fundamental concepts of neural learning without the complexity of multiple layers.</p>
<p><strong>Perceptron Architecture:</strong></p>
<ul>
<li>
<p><strong>Inputs</strong>: <code>x‚ÇÅ, x‚ÇÇ, ..., x‚Çô</code> (features)</p>
</li>
<li>
<p><strong>Weights</strong>: <code>w‚ÇÅ, w‚ÇÇ, ..., w‚Çô</code> (learned parameters)</p>
</li>
<li>
<p><strong>Bias</strong>: <code>b</code> (threshold adjustment)</p>
</li>
<li>
<p><strong>Output</strong>: <code>y = f(Œ£w·µ¢x·µ¢ + b)</code> where <code>f</code> is activation function</p>
</li>
</ul>
<p><strong>Activation Functions:</strong></p>
<ul>
<li>
<p><strong>Step Function</strong>: <code>f(z) = 1 if z ‚â• 0, else 0</code></p>
</li>
<li>
<p><strong>Sigmoid</strong>: <code>f(z) = 1/(1 + e^(-z))</code> (smooth, differentiable)</p>
</li>
</ul>
<p><strong>Learning Rule (Perceptron Algorithm):</strong></p>
<ul>
<li>
<p>For each training example: <code>w·µ¢ = w·µ¢ + Œ±(target - prediction) * x·µ¢</code></p>
</li>
<li>
<p>Where <code>Œ±</code> is the learning rate</p>
</li>
</ul>
<h3 id="from-scratch-implementation">From-Scratch Implementation<a class="headerlink" href="#from-scratch-implementation" title="Permanent link">&para;</a></h3>
<p>```python
import numpy as np
import matplotlib.pyplot as plt
from typing import Tuple, List, Dict, Any
import random</p>
<p>class Perceptron:
    &ldquo;&rdquo;&rdquo;
    Single-layer perceptron implementation from scratch.
    Demonstrates basic neural network concepts and learning.
    &ldquo;&rdquo;&ldquo;</p>
<div class="language-text highlight"><pre><span></span><code>def __init__(self, learning_rate: float = 0.1, max_epochs: int = 100, activation: str = &#39;step&#39;):
    &quot;&quot;&quot;
    Initialize perceptron.

    Args:
        learning_rate: Step size for weight updates
        max_epochs: Maximum training iterations
        activation: Activation function (&#39;step&#39; or &#39;sigmoid&#39;)
    &quot;&quot;&quot;
    self.learning_rate = learning_rate
    self.max_epochs = max_epochs
    self.activation = activation
    self.weights = None
    self.bias = None
    self.training_history = []
    self.trained = False

def _activation_function(self, z: np.ndarray) -&gt; np.ndarray:
    &quot;&quot;&quot;Apply activation function to input.&quot;&quot;&quot;
    if self.activation == &#39;step&#39;:
        return np.where(z &gt;= 0, 1, 0)
    elif self.activation == &#39;sigmoid&#39;:

        ## Clip to prevent overflow

        z = np.clip(z, -500, 500)
        return 1 / (1 + np.exp(-z))
    else:
        raise ValueError(f&quot;Unknown activation function: {self.activation}&quot;)

def _activation_derivative(self, z: np.ndarray) -&gt; np.ndarray:
    &quot;&quot;&quot;Compute derivative of activation function.&quot;&quot;&quot;
    if self.activation == &#39;step&#39;:

        ## Step function derivative is 0 everywhere (except at 0, undefined)

        return np.ones_like(z)  # Use 1 as approximation for learning
    elif self.activation == &#39;sigmoid&#39;:
        sigmoid_output = self._activation_function(z)
        return sigmoid_output * (1 - sigmoid_output)
    else:
        raise ValueError(f&quot;Unknown activation function: {self.activation}&quot;)

def _forward_pass(self, X: np.ndarray) -&gt; Tuple[np.ndarray, np.ndarray]:
    &quot;&quot;&quot;
    Perform forward pass through perceptron.

    Args:
        X: Input features

    Returns:
        Tuple of (linear_output, activated_output)
    &quot;&quot;&quot;

    ## Linear combination: z = X * w + b

    z = np.dot(X, self.weights) + self.bias

    ## Apply activation function

    a = self._activation_function(z)

    return z, a

def fit(self, X: np.ndarray, y: np.ndarray) -&gt; Dict[str, Any]:
    &quot;&quot;&quot;
    Train the perceptron using the perceptron learning algorithm.

    Args:
        X: Training features (n_samples, n_features)
        y: Training targets (n_samples,)

    Returns:
        Training statistics
    &quot;&quot;&quot;

    ## Ensure proper shapes

    if X.ndim == 1:
        X = X.reshape(-1, 1)

    n_samples, n_features = X.shape

    ## Initialize weights and bias randomly

    self.weights = np.random.normal(0, 0.1, n_features)
    self.bias = np.random.normal(0, 0.1)

    ## Track training progress

    self.training_history = []
    converged = False

    for epoch in range(self.max_epochs):
        total_error = 0
        correct_predictions = 0

        ## Process each training example

        for i in range(n_samples):

            ## Forward pass for single example

            x_i = X[i]
            target = y[i]

            ## Compute prediction

            z, prediction = self._forward_pass(x_i.reshape(1, -1))
            prediction = prediction[0]  # Extract scalar

            ## Compute error

            error = target - prediction
            total_error += abs(error)

            if abs(error) &lt; 1e-6:  # Consider very small errors as correct
                correct_predictions += 1

            ## Update weights and bias using perceptron learning rule

            if self.activation == &#39;step&#39;:

                ## Classic perceptron rule

                self.weights += self.learning_rate * error * x_i
                self.bias += self.learning_rate * error
            else:

                ## Gradient descent for sigmoid

                derivative = self._activation_derivative(z)[0]
                self.weights += self.learning_rate * error * derivative * x_i
                self.bias += self.learning_rate * error * derivative

        ## Calculate accuracy

        accuracy = correct_predictions / n_samples

        ## Record epoch statistics

        epoch_stats = {
            &#39;epoch&#39;: epoch + 1,
            &#39;total_error&#39;: total_error,
            &#39;accuracy&#39;: accuracy,
            &#39;weights&#39;: self.weights.copy(),
            &#39;bias&#39;: self.bias
        }
        self.training_history.append(epoch_stats)

        ## Check for convergence

        if total_error == 0:
            converged = True
            print(f&quot;Converged after {epoch + 1} epochs&quot;)
            break

    self.trained = True

    return {
        &#39;converged&#39;: converged,
        &#39;final_epoch&#39;: len(self.training_history),
        &#39;final_accuracy&#39;: self.training_history[-1][&#39;accuracy&#39;],
        &#39;final_error&#39;: self.training_history[-1][&#39;total_error&#39;]
    }

def predict(self, X: np.ndarray) -&gt; np.ndarray:
    &quot;&quot;&quot;Make predictions on new data.&quot;&quot;&quot;
    if not self.trained:
        raise ValueError(&quot;Perceptron must be trained before making predictions&quot;)

    if X.ndim == 1:
        X = X.reshape(-1, 1)

    _, predictions = self._forward_pass(X)
    return predictions

def decision_boundary_equation(self) -&gt; str:
    &quot;&quot;&quot;Get human-readable decision boundary equation.&quot;&quot;&quot;
    if not self.trained or len(self.weights) != 2:
        return &quot;Decision boundary not available&quot;

    w1, w2 = self.weights
    b = self.bias

    ## Decision boundary: w1*x1 + w2*x2 + b = 0

    ## Solving for x2: x2 = (-w1*x1 - b) / w2

    return f&quot;x2 = {-w1/w2:.3f} * x1 + {-b/w2:.3f}&quot;

def get_training_statistics(self) -&gt; Dict[str, List]:
    &quot;&quot;&quot;Get detailed training statistics.&quot;&quot;&quot;
    return {
        &#39;epochs&#39;: [stats[&#39;epoch&#39;] for stats in self.training_history],
        &#39;errors&#39;: [stats[&#39;total_error&#39;] for stats in self.training_history],
        &#39;accuracies&#39;: [stats[&#39;accuracy&#39;] for stats in self.training_history]
    }
</code></pre></div>
<p>def demonstrate_perceptron():
    &ldquo;&rdquo;&ldquo;Demonstrate perceptron with classic examples.&rdquo;&ldquo;&rdquo;
    print(&ldquo;Perceptron Demonstration&rdquo;)
    print(&ldquo;=&rdquo; * 25)</p>
<div class="language-text highlight"><pre><span></span><code>## Example 1: AND Gate

print(&quot;\n1. AND Gate Learning&quot;)
print(&quot;-&quot; * 20)

## AND gate truth table

X_and = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_and = np.array([0, 0, 0, 1])

## Train perceptron

perceptron_and = Perceptron(learning_rate=0.1, max_epochs=50, activation=&#39;step&#39;)
and_stats = perceptron_and.fit(X_and, y_and)

print(f&quot;AND Gate Training:&quot;)
print(f&quot;  Converged: {and_stats[&#39;converged&#39;]}&quot;)
print(f&quot;  Final accuracy: {and_stats[&#39;final_accuracy&#39;]:.3f}&quot;)
print(f&quot;  Epochs required: {and_stats[&#39;final_epoch&#39;]}&quot;)
print(f&quot;  Decision boundary: {perceptron_and.decision_boundary_equation()}&quot;)

## Test predictions

predictions_and = perceptron_and.predict(X_and)
print(f&quot;\nAND Gate Results:&quot;)
for i, (inputs, target, pred) in enumerate(zip(X_and, y_and, predictions_and)):
    print(f&quot;  {inputs[0]} AND {inputs[1]} = {target} (predicted: {pred:.0f})&quot;)

## Example 2: OR Gate

print(f&quot;\n2. OR Gate Learning&quot;)
print(&quot;-&quot; * 19)

## OR gate truth table

X_or = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_or = np.array([0, 1, 1, 1])

## Train perceptron

perceptron_or = Perceptron(learning_rate=0.1, max_epochs=50, activation=&#39;step&#39;)
or_stats = perceptron_or.fit(X_or, y_or)

print(f&quot;OR Gate Training:&quot;)
print(f&quot;  Converged: {or_stats[&#39;converged&#39;]}&quot;)
print(f&quot;  Final accuracy: {or_stats[&#39;final_accuracy&#39;]:.3f}&quot;)
print(f&quot;  Epochs required: {or_stats[&#39;final_epoch&#39;]}&quot;)
print(f&quot;  Decision boundary: {perceptron_or.decision_boundary_equation()}&quot;)

## Example 3: XOR Gate (should fail - not linearly separable)

print(f&quot;\n3. XOR Gate Learning (Expected to Fail)&quot;)
print(&quot;-&quot; * 40)

## XOR gate truth table

X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_xor = np.array([0, 1, 1, 0])

## Train perceptron

perceptron_xor = Perceptron(learning_rate=0.1, max_epochs=100, activation=&#39;step&#39;)
xor_stats = perceptron_xor.fit(X_xor, y_xor)

print(f&quot;XOR Gate Training:&quot;)
print(f&quot;  Converged: {xor_stats[&#39;converged&#39;]}&quot;)
print(f&quot;  Final accuracy: {xor_stats[&#39;final_accuracy&#39;]:.3f}&quot;)
print(f&quot;  Epochs completed: {xor_stats[&#39;final_epoch&#39;]}&quot;)
print(f&quot;  Final error: {xor_stats[&#39;final_error&#39;]}&quot;)

predictions_xor = perceptron_xor.predict(X_xor)
print(f&quot;\nXOR Gate Results (showing limitation):&quot;)
for i, (inputs, target, pred) in enumerate(zip(X_xor, y_xor, predictions_xor)):
    correct = &quot;‚úì&quot; if abs(target - pred) &lt; 0.5 else &quot;‚úó&quot;
    print(f&quot;  {inputs[0]} XOR {inputs[1]} = {target} (predicted: {pred:.0f}) {correct}&quot;)

print(f&quot;\nPerceptron Limitation: Cannot learn XOR (not linearly separable)&quot;)
print(f&quot;This motivates the need for multi-layer networks!&quot;)

## Example 4: Linearly Separable 2D Data

print(f&quot;\n4. 2D Classification Problem&quot;)
print(&quot;-&quot; * 30)

## Generate linearly separable 2D data

np.random.seed(42)

## Class 0: points around (2, 2)

class0_x = np.random.normal(2, 0.8, 25)
class0_y = np.random.normal(2, 0.8, 25)

## Class 1: points around (5, 5)

class1_x = np.random.normal(5, 0.8, 25)
class1_y = np.random.normal(5, 0.8, 25)

## Combine data

X_2d = np.column_stack([
    np.concatenate([class0_x, class1_x]),
    np.concatenate([class0_y, class1_y])
])
y_2d = np.concatenate([np.zeros(25), np.ones(25)])

## Shuffle data

indices = np.random.permutation(len(y_2d))
X_2d = X_2d[indices]
y_2d = y_2d[indices]

## Train perceptron with sigmoid activation

perceptron_2d = Perceptron(learning_rate=0.01, max_epochs=200, activation=&#39;sigmoid&#39;)
stats_2d = perceptron_2d.fit(X_2d, y_2d)

print(f&quot;2D Classification Training:&quot;)
print(f&quot;  Converged: {stats_2d[&#39;converged&#39;]}&quot;)
print(f&quot;  Final accuracy: {stats_2d[&#39;final_accuracy&#39;]:.3f}&quot;)
print(f&quot;  Epochs required: {stats_2d[&#39;final_epoch&#39;]}&quot;)

## Test on new points

test_points = np.array([[1, 1], [3, 3], [6, 6], [4, 4]])
test_predictions = perceptron_2d.predict(test_points)

print(f&quot;\nTest Predictions:&quot;)
for point, pred in zip(test_points, test_predictions):
    class_pred = &quot;Class 1&quot; if pred &gt; 0.5 else &quot;Class 0&quot;
    print(f&quot;  Point {point}: {class_pred} (confidence: {pred:.3f})&quot;)

return perceptron_and, perceptron_or, perceptron_xor, perceptron_2d
</code></pre></div>
<hr />
<h2 id="part-2-tiny-multi-layer-perceptron-mlp-demo">Part 2: Tiny Multi-Layer Perceptron (MLP) Demo<a class="headerlink" href="#part-2-tiny-multi-layer-perceptron-mlp-demo" title="Permanent link">&para;</a></h2>
<h3 id="mathematical-foundation_1">Mathematical Foundation<a class="headerlink" href="#mathematical-foundation_1" title="Permanent link">&para;</a></h3>
<p>Multi-layer perceptrons extend single perceptrons by adding hidden layers, enabling them to learn non-linear patterns. The key innovation is <strong>backpropagation</strong> - an algorithm that efficiently computes gradients for all weights in the network.</p>
<p><strong>MLP Architecture:</strong></p>
<ul>
<li>
<p><strong>Input Layer</strong>: Receives features</p>
</li>
<li>
<p><strong>Hidden Layer(s)</strong>: Process and transform features </p>
</li>
<li>
<p><strong>Output Layer</strong>: Produces final predictions</p>
</li>
<li>
<p><strong>Connections</strong>: Each neuron connects to all neurons in the next layer</p>
</li>
</ul>
<p><strong>Forward Pass:</strong></p>
<ol>
<li>
<p><code>z‚ÇÅ = W‚ÇÅX + b‚ÇÅ</code> (linear transformation)</p>
</li>
<li>
<p><code>a‚ÇÅ = œÉ(z‚ÇÅ)</code> (activation function)</p>
</li>
<li>
<p><code>z‚ÇÇ = W‚ÇÇa‚ÇÅ + b‚ÇÇ</code> (second layer)</p>
</li>
<li>
<p><code>≈∑ = œÉ(z‚ÇÇ)</code> (final output)</p>
</li>
</ol>
<p><strong>Backpropagation Algorithm:</strong></p>
<ol>
<li>
<p><strong>Forward pass</strong>: Compute predictions</p>
</li>
<li>
<p><strong>Compute loss</strong>: Compare predictions to targets</p>
</li>
<li>
<p><strong>Backward pass</strong>: Compute gradients using chain rule</p>
</li>
<li>
<p><strong>Update weights</strong>: Apply gradient descent</p>
</li>
</ol>
<h3 id="from-scratch-implementation_1">From-Scratch Implementation<a class="headerlink" href="#from-scratch-implementation_1" title="Permanent link">&para;</a></h3>
<p>```python</p>
<p>class TinyMLP:
    &ldquo;&rdquo;&rdquo;
    Tiny Multi-Layer Perceptron implementation from scratch.
    Demonstrates backpropagation and multi-layer learning.
    &ldquo;&rdquo;&ldquo;</p>
<div class="language-text highlight"><pre><span></span><code>def __init__(self, input_size: int, hidden_size: int, output_size: int, learning_rate: float = 0.1):
    &quot;&quot;&quot;
    Initialize tiny MLP with one hidden layer.

    Args:
        input_size: Number of input features
        hidden_size: Number of neurons in hidden layer
        output_size: Number of output neurons
        learning_rate: Learning rate for gradient descent
    &quot;&quot;&quot;
    self.input_size = input_size
    self.hidden_size = hidden_size
    self.output_size = output_size
    self.learning_rate = learning_rate

    ## Initialize weights with small random values

    self.W1 = np.random.normal(0, 0.5, (input_size, hidden_size))   # Input to hidden
    self.b1 = np.zeros((1, hidden_size))                            # Hidden layer bias
    self.W2 = np.random.normal(0, 0.5, (hidden_size, output_size))  # Hidden to output
    self.b2 = np.zeros((1, output_size))                            # Output layer bias

    ## Track training progress

    self.training_history = []
    self.trained = False

def _sigmoid(self, z: np.ndarray) -&gt; np.ndarray:
    &quot;&quot;&quot;Sigmoid activation function with numerical stability.&quot;&quot;&quot;
    z = np.clip(z, -500, 500)  # Prevent overflow
    return 1 / (1 + np.exp(-z))

def _sigmoid_derivative(self, z: np.ndarray) -&gt; np.ndarray:
    &quot;&quot;&quot;Derivative of sigmoid function.&quot;&quot;&quot;
    sigmoid_z = self._sigmoid(z)
    return sigmoid_z * (1 - sigmoid_z)

def _relu(self, z: np.ndarray) -&gt; np.ndarray:
    &quot;&quot;&quot;ReLU activation function.&quot;&quot;&quot;
    return np.maximum(0, z)

def _relu_derivative(self, z: np.ndarray) -&gt; np.ndarray:
    &quot;&quot;&quot;Derivative of ReLU function.&quot;&quot;&quot;
    return np.where(z &gt; 0, 1, 0)

def forward_pass(self, X: np.ndarray) -&gt; Dict[str, np.ndarray]:
    &quot;&quot;&quot;
    Perform forward pass through the network.

    Args:
        X: Input data (batch_size, input_size)

    Returns:
        Dictionary containing intermediate values for backpropagation
    &quot;&quot;&quot;

    ## Ensure X is 2D

    if X.ndim == 1:
        X = X.reshape(1, -1)

    ## Layer 1: Input to Hidden

    z1 = np.dot(X, self.W1) + self.b1
    a1 = self._sigmoid(z1)

    ## Layer 2: Hidden to Output

    z2 = np.dot(a1, self.W2) + self.b2
    a2 = self._sigmoid(z2)

    ## Store intermediate values for backpropagation

    cache = {
        &#39;X&#39;: X,
        &#39;z1&#39;: z1,
        &#39;a1&#39;: a1,
        &#39;z2&#39;: z2,
        &#39;a2&#39;: a2
    }

    return cache

def compute_loss(self, predictions: np.ndarray, targets: np.ndarray) -&gt; float:
    &quot;&quot;&quot;
    Compute mean squared error loss.

    Args:
        predictions: Network predictions
        targets: True target values

    Returns:
        Mean squared error
    &quot;&quot;&quot;
    return np.mean((predictions - targets) ** 2)

def backward_pass(self, cache: Dict[str, np.ndarray], targets: np.ndarray) -&gt; Dict[str, np.ndarray]:
    &quot;&quot;&quot;
    Perform backward pass (backpropagation) to compute gradients.

    Args:
        cache: Forward pass intermediate values
        targets: True target values

    Returns:
        Dictionary containing gradients for all parameters
    &quot;&quot;&quot;

    ## Extract values from cache

    X = cache[&#39;X&#39;]
    z1 = cache[&#39;z1&#39;]
    a1 = cache[&#39;a1&#39;]
    z2 = cache[&#39;z2&#39;]
    a2 = cache[&#39;a2&#39;]

    m = X.shape[0]  # batch size

    ## Ensure targets have correct shape

    if targets.ndim == 1:
        targets = targets.reshape(-1, 1)

    ## Output layer gradients (Layer 2)

    dz2 = a2 - targets  # Derivative of MSE w.r.t. z2 (simplified for sigmoid)
    dW2 = np.dot(a1.T, dz2) / m
    db2 = np.mean(dz2, axis=0, keepdims=True)

    ## Hidden layer gradients (Layer 1)

    da1 = np.dot(dz2, self.W2.T)
    dz1 = da1 * self._sigmoid_derivative(z1)
    dW1 = np.dot(X.T, dz1) / m
    db1 = np.mean(dz1, axis=0, keepdims=True)

    gradients = {
        &#39;dW1&#39;: dW1,
        &#39;db1&#39;: db1,
        &#39;dW2&#39;: dW2,
        &#39;db2&#39;: db2
    }

    return gradients

def update_weights(self, gradients: Dict[str, np.ndarray]) -&gt; None:
    &quot;&quot;&quot;
    Update weights using gradient descent.

    Args:
        gradients: Computed gradients for all parameters
    &quot;&quot;&quot;
    self.W1 -= self.learning_rate * gradients[&#39;dW1&#39;]
    self.b1 -= self.learning_rate * gradients[&#39;db1&#39;]
    self.W2 -= self.learning_rate * gradients[&#39;dW2&#39;]
    self.b2 -= self.learning_rate * gradients[&#39;db2&#39;]

def train_epoch(self, X: np.ndarray, y: np.ndarray) -&gt; Dict[str, float]:
    &quot;&quot;&quot;
    Train for one epoch (one pass through all data).

    Args:
        X: Training features
        y: Training targets

    Returns:
        Training statistics for this epoch
    &quot;&quot;&quot;

    ## Forward pass

    cache = self.forward_pass(X)
    predictions = cache[&#39;a2&#39;]

    ## Compute loss

    loss = self.compute_loss(predictions, y)

    ## Backward pass

    gradients = self.backward_pass(cache, y)

    ## Update weights

    self.update_weights(gradients)

    ## Compute accuracy (for classification problems)

    if self.output_size == 1:  # Binary classification
        accuracy = np.mean((predictions &gt; 0.5) == (y &gt; 0.5))
    else:  # Multi-class classification
        predicted_classes = np.argmax(predictions, axis=1)
        true_classes = np.argmax(y, axis=1) if y.shape[1] &gt; 1 else y
        accuracy = np.mean(predicted_classes == true_classes)

    return {
        &#39;loss&#39;: loss,
        &#39;accuracy&#39;: accuracy,
        &#39;predictions&#39;: predictions
    }

def fit(self, X: np.ndarray, y: np.ndarray, epochs: int = 100, verbose: bool = True) -&gt; Dict[str, Any]:
    &quot;&quot;&quot;
    Train the MLP for specified number of epochs.

    Args:
        X: Training features
        y: Training targets
        epochs: Number of training epochs
        verbose: Whether to print training progress

    Returns:
        Training history and statistics
    &quot;&quot;&quot;

    ## Ensure proper shapes

    if X.ndim == 1:
        X = X.reshape(-1, 1)
    if y.ndim == 1:
        y = y.reshape(-1, 1)

    self.training_history = []

    for epoch in range(epochs):

        ## Train one epoch

        epoch_stats = self.train_epoch(X, y)

        ## Add epoch number

        epoch_stats[&#39;epoch&#39;] = epoch + 1

        ## Store training history

        self.training_history.append(epoch_stats)

        ## Print progress

        if verbose and (epoch + 1) % max(1, epochs // 10) == 0:
            print(f&quot;Epoch {epoch + 1:3d}/{epochs}: Loss = {epoch_stats[&#39;loss&#39;]:.4f}, Accuracy = {epoch_stats[&#39;accuracy&#39;]:.3f}&quot;)

    self.trained = True

    return {
        &#39;training_history&#39;: self.training_history,
        &#39;final_loss&#39;: self.training_history[-1][&#39;loss&#39;],
        &#39;final_accuracy&#39;: self.training_history[-1][&#39;accuracy&#39;]
    }

def predict(self, X: np.ndarray) -&gt; np.ndarray:
    &quot;&quot;&quot;Make predictions on new data.&quot;&quot;&quot;
    if not self.trained:
        raise ValueError(&quot;MLP must be trained before making predictions&quot;)

    cache = self.forward_pass(X)
    return cache[&#39;a2&#39;]

def get_weights_info(self) -&gt; Dict[str, Any]:
    &quot;&quot;&quot;Get information about current weights.&quot;&quot;&quot;
    return {
        &#39;W1_shape&#39;: self.W1.shape,
        &#39;W1_mean&#39;: np.mean(self.W1),
        &#39;W1_std&#39;: np.std(self.W1),
        &#39;W2_shape&#39;: self.W2.shape,
        &#39;W2_mean&#39;: np.mean(self.W2),
        &#39;W2_std&#39;: np.std(self.W2),
        &#39;total_parameters&#39;: self.W1.size + self.b1.size + self.W2.size + self.b2.size
    }
</code></pre></div>
<p>def demonstrate_tiny_mlp():
    &ldquo;&rdquo;&ldquo;Demonstrate tiny MLP with XOR problem and other examples.&rdquo;&ldquo;&rdquo;
    print(&ldquo;nTiny Multi-Layer Perceptron Demonstration&rdquo;)
    print(&ldquo;=&rdquo; * 41)</p>
<div class="language-text highlight"><pre><span></span><code>## Example 1: XOR Problem (the classic MLP success story)

print(&quot;\n1. XOR Problem - MLP Success&quot;)
print(&quot;-&quot; * 30)

## XOR data

X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_xor = np.array([[0], [1], [1], [0]])

## Create and train tiny MLP

mlp_xor = TinyMLP(input_size=2, hidden_size=4, output_size=1, learning_rate=1.0)

print(&quot;Training MLP on XOR problem...&quot;)
training_stats = mlp_xor.fit(X_xor, y_xor, epochs=1000, verbose=False)

print(f&quot;Training completed:&quot;)
print(f&quot;  Final loss: {training_stats[&#39;final_loss&#39;]:.4f}&quot;)
print(f&quot;  Final accuracy: {training_stats[&#39;final_accuracy&#39;]:.3f}&quot;)

## Test XOR predictions

predictions = mlp_xor.predict(X_xor)
print(f&quot;\nXOR Results:&quot;)
for i, (inputs, target, pred) in enumerate(zip(X_xor, y_xor, predictions)):
    pred_binary = 1 if pred[0] &gt; 0.5 else 0
    correct = &quot;‚úì&quot; if pred_binary == target[0] else &quot;‚úó&quot;
    print(f&quot;  {inputs[0]} XOR {inputs[1]} = {target[0]} (predicted: {pred[0]:.3f} ‚Üí {pred_binary}) {correct}&quot;)

## Show weight information

weights_info = mlp_xor.get_weights_info()
print(f&quot;\nNetwork Architecture:&quot;)
print(f&quot;  Hidden layer weights: {weights_info[&#39;W1_shape&#39;]}&quot;)
print(f&quot;  Output layer weights: {weights_info[&#39;W2_shape&#39;]}&quot;)
print(f&quot;  Total parameters: {weights_info[&#39;total_parameters&#39;]}&quot;)

## Example 2: Simple 2D Classification

print(f&quot;\n2. 2D Non-linear Classification&quot;)
print(&quot;-&quot; * 32)

## Generate non-linearly separable data (circular pattern)

np.random.seed(42)
n_samples = 100

## Inner circle (class 0)

r_inner = np.random.uniform(0, 1.5, n_samples // 2)
theta_inner = np.random.uniform(0, 2*np.pi, n_samples // 2)
x_inner = r_inner * np.cos(theta_inner)
y_inner = r_inner * np.sin(theta_inner)

## Outer circle (class 1)

r_outer = np.random.uniform(2.5, 4, n_samples // 2)
theta_outer = np.random.uniform(0, 2*np.pi, n_samples // 2)
x_outer = r_outer * np.cos(theta_outer)
y_outer = r_outer * np.sin(theta_outer)

## Combine data

X_circle = np.column_stack([
    np.concatenate([x_inner, x_outer]),
    np.concatenate([y_inner, y_outer])
])
y_circle = np.concatenate([np.zeros(n_samples // 2), np.ones(n_samples // 2)])

## Shuffle

indices = np.random.permutation(n_samples)
X_circle = X_circle[indices]
y_circle = y_circle[indices].reshape(-1, 1)

## Create and train MLP

mlp_circle = TinyMLP(input_size=2, hidden_size=8, output_size=1, learning_rate=0.5)

print(&quot;Training MLP on circular classification...&quot;)
circle_stats = mlp_circle.fit(X_circle, y_circle, epochs=500, verbose=False)

print(f&quot;Training completed:&quot;)
print(f&quot;  Final loss: {circle_stats[&#39;final_loss&#39;]:.4f}&quot;)
print(f&quot;  Final accuracy: {circle_stats[&#39;final_accuracy&#39;]:.3f}&quot;)

## Test on specific points

test_points = np.array([[0, 0], [3, 0], [0, 3], [-2, -2]])
test_predictions = mlp_circle.predict(test_points)

print(f&quot;\nTest Predictions:&quot;)
for point, pred in zip(test_points, test_predictions):
    class_pred = &quot;Outer&quot; if pred[0] &gt; 0.5 else &quot;Inner&quot;
    print(f&quot;  Point {point}: {class_pred} circle (confidence: {pred[0]:.3f})&quot;)

## Example 3: Function Approximation

print(f&quot;\n3. Function Approximation&quot;)
print(&quot;-&quot; * 26)

## Generate data for a non-linear function: y = sin(x) + 0.5*cos(2x)

X_func = np.linspace(-2*np.pi, 2*np.pi, 100).reshape(-1, 1)
y_func = np.sin(X_func) + 0.5 * np.cos(2 * X_func) + 0.1 * np.random.normal(0, 1, X_func.shape)

## Normalize inputs for better training

X_func_norm = (X_func - np.mean(X_func)) / np.std(X_func)

## Create and train MLP for regression

mlp_func = TinyMLP(input_size=1, hidden_size=10, output_size=1, learning_rate=0.01)

print(&quot;Training MLP for function approximation...&quot;)
func_stats = mlp_func.fit(X_func_norm, y_func, epochs=1000, verbose=False)

print(f&quot;Training completed:&quot;)
print(f&quot;  Final loss: {func_stats[&#39;final_loss&#39;]:.4f}&quot;)

## Test function approximation

test_x = np.array([[-1], [0], [1]]) # Normalized test points
test_predictions = mlp_func.predict(test_x)
actual_x = test_x * np.std(X_func) + np.mean(X_func)  # Denormalize for display

print(f&quot;\nFunction Approximation Results:&quot;)
for x_norm, x_actual, pred in zip(test_x, actual_x, test_predictions):
    actual_y = np.sin(x_actual) + 0.5 * np.cos(2 * x_actual)
    error = abs(pred[0] - actual_y[0])
    print(f&quot;  x = {x_actual[0]:.2f}: predicted = {pred[0]:.3f}, actual ‚âà {actual_y[0]:.3f} (error: {error:.3f})&quot;)

return mlp_xor, mlp_circle, mlp_func
</code></pre></div>
<hr />
<h2 id="part-3-training-loop-intuition">Part 3: Training Loop Intuition<a class="headerlink" href="#part-3-training-loop-intuition" title="Permanent link">&para;</a></h2>
<h3 id="understanding-the-training-process">Understanding the Training Process<a class="headerlink" href="#understanding-the-training-process" title="Permanent link">&para;</a></h3>
<p>The training loop is the heart of neural network learning. Understanding how weights evolve, loss decreases, and the network learns patterns is crucial for developing intuition about neural network behavior.</p>
<p><strong>Training Loop Components:</strong></p>
<ol>
<li>
<p><strong>Initialization</strong>: Random weights start the process</p>
</li>
<li>
<p><strong>Forward Pass</strong>: Compute predictions with current weights</p>
</li>
<li>
<p><strong>Loss Calculation</strong>: Measure prediction error</p>
</li>
<li>
<p><strong>Backward Pass</strong>: Compute how to adjust weights</p>
</li>
<li>
<p><strong>Weight Update</strong>: Apply gradient descent</p>
</li>
<li>
<p><strong>Repeat</strong>: Until convergence or max epochs</p>
</li>
</ol>
<h3 id="training-analysis-tools">Training Analysis Tools<a class="headerlink" href="#training-analysis-tools" title="Permanent link">&para;</a></h3>
<p>```python
class TrainingAnalyzer:
    &ldquo;&rdquo;&rdquo;
    Tools for analyzing and visualizing neural network training.
    Helps build intuition about the learning process.
    &ldquo;&rdquo;&ldquo;</p>
<div class="language-text highlight"><pre><span></span><code>def __init__(self):
    self.training_logs = []

def log_training_step(self, epoch: int, weights: Dict, gradients: Dict, loss: float, accuracy: float):
    &quot;&quot;&quot;Log detailed training step information.&quot;&quot;&quot;
    log_entry = {
        &#39;epoch&#39;: epoch,
        &#39;loss&#39;: loss,
        &#39;accuracy&#39;: accuracy,
        &#39;weights&#39;: {k: v.copy() for k, v in weights.items()},
        &#39;gradients&#39;: {k: v.copy() for k, v in gradients.items()},
        &#39;weight_norms&#39;: {k: np.linalg.norm(v) for k, v in weights.items()},
        &#39;gradient_norms&#39;: {k: np.linalg.norm(v) for k, v in gradients.items()}
    }
    self.training_logs.append(log_entry)

def analyze_convergence(self) -&gt; Dict[str, Any]:
    &quot;&quot;&quot;Analyze convergence patterns in training.&quot;&quot;&quot;
    if not self.training_logs:
        return {}

    losses = [log[&#39;loss&#39;] for log in self.training_logs]
    accuracies = [log[&#39;accuracy&#39;] for log in self.training_logs]

    ## Find convergence point (where loss stops decreasing significantly)

    convergence_epoch = None
    loss_threshold = 0.001  # Minimum loss decrease to consider significant

    for i in range(10, len(losses)):
        recent_improvement = losses[i-10] - losses[i]
        if recent_improvement &lt; loss_threshold:
            convergence_epoch = i
            break

    ## Analyze weight evolution

    weight_evolution = {}
    for weight_name in self.training_logs[0][&#39;weights&#39;].keys():
        weight_norms = [log[&#39;weight_norms&#39;][weight_name] for log in self.training_logs]
        weight_evolution[weight_name] = {
            &#39;initial_norm&#39;: weight_norms[0],
            &#39;final_norm&#39;: weight_norms[-1],
            &#39;change_ratio&#39;: weight_norms[-1] / weight_norms[0] if weight_norms[0] &gt; 0 else 0
        }

    return {
        &#39;convergence_epoch&#39;: convergence_epoch,
        &#39;final_loss&#39;: losses[-1],
        &#39;final_accuracy&#39;: accuracies[-1],
        &#39;loss_reduction&#39;: losses[0] - losses[-1],
        &#39;weight_evolution&#39;: weight_evolution,
        &#39;training_stable&#39;: np.std(losses[-10:]) &lt; 0.01 if len(losses) &gt;= 10 else False
    }

def get_training_dynamics(self) -&gt; Dict[str, List]:
    &quot;&quot;&quot;Get training dynamics for visualization.&quot;&quot;&quot;
    return {
        &#39;epochs&#39;: [log[&#39;epoch&#39;] for log in self.training_logs],
        &#39;losses&#39;: [log[&#39;loss&#39;] for log in self.training_logs],
        &#39;accuracies&#39;: [log[&#39;accuracy&#39;] for log in self.training_logs],
        &#39;weight_norms&#39;: {
            name: [log[&#39;weight_norms&#39;][name] for log in self.training_logs]
            for name in self.training_logs[0][&#39;weight_norms&#39;].keys()
        },
        &#39;gradient_norms&#39;: {
            name: [log[&#39;gradient_norms&#39;][name] for log in self.training_logs]
            for name in self.training_logs[0][&#39;gradient_norms&#39;].keys()
        }
    }
</code></pre></div>
<p>class InstrumentedTinyMLP(TinyMLP):
    &ldquo;&rdquo;&rdquo;
    Extended TinyMLP with detailed training analysis capabilities.
    Logs training dynamics for educational insight.
    &ldquo;&rdquo;&ldquo;</p>
<div class="language-text highlight"><pre><span></span><code>def __init__(self, *args, **kwargs):
    super().__init__(*args, **kwargs)
    self.analyzer = TrainingAnalyzer()

def train_epoch_instrumented(self, X: np.ndarray, y: np.ndarray, epoch: int) -&gt; Dict[str, float]:
    &quot;&quot;&quot;Enhanced training epoch with detailed logging.&quot;&quot;&quot;

    ## Forward pass

    cache = self.forward_pass(X)
    predictions = cache[&#39;a2&#39;]

    ## Compute loss

    loss = self.compute_loss(predictions, y)

    ## Backward pass

    gradients = self.backward_pass(cache, y)

    ## Log before weight update

    weights = {&#39;W1&#39;: self.W1, &#39;b1&#39;: self.b1, &#39;W2&#39;: self.W2, &#39;b2&#39;: self.b2}

    ## Compute accuracy

    if self.output_size == 1:
        accuracy = np.mean((predictions &gt; 0.5) == (y &gt; 0.5))
    else:
        predicted_classes = np.argmax(predictions, axis=1)
        true_classes = np.argmax(y, axis=1) if y.shape[1] &gt; 1 else y
        accuracy = np.mean(predicted_classes == true_classes)

    ## Log training step

    self.analyzer.log_training_step(epoch, weights, gradients, loss, accuracy)

    ## Update weights

    self.update_weights(gradients)

    return {
        &#39;loss&#39;: loss,
        &#39;accuracy&#39;: accuracy,
        &#39;predictions&#39;: predictions
    }

def fit_with_analysis(self, X: np.ndarray, y: np.ndarray, epochs: int = 100, verbose: bool = True) -&gt; Dict[str, Any]:
    &quot;&quot;&quot;Train with detailed analysis logging.&quot;&quot;&quot;
    if X.ndim == 1:
        X = X.reshape(-1, 1)
    if y.ndim == 1:
        y = y.reshape(-1, 1)

    self.training_history = []

    for epoch in range(epochs):
        epoch_stats = self.train_epoch_instrumented(X, y, epoch + 1)
        epoch_stats[&#39;epoch&#39;] = epoch + 1
        self.training_history.append(epoch_stats)

        if verbose and (epoch + 1) % max(1, epochs // 10) == 0:
            print(f&quot;Epoch {epoch + 1:3d}/{epochs}: Loss = {epoch_stats[&#39;loss&#39;]:.4f}, Accuracy = {epoch_stats[&#39;accuracy&#39;]:.3f}&quot;)

    self.trained = True

    ## Analyze training

    convergence_analysis = self.analyzer.analyze_convergence()

    return {
        &#39;training_history&#39;: self.training_history,
        &#39;final_loss&#39;: self.training_history[-1][&#39;loss&#39;],
        &#39;final_accuracy&#39;: self.training_history[-1][&#39;accuracy&#39;],
        &#39;convergence_analysis&#39;: convergence_analysis
    }
</code></pre></div>
<p>def demonstrate_training_loop_intuition():
    &ldquo;&rdquo;&ldquo;Demonstrate training loop dynamics and intuition.&rdquo;&ldquo;&rdquo;
    print(&ldquo;nTraining Loop Intuition Demonstration&rdquo;)
    print(&ldquo;=&rdquo; * 37)</p>
<div class="language-text highlight"><pre><span></span><code>## Example 1: Weight Evolution During Training

print(&quot;\n1. Weight Evolution Analysis&quot;)
print(&quot;-&quot; * 28)

## Use XOR problem with detailed analysis

X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_xor = np.array([[0], [1], [1], [0]])

## Create instrumented MLP

mlp_analyzed = InstrumentedTinyMLP(input_size=2, hidden_size=3, output_size=1, learning_rate=2.0)

print(&quot;Training XOR with weight analysis...&quot;)
analysis_results = mlp_analyzed.fit_with_analysis(X_xor, y_xor, epochs=300, verbose=False)

## Display convergence analysis

convergence = analysis_results[&#39;convergence_analysis&#39;]
print(f&quot;\nConvergence Analysis:&quot;)
print(f&quot;  Converged at epoch: {convergence.get(&#39;convergence_epoch&#39;, &#39;Not converged&#39;)}&quot;)
print(f&quot;  Final loss: {convergence[&#39;final_loss&#39;]:.4f}&quot;)
print(f&quot;  Loss reduction: {convergence[&#39;loss_reduction&#39;]:.4f}&quot;)
print(f&quot;  Training stable: {convergence[&#39;training_stable&#39;]}&quot;)

## Weight evolution

print(f&quot;\nWeight Evolution:&quot;)
for weight_name, evolution in convergence[&#39;weight_evolution&#39;].items():
    print(f&quot;  {weight_name}: {evolution[&#39;initial_norm&#39;]:.3f} ‚Üí {evolution[&#39;final_norm&#39;]:.3f} &quot;
          f&quot;(ratio: {evolution[&#39;change_ratio&#39;]:.2f})&quot;)

## Example 2: Learning Rate Impact

print(f&quot;\n2. Learning Rate Impact&quot;)
print(&quot;-&quot; * 24)

learning_rates = [0.1, 1.0, 5.0, 10.0]
lr_results = {}

for lr in learning_rates:
    mlp_lr = TinyMLP(input_size=2, hidden_size=4, output_size=1, learning_rate=lr)

    ## Train with current learning rate

    lr_stats = mlp_lr.fit(X_xor, y_xor, epochs=200, verbose=False)

    lr_results[lr] = {
        &#39;final_loss&#39;: lr_stats[&#39;final_loss&#39;],
        &#39;final_accuracy&#39;: lr_stats[&#39;final_accuracy&#39;],
        &#39;converged&#39;: lr_stats[&#39;final_loss&#39;] &lt; 0.1
    }

print(&quot;Learning Rate Impact on XOR Learning:&quot;)
print(&quot;  LR     | Final Loss | Accuracy | Converged&quot;)
print(&quot;  -------|------------|----------|----------&quot;)
for lr, results in lr_results.items():
    converged_str = &quot;Yes&quot; if results[&#39;converged&#39;] else &quot;No&quot;
    print(f&quot;  {lr:5.1f}  |   {results[&#39;final_loss&#39;]:6.3f}   |  {results[&#39;final_accuracy&#39;]:6.3f}  |    {converged_str}&quot;)

## Example 3: Hidden Layer Size Impact

print(f&quot;\n3. Hidden Layer Size Impact&quot;)
print(&quot;-&quot; * 29)

hidden_sizes = [2, 3, 4, 8, 16]
size_results = {}

for hidden_size in hidden_sizes:
    mlp_size = TinyMLP(input_size=2, hidden_size=hidden_size, output_size=1, learning_rate=1.0)

    size_stats = mlp_size.fit(X_xor, y_xor, epochs=500, verbose=False)

    ## Count parameters

    total_params = (2 * hidden_size + hidden_size) + (hidden_size * 1 + 1)

    size_results[hidden_size] = {
        &#39;final_loss&#39;: size_stats[&#39;final_loss&#39;],
        &#39;final_accuracy&#39;: size_stats[&#39;final_accuracy&#39;],
        &#39;total_params&#39;: total_params,
        &#39;converged&#39;: size_stats[&#39;final_loss&#39;] &lt; 0.1
    }

print(&quot;Hidden Layer Size Impact:&quot;)
print(&quot;  Size | Params | Final Loss | Accuracy | Converged&quot;)
print(&quot;  -----|--------|------------|----------|----------&quot;)
for size, results in size_results.items():
    converged_str = &quot;Yes&quot; if results[&#39;converged&#39;] else &quot;No&quot;
    print(f&quot;  {size:3d}  |   {results[&#39;total_params&#39;]:3d}  |   {results[&#39;final_loss&#39;]:6.3f}   |  {results[&#39;final_accuracy&#39;]:6.3f}  |    {converged_str}&quot;)

## Example 4: Training Dynamics Visualization (text-based)

print(f&quot;\n4. Training Dynamics Analysis&quot;)
print(&quot;-&quot; * 31)

## Get training dynamics from analyzed MLP

dynamics = mlp_analyzed.analyzer.get_training_dynamics()

## Show loss progression (every 30 epochs)

print(&quot;Loss Progression (every 30 epochs):&quot;)
epochs = dynamics[&#39;epochs&#39;]
losses = dynamics[&#39;losses&#39;]

step = max(1, len(epochs) // 10)
print(&quot;  Epoch | Loss&quot;)
print(&quot;  ------|-------&quot;)
for i in range(0, len(epochs), step):
    print(f&quot;  {epochs[i]:5d} | {losses[i]:.4f}&quot;)

## Weight norm evolution

print(f&quot;\nWeight Norm Evolution:&quot;)
weight_norms = dynamics[&#39;weight_norms&#39;]

for weight_name, norms in weight_norms.items():
    initial_norm = norms[0]
    final_norm = norms[-1]
    max_norm = max(norms)
    print(f&quot;  {weight_name}: {initial_norm:.3f} ‚Üí {final_norm:.3f} (max: {max_norm:.3f})&quot;)

## Example 5: Common Training Issues

print(f&quot;\n5. Common Training Issues&quot;)
print(&quot;-&quot; * 26)

## Issue 1: Learning rate too high (oscillation)

print(&quot;a) Learning Rate Too High (Oscillation):&quot;)
mlp_oscillate = TinyMLP(input_size=2, hidden_size=4, output_size=1, learning_rate=20.0)
osc_stats = mlp_oscillate.fit(X_xor, y_xor, epochs=100, verbose=False)

losses_osc = [stats[&#39;loss&#39;] for stats in mlp_oscillate.training_history]
loss_variance = np.var(losses_osc[-20:]) if len(losses_osc) &gt;= 20 else 0

print(f&quot;  Final loss: {osc_stats[&#39;final_loss&#39;]:.4f}&quot;)
print(f&quot;  Loss variance (last 20 epochs): {loss_variance:.4f}&quot;)
print(f&quot;  Diagnosis: {&#39;Oscillating&#39; if loss_variance &gt; 0.1 else &#39;Stable&#39;}&quot;)

## Issue 2: Learning rate too low (slow convergence)

print(f&quot;\nb) Learning Rate Too Low (Slow Convergence):&quot;)
mlp_slow = TinyMLP(input_size=2, hidden_size=4, output_size=1, learning_rate=0.01)
slow_stats = mlp_slow.fit(X_xor, y_xor, epochs=100, verbose=False)

print(f&quot;  Final loss: {slow_stats[&#39;final_loss&#39;]:.4f}&quot;)
print(f&quot;  Final accuracy: {slow_stats[&#39;final_accuracy&#39;]:.3f}&quot;)
print(f&quot;  Diagnosis: {&#39;Needs more epochs&#39; if slow_stats[&#39;final_loss&#39;] &gt; 0.5 else &#39;Adequate&#39;}&quot;)

## Issue 3: Insufficient capacity

print(f&quot;\nc) Insufficient Network Capacity:&quot;)
mlp_small = TinyMLP(input_size=2, hidden_size=1, output_size=1, learning_rate=1.0)
small_stats = mlp_small.fit(X_xor, y_xor, epochs=500, verbose=False)

print(f&quot;  Final loss: {small_stats[&#39;final_loss&#39;]:.4f}&quot;)
print(f&quot;  Final accuracy: {small_stats[&#39;final_accuracy&#39;]:.3f}&quot;)
print(f&quot;  Diagnosis: {&#39;Insufficient capacity&#39; if small_stats[&#39;final_accuracy&#39;] &lt; 0.8 else &#39;Adequate&#39;}&quot;)

return mlp_analyzed, lr_results, size_results
</code></pre></div>
<hr />
<h2 id="part-4-practical-applications-and-behavior-reasoning">Part 4: Practical Applications and Behavior Reasoning<a class="headerlink" href="#part-4-practical-applications-and-behavior-reasoning" title="Permanent link">&para;</a></h2>
<h3 id="understanding-neural-network-behavior">Understanding Neural Network Behavior<a class="headerlink" href="#understanding-neural-network-behavior" title="Permanent link">&para;</a></h3>
<p>To effectively use neural networks in automation systems, we must understand how they make decisions, what patterns they learn, and how to interpret their behavior.</p>
<p><strong>Key Behavioral Concepts:</strong></p>
<ul>
<li>
<p><strong>Feature Learning</strong>: Hidden layers learn useful representations</p>
</li>
<li>
<p><strong>Decision Boundaries</strong>: Networks create complex decision regions</p>
</li>
<li>
<p><strong>Generalization</strong>: Ability to perform well on unseen data</p>
</li>
<li>
<p><strong>Interpretability</strong>: Understanding what the network has learned</p>
</li>
</ul>
<h3 id="behavior-analysis-tools">Behavior Analysis Tools<a class="headerlink" href="#behavior-analysis-tools" title="Permanent link">&para;</a></h3>
<p>```python</p>
<p>class NetworkBehaviorAnalyzer:
    &ldquo;&rdquo;&rdquo;
    Tools for understanding and interpreting neural network behavior.
    Helps reason about what networks learn and how they make decisions.
    &ldquo;&rdquo;&ldquo;</p>
<div class="language-text highlight"><pre><span></span><code>def __init__(self, mlp: TinyMLP):
    self.mlp = mlp

def analyze_hidden_layer_activations(self, X: np.ndarray) -&gt; Dict[str, Any]:
    &quot;&quot;&quot;
    Analyze what the hidden layer learns by examining activations.

    Args:
        X: Input data to analyze

    Returns:
        Analysis of hidden layer behavior
    &quot;&quot;&quot;
    if not self.mlp.trained:
        raise ValueError(&quot;MLP must be trained before analysis&quot;)

    ## Get hidden layer activations

    cache = self.mlp.forward_pass(X)
    hidden_activations = cache[&#39;a1&#39;]

    ## Analyze each hidden neuron

    neuron_analysis = {}
    for i in range(hidden_activations.shape[1]):
        neuron_i_activations = hidden_activations[:, i]

        neuron_analysis[f&#39;neuron_{i}&#39;] = {
            &#39;mean_activation&#39;: np.mean(neuron_i_activations),
            &#39;activation_range&#39;: [np.min(neuron_i_activations), np.max(neuron_i_activations)],
            &#39;activation_variance&#39;: np.var(neuron_i_activations),
            &#39;never_activates&#39;: np.max(neuron_i_activations) &lt; 0.1,
            &#39;always_saturated&#39;: np.min(neuron_i_activations) &gt; 0.9
        }

    return {
        &#39;hidden_activations&#39;: hidden_activations,
        &#39;neuron_analysis&#39;: neuron_analysis,
        &#39;num_dead_neurons&#39;: sum(1 for analysis in neuron_analysis.values() 
                               if analysis[&#39;never_activates&#39;]),
        &#39;num_saturated_neurons&#39;: sum(1 for analysis in neuron_analysis.values() 
                                    if analysis[&#39;always_saturated&#39;])
    }

def analyze_weight_patterns(self) -&gt; Dict[str, Any]:
    &quot;&quot;&quot;Analyze learned weight patterns for insights.&quot;&quot;&quot;
    if not self.mlp.trained:
        raise ValueError(&quot;MLP must be trained before analysis&quot;)

    ## Input to hidden weights analysis

    W1_analysis = {
        &#39;weight_matrix_shape&#39;: self.mlp.W1.shape,
        &#39;weight_statistics&#39;: {
            &#39;mean&#39;: np.mean(self.mlp.W1),
            &#39;std&#39;: np.std(self.mlp.W1),
            &#39;min&#39;: np.min(self.mlp.W1),
            &#39;max&#39;: np.max(self.mlp.W1)
        },
        &#39;neuron_weight_norms&#39;: [np.linalg.norm(self.mlp.W1[:, i]) 
                               for i in range(self.mlp.W1.shape[1])]
    }

    ## Hidden to output weights analysis

    W2_analysis = {
        &#39;weight_vector_shape&#39;: self.mlp.W2.shape,
        &#39;weight_statistics&#39;: {
            &#39;mean&#39;: np.mean(self.mlp.W2),
            &#39;std&#39;: np.std(self.mlp.W2),
            &#39;min&#39;: np.min(self.mlp.W2),
            &#39;max&#39;: np.max(self.mlp.W2)
        }
    }

    return {
        &#39;input_to_hidden&#39;: W1_analysis,
        &#39;hidden_to_output&#39;: W2_analysis
    }

def create_decision_boundary_analysis(self, X: np.ndarray, resolution: int = 50) -&gt; Dict[str, Any]:
    &quot;&quot;&quot;
    Create a grid analysis to understand decision boundaries.

    Args:
        X: Training data to determine grid bounds
        resolution: Grid resolution for analysis

    Returns:
        Decision boundary analysis
    &quot;&quot;&quot;
    if X.shape[1] != 2:
        raise ValueError(&quot;Decision boundary analysis only supported for 2D input&quot;)

    ## Create grid

    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1

    xx, yy = np.meshgrid(
        np.linspace(x_min, x_max, resolution),
        np.linspace(y_min, y_max, resolution)
    )

    ## Get predictions for grid points

    grid_points = np.column_stack([xx.ravel(), yy.ravel()])
    predictions = self.mlp.predict(grid_points)

    ## Reshape predictions to grid

    prediction_grid = predictions.reshape(xx.shape)

    return {
        &#39;x_grid&#39;: xx,
        &#39;y_grid&#39;: yy,
        &#39;prediction_grid&#39;: prediction_grid,
        &#39;decision_boundary_complexity&#39;: np.var(prediction_grid)
    }

def interpret_xor_solution(self, X_xor: np.ndarray, y_xor: np.ndarray) -&gt; Dict[str, Any]:
    &quot;&quot;&quot;
    Specific analysis for XOR problem to understand how MLP solves it.

    Args:
        X_xor: XOR input data
        y_xor: XOR target data

    Returns:
        Interpretation of XOR solution
    &quot;&quot;&quot;
    if not self.mlp.trained:
        raise ValueError(&quot;MLP must be trained before analysis&quot;)

    ## Get hidden layer activations for XOR inputs

    cache = self.mlp.forward_pass(X_xor)
    hidden_activations = cache[&#39;a1&#39;]
    final_outputs = cache[&#39;a2&#39;]

    ## Analyze how each hidden neuron responds to XOR inputs

    neuron_responses = {}
    for i in range(hidden_activations.shape[1]):
        responses = hidden_activations[:, i]
        neuron_responses[f&#39;hidden_neuron_{i}&#39;] = {
            &#39;input_00&#39;: responses[0],
            &#39;input_01&#39;: responses[1],
            &#39;input_10&#39;: responses[2],
            &#39;input_11&#39;: responses[3],
            &#39;pattern_type&#39;: self._classify_xor_pattern(responses)
        }

    return {
        &#39;hidden_responses&#39;: neuron_responses,
        &#39;final_outputs&#39;: final_outputs.flatten(),
        &#39;solution_interpretation&#39;: self._interpret_xor_strategy(neuron_responses)
    }

def _classify_xor_pattern(self, responses: np.ndarray) -&gt; str:
    &quot;&quot;&quot;Classify the pattern learned by a hidden neuron.&quot;&quot;&quot;

    ## Check for common XOR decomposition patterns

    if responses[0] &lt; 0.5 and responses[1] &gt; 0.5 and responses[2] &gt; 0.5 and responses[3] &lt; 0.5:
        return &quot;XOR-like&quot;
    elif responses[0] &gt; 0.5 and responses[1] &lt; 0.5 and responses[2] &lt; 0.5 and responses[3] &gt; 0.5:
        return &quot;XNOR-like&quot;
    elif responses[0] &lt; 0.5 and responses[1] &gt; 0.5 and responses[2] &gt; 0.5 and responses[3] &gt; 0.5:
        return &quot;OR-like&quot;
    elif responses[0] &lt; 0.5 and responses[1] &lt; 0.5 and responses[2] &lt; 0.5 and responses[3] &gt; 0.5:
        return &quot;AND-like&quot;
    else:
        return &quot;Complex&quot;

def _interpret_xor_strategy(self, neuron_responses: Dict) -&gt; str:
    &quot;&quot;&quot;Interpret the overall strategy used to solve XOR.&quot;&quot;&quot;
    patterns = [info[&#39;pattern_type&#39;] for info in neuron_responses.values()]

    if &#39;XOR-like&#39; in patterns or &#39;XNOR-like&#39; in patterns:
        return &quot;Direct XOR decomposition&quot;
    elif &#39;OR-like&#39; in patterns and &#39;AND-like&#39; in patterns:
        return &quot;OR/AND combination strategy&quot;
    else:
        return &quot;Complex non-linear combination&quot;
</code></pre></div>
<p>def demonstrate_behavior_reasoning():
    &ldquo;&rdquo;&ldquo;Demonstrate neural network behavior analysis and reasoning.&rdquo;&ldquo;&rdquo;
    print(&ldquo;nNeural Network Behavior Reasoning&rdquo;)
    print(&ldquo;=&rdquo; * 35)</p>
<div class="language-text highlight"><pre><span></span><code>## Example 1: XOR Solution Analysis

print(&quot;\n1. XOR Solution Analysis&quot;)
print(&quot;-&quot; * 25)

## Train MLP on XOR

X_xor = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y_xor = np.array([[0], [1], [1], [0]])

mlp_xor_analysis = TinyMLP(input_size=2, hidden_size=4, output_size=1, learning_rate=1.5)
mlp_xor_analysis.fit(X_xor, y_xor, epochs=500, verbose=False)

## Analyze behavior

analyzer = NetworkBehaviorAnalyzer(mlp_xor_analysis)

## Hidden layer activation analysis

activation_analysis = analyzer.analyze_hidden_layer_activations(X_xor)

print(&quot;Hidden Layer Activation Analysis:&quot;)
for neuron_name, analysis in activation_analysis[&#39;neuron_analysis&#39;].items():
    print(f&quot;  {neuron_name}:&quot;)
    print(f&quot;    Mean activation: {analysis[&#39;mean_activation&#39;]:.3f}&quot;)
    print(f&quot;    Activation range: [{analysis[&#39;activation_range&#39;][0]:.3f}, {analysis[&#39;activation_range&#39;][1]:.3f}]&quot;)
    print(f&quot;    Dead neuron: {analysis[&#39;never_activates&#39;]}&quot;)
    print(f&quot;    Saturated: {analysis[&#39;always_saturated&#39;]}&quot;)

print(f&quot;\nNetwork Health:&quot;)
print(f&quot;  Dead neurons: {activation_analysis[&#39;num_dead_neurons&#39;]}&quot;)
print(f&quot;  Saturated neurons: {activation_analysis[&#39;num_saturated_neurons&#39;]}&quot;)

## XOR-specific interpretation

xor_interpretation = analyzer.interpret_xor_solution(X_xor, y_xor)

print(f&quot;\nXOR Solution Strategy:&quot;)
print(f&quot;  {xor_interpretation[&#39;solution_interpretation&#39;]}&quot;)

print(f&quot;\nHidden Neuron Patterns:&quot;)
for neuron, response in xor_interpretation[&#39;hidden_responses&#39;].items():
    print(f&quot;  {neuron}: {response[&#39;pattern_type&#39;]}&quot;)
    print(f&quot;    Responses: [0,0]‚Üí{response[&#39;input_00&#39;]:.2f}, [0,1]‚Üí{response[&#39;input_01&#39;]:.2f}, &quot;
          f&quot;[1,0]‚Üí{response[&#39;input_10&#39;]:.2f}, [1,1]‚Üí{response[&#39;input_11&#39;]:.2f}&quot;)

## Example 2: Weight Pattern Analysis

print(f&quot;\n2. Weight Pattern Analysis&quot;)
print(&quot;-&quot; * 26)

weight_analysis = analyzer.analyze_weight_patterns()

print(&quot;Input-to-Hidden Weights:&quot;)
W1_stats = weight_analysis[&#39;input_to_hidden&#39;][&#39;weight_statistics&#39;]
print(f&quot;  Shape: {weight_analysis[&#39;input_to_hidden&#39;][&#39;weight_matrix_shape&#39;]}&quot;)
print(f&quot;  Mean: {W1_stats[&#39;mean&#39;]:.3f}, Std: {W1_stats[&#39;std&#39;]:.3f}&quot;)
print(f&quot;  Range: [{W1_stats[&#39;min&#39;]:.3f}, {W1_stats[&#39;max&#39;]:.3f}]&quot;)

print(f&quot;\nHidden-to-Output Weights:&quot;)
W2_stats = weight_analysis[&#39;hidden_to_output&#39;][&#39;weight_statistics&#39;]
print(f&quot;  Shape: {weight_analysis[&#39;hidden_to_output&#39;][&#39;weight_vector_shape&#39;]}&quot;)
print(f&quot;  Mean: {W2_stats[&#39;mean&#39;]:.3f}, Std: {W2_stats[&#39;std&#39;]:.3f}&quot;)
print(f&quot;  Range: [{W2_stats[&#39;min&#39;]:.3f}, {W2_stats[&#39;max&#39;]:.3f}]&quot;)

## Neuron importance based on weight norms

neuron_norms = weight_analysis[&#39;input_to_hidden&#39;][&#39;neuron_weight_norms&#39;]
print(f&quot;\nNeuron Importance (by weight norm):&quot;)
for i, norm in enumerate(neuron_norms):
    importance = &quot;High&quot; if norm &gt; np.mean(neuron_norms) else &quot;Low&quot;
    print(f&quot;  Hidden neuron {i}: {norm:.3f} ({importance})&quot;)

## Example 3: Generalization Analysis

print(f&quot;\n3. Generalization Analysis&quot;)
print(&quot;-&quot; * 27)

## Test on noisy versions of XOR inputs

noise_levels = [0.0, 0.1, 0.2, 0.3]

print(&quot;Robustness to Input Noise:&quot;)
print(&quot;  Noise | Accuracy&quot;)
print(&quot;  ------|----------&quot;)

for noise_level in noise_levels:

    ## Add noise to XOR inputs

    X_noisy = X_xor + np.random.normal(0, noise_level, X_xor.shape)
    predictions = mlp_xor_analysis.predict(X_noisy)

    ## Calculate accuracy

    predicted_classes = (predictions &gt; 0.5).astype(int)
    actual_classes = y_xor.flatten()
    accuracy = np.mean(predicted_classes.flatten() == actual_classes)

    print(f&quot;  {noise_level:5.1f} |  {accuracy:6.3f}&quot;)

## Example 4: Decision Boundary Complexity

print(f&quot;\n4. Decision Boundary Analysis&quot;)
print(&quot;-&quot; * 30)

boundary_analysis = analyzer.create_decision_boundary_analysis(X_xor, resolution=20)

print(f&quot;Decision Boundary Complexity: {boundary_analysis[&#39;decision_boundary_complexity&#39;]:.3f}&quot;)

## Sample some points from decision boundary region

prediction_grid = boundary_analysis[&#39;prediction_grid&#39;]
boundary_points = []

for i in range(prediction_grid.shape[0]):
    for j in range(prediction_grid.shape[1]):
        prediction = prediction_grid[i, j]
        if 0.4 &lt; prediction &lt; 0.6:  # Near decision boundary
            x = boundary_analysis[&#39;x_grid&#39;][i, j]
            y = boundary_analysis[&#39;y_grid&#39;][i, j]
            boundary_points.append((x, y, prediction))

print(f&quot;Decision boundary points (prediction ‚âà 0.5):&quot;)
for x, y, pred in boundary_points[:5]:  # Show first 5
    print(f&quot;  ({x:.2f}, {y:.2f}) ‚Üí {pred:.3f}&quot;)

## Example 5: Feature Sensitivity Analysis

print(f&quot;\n5. Feature Sensitivity Analysis&quot;)
print(&quot;-&quot; * 32)

## Test sensitivity to each input feature

base_input = np.array([[0.5, 0.5]])  # Neutral point
base_prediction = mlp_xor_analysis.predict(base_input)[0, 0]

feature_sensitivities = []
perturbation = 0.1

for feature_idx in range(2):

    ## Perturb feature positively

    perturbed_input = base_input.copy()
    perturbed_input[0, feature_idx] += perturbation
    pos_prediction = mlp_xor_analysis.predict(perturbed_input)[0, 0]

    ## Perturb feature negatively

    perturbed_input = base_input.copy()
    perturbed_input[0, feature_idx] -= perturbation
    neg_prediction = mlp_xor_analysis.predict(perturbed_input)[0, 0]

    ## Calculate sensitivity

    sensitivity = abs(pos_prediction - neg_prediction) / (2 * perturbation)
    feature_sensitivities.append(sensitivity)

    print(f&quot;  Feature {feature_idx} sensitivity: {sensitivity:.3f}&quot;)

most_important_feature = np.argmax(feature_sensitivities)
print(f&quot;  Most important feature: {most_important_feature}&quot;)

return analyzer, xor_interpretation, weight_analysis
</code></pre></div>
<h2 id="main-demonstration-function">Main demonstration function<a class="headerlink" href="#main-demonstration-function" title="Permanent link">&para;</a></h2>
<p>def run_all_neural_network_demonstrations():
    &ldquo;&rdquo;&ldquo;Run all neural network demonstrations.&rdquo;&ldquo;&rdquo;
    print(&ldquo;üß† NEURAL NETWORKS: CONCEPTS AND IMPLEMENTATION&rdquo;)
    print(&ldquo;=&rdquo; * 50)</p>
<div class="language-text highlight"><pre><span></span><code>## Perceptron demonstrations

perceptron_models = demonstrate_perceptron()

## MLP demonstrations

mlp_models = demonstrate_tiny_mlp()

## Training loop intuition

training_analysis = demonstrate_training_loop_intuition()

## Behavior reasoning

behavior_analysis = demonstrate_behavior_reasoning()

print(f&quot;\n{&#39;=&#39;*50}&quot;)
print(&quot;NEURAL NETWORK DEMONSTRATIONS COMPLETED&quot;)
print(&quot;Key concepts demonstrated:&quot;)
print(&quot;‚Ä¢ Perceptron: single-layer learning with limitations&quot;)
print(&quot;‚Ä¢ Multi-layer Perceptron: overcoming linear separability&quot;)
print(&quot;‚Ä¢ Training dynamics: weight evolution and convergence&quot;)
print(&quot;‚Ä¢ Behavior analysis: understanding what networks learn&quot;)
print(&quot;‚Ä¢ Practical insights: hyperparameter effects and debugging&quot;)
print(&quot;=&quot; * 50)

return {
    &quot;perceptrons&quot;: perceptron_models,
    &quot;mlps&quot;: mlp_models,
    &quot;training_analysis&quot;: training_analysis,
    &quot;behavior_analysis&quot;: behavior_analysis
}
</code></pre></div>
<p>if <strong>name</strong> == &ldquo;<strong>main</strong>&rdquo;:
    all_results = run_all_neural_network_demonstrations()
 
 </p>







  
    
  
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="Last update">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="October 16, 2025 05:58:30 UTC">October 16, 2025</span>
  </span>

    
    
    
    
  </aside>


  



  <form class="md-feedback" name="feedback" hidden>
    <fieldset>
      <legend class="md-feedback__title">
        Was this page helpful?
      </legend>
      <div class="md-feedback__inner">
        <div class="md-feedback__list">
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page was helpful" data-md-value="1">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m7 0c0 .8-.7 1.5-1.5 1.5S14 10.3 14 9.5 14.7 8 15.5 8s1.5.7 1.5 1.5m-5 7.73c-1.75 0-3.29-.73-4.19-1.81L9.23 14c.45.72 1.52 1.23 2.77 1.23s2.32-.51 2.77-1.23l1.42 1.42c-.9 1.08-2.44 1.81-4.19 1.81"/></svg>
            </button>
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page could be improved" data-md-value="0">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10m-6.5-4c.8 0 1.5.7 1.5 1.5s-.7 1.5-1.5 1.5-1.5-.7-1.5-1.5.7-1.5 1.5-1.5M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m2 4.5c1.75 0 3.29.72 4.19 1.81l-1.42 1.42C14.32 16.5 13.25 16 12 16s-2.32.5-2.77 1.23l-1.42-1.42C8.71 14.72 10.25 14 12 14"/></svg>
            </button>
          
        </div>
        <div class="md-feedback__note">
          
            <div data-md-value="1" hidden>
              
              
                
              
              
              
                
                
              
              Thanks for your feedback!
            </div>
          
            <div data-md-value="0" hidden>
              
              
                
              
              
              
                
                
              
              Thanks for your feedback! Help us improve this page by creating an <a href="https://github.com/Eatham532/Software-Engineering-HSC-Textbook/issues/new/choose" target="_blank" rel="noopener">issue</a> on github.
            </div>
          
        </div>
      </div>
    </fieldset>
  </form>


                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        

<!-- Footer -->
<footer class="md-footer">
  
    <!-- Custom footer with left/right layout -->
    <div class="md-footer__inner md-grid">
      <!-- Left side: Copyright and cookie settings -->
      <div class="md-footer__left">
        <div class="md-footer__copyright">
          
            Copyright &copy; 2025 Eatham532 ‚Äì <a href="#__consent">Change cookie settings</a>

          
        </div>
      </div>

      <!-- Right side: Page name and BETA -->
      <div class="md-footer__right">
        <div class="md-footer__page-info">
          <span class="md-footer__page-title">Content</span>
          
            <span class="md-footer__beta-badge">BETA</span>
          
        </div>
      </div>
    </div>
  
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-progress" data-md-component="progress" role="progressbar"></div>
    
    
      <div class="md-consent" data-md-component="consent" id="__consent" hidden>
        <div class="md-consent__overlay"></div>
        <aside class="md-consent__inner">
          <form class="md-consent__form md-grid md-typeset" name="consent">
            



<h4>Cookie consent</h4>
<p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of the textbook. With your consent, you're helping us to make software engineering education better for everyone.</p>
<input class="md-toggle" type="checkbox" id="__settings" >
<div class="md-consent__settings">
  <ul class="task-list">
    
    
    
      
        
  
  
    
    
  
  <li class="task-list-item">
    <label class="task-list-control">
      <input type="checkbox" name="github" checked>
      <span class="task-list-indicator"></span>
      GitHub
    </label>
  </li>

      
    
    
      
        
  
  
    
    
  
  <li class="task-list-item">
    <label class="task-list-control">
      <input type="checkbox" name="analytics" checked>
      <span class="task-list-indicator"></span>
      Google Analytics
    </label>
  </li>

      
    
  </ul>
</div>
<div class="md-consent__controls">
  
    
      <button class="md-button md-button--primary">Accept</button>
    
    
    
  
    
    
    
      <label class="md-button" for="__settings">Manage settings</label>
    
  
</div>
          </form>
        </aside>
      </div>
      <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout((function(){document.querySelector("[data-md-component=consent]").hidden=!1}),250);var form=document.forms.consent;for(var action of["submit","reset"])form.addEventListener(action,(function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map((function(e){return[e,!0]})))),location.hash="",location.reload()}))</script>
    
    
      
      <script id="__config" type="application/json">{"base": "../../../..", "features": ["navigation.tabs", "navigation.top", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.prune", "search.highlight", "search.suggest", "content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.action.edit", "content.action.view", "toc.follow"], "search": "../../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../../../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="../../../../assets/diagram-modal.js"></script>
      
        <script src="../../../../assets/quiz.js"></script>
      
        <script src="../../../../assets/ide-utils.js"></script>
      
        <script src="../../../../assets/code-blocks.js"></script>
      
    
  </body>
</html>